diff --git a/gcc/Makefile.in b/gcc/Makefile.in
index d1ab22f..5dd1c25 100644
--- a/gcc/Makefile.in
+++ b/gcc/Makefile.in
@@ -3132,7 +3132,7 @@ PLUGIN_HEADERS = $(TREE_H) $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \
   tree-parloops.h tree-ssa-address.h tree-ssa-coalesce.h tree-ssa-dom.h \
   tree-ssa-loop.h tree-ssa-loop-ivopts.h tree-ssa-loop-manip.h \
   tree-ssa-loop-niter.h tree-ssa-ter.h tree-ssa-threadedge.h \
-  tree-ssa-threadupdate.h
+  tree-ssa-threadupdate.h pass-instances.def
 
 # generate the 'build fragment' b-header-vars
 s-header-vars: Makefile
diff --git a/gcc/asan.c b/gcc/asan.c
index 28a476f..08cc2c0 100644
--- a/gcc/asan.c
+++ b/gcc/asan.c
@@ -2099,6 +2099,7 @@ transform_statements (void)
 	  if (has_stmt_been_instrumented_p (s))
 	    gsi_next (&i);
 	  else if (gimple_assign_single_p (s)
+		   && !gimple_clobber_p (s)
 		   && maybe_instrument_assignment (&i))
 	    /*  Nothing to do as maybe_instrument_assignment advanced
 		the iterator I.  */;
diff --git a/gcc/c-family/array-notation-common.c b/gcc/c-family/array-notation-common.c
index c010039..f8bce04 100644
--- a/gcc/c-family/array-notation-common.c
+++ b/gcc/c-family/array-notation-common.c
@@ -221,11 +221,14 @@ find_rank (location_t loc, tree orig_expr, tree expr, bool ignore_builtin_fn,
 	      current_rank++;
 	      ii_tree = ARRAY_NOTATION_ARRAY (ii_tree);
 	    }
-	  else if (TREE_CODE (ii_tree) == ARRAY_REF)
+	  else if (handled_component_p (ii_tree)
+		   || TREE_CODE (ii_tree) == INDIRECT_REF)
 	    ii_tree = TREE_OPERAND (ii_tree, 0);
 	  else if (TREE_CODE (ii_tree) == PARM_DECL
 		   || TREE_CODE (ii_tree) == VAR_DECL)
 	    break;
+	  else
+	    gcc_unreachable ();
 	}
       if (*rank == 0)
 	/* In this case, all the expressions this function has encountered thus
@@ -329,6 +332,14 @@ extract_array_notation_exprs (tree node, bool ignore_builtin_fn,
       vec_safe_push (*array_list, node);
       return;
     }
+  if (TREE_CODE (node) == DECL_EXPR)
+    {
+      tree x = DECL_EXPR_DECL (node);
+      if (DECL_INITIAL (x))
+	extract_array_notation_exprs (DECL_INITIAL (x),
+				      ignore_builtin_fn,
+				      array_list);
+    }
   else if (TREE_CODE (node) == STATEMENT_LIST)
     {
       tree_stmt_iterator ii_tsi;
diff --git a/gcc/c-family/c-gimplify.c b/gcc/c-family/c-gimplify.c
index 737be4d..9308580 100644
--- a/gcc/c-family/c-gimplify.c
+++ b/gcc/c-family/c-gimplify.c
@@ -199,9 +199,7 @@ c_gimplify_expr (tree *expr_p, gimple_seq *pre_p ATTRIBUTE_UNUSED,
 	tree type = TREE_TYPE (TREE_OPERAND (*expr_p, 0));
 	if (INTEGRAL_TYPE_P (type) && c_promoting_integer_type_p (type))
 	  {
-	    if (TYPE_OVERFLOW_UNDEFINED (type)
-		|| ((flag_sanitize & SANITIZE_SI_OVERFLOW)
-		    && !TYPE_OVERFLOW_WRAPS (type)))
+	    if (!TYPE_OVERFLOW_WRAPS (type))
 	      type = unsigned_type_for (type);
 	    return gimplify_self_mod_expr (expr_p, pre_p, post_p, 1, type);
 	  }
diff --git a/gcc/c/c-array-notation.c b/gcc/c/c-array-notation.c
index 2305e1e..be08f53 100644
--- a/gcc/c/c-array-notation.c
+++ b/gcc/c/c-array-notation.c
@@ -1265,6 +1265,25 @@ expand_array_notations (tree *tp, int *walk_subtrees, void *)
 					 rhs_loc, rhs, TREE_TYPE (rhs));
       }
       break;
+    case DECL_EXPR:
+      {
+	tree x = DECL_EXPR_DECL (*tp);
+	if (DECL_INITIAL (x))
+	  {
+	    location_t loc = DECL_SOURCE_LOCATION (x);
+	    tree lhs = x;
+	    tree rhs = DECL_INITIAL (x);
+	    DECL_INITIAL (x) = NULL;
+	    tree new_modify_expr = build_modify_expr (loc, lhs,
+						      TREE_TYPE (lhs),
+						      NOP_EXPR,
+						      loc, rhs,
+						      TREE_TYPE(rhs));
+	    expand_array_notations (&new_modify_expr, walk_subtrees, NULL);
+	    *tp = new_modify_expr;
+	  }
+      }
+      break;
     case CALL_EXPR:
       *tp = fix_array_notation_call_expr (*tp);
       break;
diff --git a/gcc/c/c-parser.c b/gcc/c/c-parser.c
index a51af2e..264c170 100644
--- a/gcc/c/c-parser.c
+++ b/gcc/c/c-parser.c
@@ -9764,7 +9764,10 @@ c_parser_omp_variable_list (c_parser *parser,
 
 		  c_parser_consume_token (parser);
 		  if (!c_parser_next_token_is (parser, CPP_COLON))
-		    low_bound = c_parser_expression (parser).value;
+		    {
+		      low_bound = c_parser_expression (parser).value;
+		      mark_exp_read (low_bound);
+		    }
 		  if (c_parser_next_token_is (parser, CPP_CLOSE_SQUARE))
 		    length = integer_one_node;
 		  else
@@ -9777,7 +9780,10 @@ c_parser_omp_variable_list (c_parser *parser,
 			  break;
 			}
 		      if (!c_parser_next_token_is (parser, CPP_CLOSE_SQUARE))
-			length = c_parser_expression (parser).value;
+			{
+			  length = c_parser_expression (parser).value;
+			  mark_exp_read (length);
+			}
 		    }
 		  /* Look for the closing `]'.  */
 		  if (!c_parser_require (parser, CPP_CLOSE_SQUARE,
@@ -14074,6 +14080,13 @@ c_parser_array_notation (location_t loc, c_parser *parser, tree initial_index,
   
   array_type = TREE_TYPE (array_value);
   gcc_assert (array_type);
+  if (TREE_CODE (array_type) != ARRAY_TYPE
+      && TREE_CODE (array_type) != POINTER_TYPE)
+    {
+      error_at (loc, "base of array section must be pointer or array type");
+      c_parser_skip_until_found (parser, CPP_CLOSE_SQUARE, NULL);
+      return error_mark_node;
+    }
   type = TREE_TYPE (array_type);
   token = c_parser_peek_token (parser);
    
diff --git a/gcc/c/c-typeck.c b/gcc/c/c-typeck.c
index 5838d6a..d096ad4 100644
--- a/gcc/c/c-typeck.c
+++ b/gcc/c/c-typeck.c
@@ -3071,6 +3071,12 @@ convert_arguments (location_t loc, vec<location_t> arg_loc, tree typelist,
       bool excess_precision = false;
       bool npc;
       tree parmval;
+      /* Some __atomic_* builtins have additional hidden argument at
+	 position 0.  */
+      location_t ploc
+	= !arg_loc.is_empty () && values->length () == arg_loc.length ()
+	  ? expansion_point_location_if_in_system_header (arg_loc[parmnum])
+	  : input_location;
 
       if (type == void_type_node)
 	{
@@ -3113,7 +3119,8 @@ convert_arguments (location_t loc, vec<location_t> arg_loc, tree typelist,
 
 	  if (type == error_mark_node || !COMPLETE_TYPE_P (type))
 	    {
-	      error ("type of formal parameter %d is incomplete", parmnum + 1);
+	      error_at (ploc, "type of formal parameter %d is incomplete",
+			parmnum + 1);
 	      parmval = val;
 	    }
 	  else
@@ -3128,34 +3135,34 @@ convert_arguments (location_t loc, vec<location_t> arg_loc, tree typelist,
 
 		  if (INTEGRAL_TYPE_P (type)
 		      && TREE_CODE (valtype) == REAL_TYPE)
-		    warning (0, "passing argument %d of %qE as integer "
-			     "rather than floating due to prototype",
-			     argnum, rname);
+		    warning_at (ploc, 0, "passing argument %d of %qE as "
+				"integer rather than floating due to "
+				"prototype", argnum, rname);
 		  if (INTEGRAL_TYPE_P (type)
 		      && TREE_CODE (valtype) == COMPLEX_TYPE)
-		    warning (0, "passing argument %d of %qE as integer "
-			     "rather than complex due to prototype",
-			     argnum, rname);
+		    warning_at (ploc, 0, "passing argument %d of %qE as "
+				"integer rather than complex due to "
+				"prototype", argnum, rname);
 		  else if (TREE_CODE (type) == COMPLEX_TYPE
 			   && TREE_CODE (valtype) == REAL_TYPE)
-		    warning (0, "passing argument %d of %qE as complex "
-			     "rather than floating due to prototype",
-			     argnum, rname);
+		    warning_at (ploc, 0, "passing argument %d of %qE as "
+				"complex rather than floating due to "
+				"prototype", argnum, rname);
 		  else if (TREE_CODE (type) == REAL_TYPE
 			   && INTEGRAL_TYPE_P (valtype))
-		    warning (0, "passing argument %d of %qE as floating "
-			     "rather than integer due to prototype",
-			     argnum, rname);
+		    warning_at (ploc, 0, "passing argument %d of %qE as "
+				"floating rather than integer due to "
+				"prototype", argnum, rname);
 		  else if (TREE_CODE (type) == COMPLEX_TYPE
 			   && INTEGRAL_TYPE_P (valtype))
-		    warning (0, "passing argument %d of %qE as complex "
-			     "rather than integer due to prototype",
-			     argnum, rname);
+		    warning_at (ploc, 0, "passing argument %d of %qE as "
+				"complex rather than integer due to "
+				"prototype", argnum, rname);
 		  else if (TREE_CODE (type) == REAL_TYPE
 			   && TREE_CODE (valtype) == COMPLEX_TYPE)
-		    warning (0, "passing argument %d of %qE as floating "
-			     "rather than complex due to prototype",
-			     argnum, rname);
+		    warning_at (ploc, 0, "passing argument %d of %qE as "
+				"floating rather than complex due to "
+				"prototype", argnum, rname);
 		  /* ??? At some point, messages should be written about
 		     conversions between complex types, but that's too messy
 		     to do now.  */
@@ -3166,9 +3173,10 @@ convert_arguments (location_t loc, vec<location_t> arg_loc, tree typelist,
 			 since without a prototype it would be `double'.  */
 		      if (formal_prec == TYPE_PRECISION (float_type_node)
 			  && type != dfloat32_type_node)
-			warning (0, "passing argument %d of %qE as %<float%> "
-				 "rather than %<double%> due to prototype",
-				 argnum, rname);
+			warning_at (ploc, 0,
+				    "passing argument %d of %qE as %<float%> "
+				    "rather than %<double%> due to prototype",
+				    argnum, rname);
 
 		      /* Warn if mismatch between argument and prototype
 			 for decimal float types.  Warn of conversions with
@@ -3191,9 +3199,10 @@ convert_arguments (location_t loc, vec<location_t> arg_loc, tree typelist,
 				   || (type == dfloat64_type_node
 				       && (valtype
 					   != dfloat32_type_node))))
-			warning (0, "passing argument %d of %qE as %qT "
-				 "rather than %qT due to prototype",
-				 argnum, rname, type, valtype);
+			warning_at (ploc, 0,
+				    "passing argument %d of %qE as %qT "
+				    "rather than %qT due to prototype",
+				    argnum, rname, type, valtype);
 
 		    }
 		  /* Detect integer changing in width or signedness.
@@ -3212,10 +3221,10 @@ convert_arguments (location_t loc, vec<location_t> arg_loc, tree typelist,
 			   and the actual arg is that enum type.  */
 			;
 		      else if (formal_prec != TYPE_PRECISION (type1))
-			warning (OPT_Wtraditional_conversion,
-				 "passing argument %d of %qE "
-				 "with different width due to prototype",
-				 argnum, rname);
+			warning_at (ploc, OPT_Wtraditional_conversion,
+				    "passing argument %d of %qE "
+				    "with different width due to prototype",
+				    argnum, rname);
 		      else if (TYPE_UNSIGNED (type) == TYPE_UNSIGNED (type1))
 			;
 		      /* Don't complain if the formal parameter type
@@ -3236,14 +3245,15 @@ convert_arguments (location_t loc, vec<location_t> arg_loc, tree typelist,
 			       && TYPE_UNSIGNED (valtype))
 			;
 		      else if (TYPE_UNSIGNED (type))
-			warning (OPT_Wtraditional_conversion,
-				 "passing argument %d of %qE "
-				 "as unsigned due to prototype",
-				 argnum, rname);
+			warning_at (ploc, OPT_Wtraditional_conversion,
+				    "passing argument %d of %qE "
+				    "as unsigned due to prototype",
+				    argnum, rname);
 		      else
-			warning (OPT_Wtraditional_conversion,
-				 "passing argument %d of %qE "
-				 "as signed due to prototype", argnum, rname);
+			warning_at (ploc, OPT_Wtraditional_conversion,
+				    "passing argument %d of %qE "
+				    "as signed due to prototype",
+				    argnum, rname);
 		    }
 		}
 
@@ -3252,13 +3262,7 @@ convert_arguments (location_t loc, vec<location_t> arg_loc, tree typelist,
 	      if (excess_precision)
 		val = build1 (EXCESS_PRECISION_EXPR, valtype, val);
 	      origtype = (!origtypes) ? NULL_TREE : (*origtypes)[parmnum];
-	      bool arg_loc_ok = !arg_loc.is_empty ()
-				/* Some __atomic_* builtins have additional
-				   hidden argument at position 0.  */
-				&& values->length () == arg_loc.length ();
-	      parmval = convert_for_assignment (loc,
-						arg_loc_ok ? arg_loc[parmnum]
-						: UNKNOWN_LOCATION, type,
+	      parmval = convert_for_assignment (loc, ploc, type,
 						val, origtype, ic_argpass,
 						npc, fundecl, function,
 						parmnum + 1);
@@ -3282,10 +3286,10 @@ convert_arguments (location_t loc, vec<location_t> arg_loc, tree typelist,
 	    {
 	      /* Convert `float' to `double'.  */
 	      if (warn_double_promotion && !c_inhibit_evaluation_warnings)
-		warning_at (arg_loc[parmnum], OPT_Wdouble_promotion,
-			 "implicit conversion from %qT to %qT when passing "
-			 "argument to function",
-			 valtype, double_type_node);
+		warning_at (ploc, OPT_Wdouble_promotion,
+			    "implicit conversion from %qT to %qT when passing "
+			    "argument to function",
+			    valtype, double_type_node);
 	      parmval = convert (double_type_node, val);
 	    }
 	}
@@ -5591,14 +5595,14 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
   /* This macro is used to emit diagnostics to ensure that all format
      strings are complete sentences, visible to gettext and checked at
      compile time.  */
-#define WARN_FOR_ASSIGNMENT(LOCATION, OPT, AR, AS, IN, RE)             	 \
+#define WARN_FOR_ASSIGNMENT(LOCATION, PLOC, OPT, AR, AS, IN, RE)	 \
   do {                                                                   \
     switch (errtype)                                                     \
       {                                                                  \
       case ic_argpass:                                                   \
-        if (pedwarn (LOCATION, OPT, AR, parmnum, rname))                 \
+        if (pedwarn (PLOC, OPT, AR, parmnum, rname))			 \
           inform ((fundecl && !DECL_IS_BUILTIN (fundecl))	         \
-	      	  ? DECL_SOURCE_LOCATION (fundecl) : LOCATION,		 \
+		  ? DECL_SOURCE_LOCATION (fundecl) : PLOC,		 \
                   "expected %qT but argument is of type %qT",            \
                   type, rhstype);                                        \
         break;                                                           \
@@ -5621,22 +5625,22 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
      compile time.  It is the same as WARN_FOR_ASSIGNMENT but with an
      extra parameter to enumerate qualifiers.  */
 
-#define WARN_FOR_QUALIFIERS(LOCATION, OPT, AR, AS, IN, RE, QUALS)        \
+#define WARN_FOR_QUALIFIERS(LOCATION, PLOC, OPT, AR, AS, IN, RE, QUALS)  \
   do {                                                                   \
     switch (errtype)                                                     \
       {                                                                  \
       case ic_argpass:                                                   \
-        if (pedwarn (LOCATION, OPT, AR, parmnum, rname, QUALS))          \
+        if (pedwarn (PLOC, OPT, AR, parmnum, rname, QUALS))		 \
           inform ((fundecl && !DECL_IS_BUILTIN (fundecl))	         \
-	      	  ? DECL_SOURCE_LOCATION (fundecl) : LOCATION,		 \
+		  ? DECL_SOURCE_LOCATION (fundecl) : PLOC,		 \
                   "expected %qT but argument is of type %qT",            \
                   type, rhstype);                                        \
         break;                                                           \
       case ic_assign:                                                    \
-        pedwarn (LOCATION, OPT, AS, QUALS);                          \
+        pedwarn (LOCATION, OPT, AS, QUALS);				 \
         break;                                                           \
       case ic_init:                                                      \
-        pedwarn (LOCATION, OPT, IN, QUALS);                          \
+        pedwarn (LOCATION, OPT, IN, QUALS);				 \
         break;                                                           \
       case ic_return:                                                    \
         pedwarn (LOCATION, OPT, RE, QUALS);                        	 \
@@ -5688,7 +5692,7 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
 	  && TREE_CODE (type) == ENUMERAL_TYPE
 	  && TYPE_MAIN_VARIANT (checktype) != TYPE_MAIN_VARIANT (type))
 	{
-	  WARN_FOR_ASSIGNMENT (input_location, OPT_Wc___compat,
+	  WARN_FOR_ASSIGNMENT (input_location, expr_loc, OPT_Wc___compat,
 			       G_("enum conversion when passing argument "
 				  "%d of %qE is invalid in C++"),
 			       G_("enum conversion in assignment is "
@@ -5851,7 +5855,7 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
 		     vice-versa.  */
 		  if (TYPE_QUALS_NO_ADDR_SPACE (ttl)
 		      & ~TYPE_QUALS_NO_ADDR_SPACE (ttr))
-		    WARN_FOR_QUALIFIERS (location, 0,
+		    WARN_FOR_QUALIFIERS (location, expr_loc, 0,
 					 G_("passing argument %d of %qE "
 					    "makes %q#v qualified function "
 					    "pointer from unqualified"),
@@ -5867,7 +5871,7 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
 		}
 	      else if (TYPE_QUALS_NO_ADDR_SPACE (ttr)
 		       & ~TYPE_QUALS_NO_ADDR_SPACE (ttl))
-		WARN_FOR_QUALIFIERS (location, 0,
+		WARN_FOR_QUALIFIERS (location, expr_loc, 0,
 				     G_("passing argument %d of %qE discards "
 					"%qv qualifier from pointer target type"),
 				     G_("assignment discards %qv qualifier "
@@ -6029,7 +6033,7 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
 		  (VOID_TYPE_P (ttr)
 		   && !null_pointer_constant
 		   && TREE_CODE (ttl) == FUNCTION_TYPE)))
-	    WARN_FOR_ASSIGNMENT (location, OPT_Wpedantic,
+	    WARN_FOR_ASSIGNMENT (location, expr_loc, OPT_Wpedantic,
 				 G_("ISO C forbids passing argument %d of "
 				    "%qE between function pointer "
 				    "and %<void *%>"),
@@ -6048,7 +6052,7 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
 	      if (TYPE_QUALS_NO_ADDR_SPACE_NO_ATOMIC (ttr)
 		  & ~TYPE_QUALS_NO_ADDR_SPACE_NO_ATOMIC (ttl))
 		{
-		  WARN_FOR_QUALIFIERS (location, 0,
+		  WARN_FOR_QUALIFIERS (location, expr_loc, 0,
 				       G_("passing argument %d of %qE discards "
 					  "%qv qualifier from pointer target type"),
 				       G_("assignment discards %qv qualifier "
@@ -6066,7 +6070,7 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
 		;
 	      /* If there is a mismatch, do warn.  */
 	      else if (warn_pointer_sign)
-		WARN_FOR_ASSIGNMENT (location, OPT_Wpointer_sign,
+		WARN_FOR_ASSIGNMENT (location, expr_loc, OPT_Wpointer_sign,
 				     G_("pointer targets in passing argument "
 					"%d of %qE differ in signedness"),
 				     G_("pointer targets in assignment "
@@ -6085,7 +6089,7 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
 		 where an ordinary one is wanted, but not vice-versa.  */
 	      if (TYPE_QUALS_NO_ADDR_SPACE (ttl)
 		  & ~TYPE_QUALS_NO_ADDR_SPACE (ttr))
-		WARN_FOR_QUALIFIERS (location, 0,
+		WARN_FOR_QUALIFIERS (location, expr_loc, 0,
 				     G_("passing argument %d of %qE makes "
 					"%q#v qualified function pointer "
 					"from unqualified"),
@@ -6101,7 +6105,7 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
       else
 	/* Avoid warning about the volatile ObjC EH puts on decls.  */
 	if (!objc_ok)
-	  WARN_FOR_ASSIGNMENT (location, 0,
+	  WARN_FOR_ASSIGNMENT (location, expr_loc, 0,
 			       G_("passing argument %d of %qE from "
 				  "incompatible pointer type"),
 			       G_("assignment from incompatible pointer type"),
@@ -6124,7 +6128,7 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
 	 or one that results from arithmetic, even including
 	 a cast to integer type.  */
       if (!null_pointer_constant)
-	WARN_FOR_ASSIGNMENT (location, 0,
+	WARN_FOR_ASSIGNMENT (location, expr_loc, 0,
 			     G_("passing argument %d of %qE makes "
 				"pointer from integer without a cast"),
 			     G_("assignment makes pointer from integer "
@@ -6138,7 +6142,7 @@ convert_for_assignment (location_t location, location_t expr_loc, tree type,
     }
   else if (codel == INTEGER_TYPE && coder == POINTER_TYPE)
     {
-      WARN_FOR_ASSIGNMENT (location, 0,
+      WARN_FOR_ASSIGNMENT (location, expr_loc, 0,
 			   G_("passing argument %d of %qE makes integer "
 			      "from pointer without a cast"),
 			   G_("assignment makes integer from pointer "
diff --git a/gcc/cfgcleanup.c b/gcc/cfgcleanup.c
index 77196ee..de307da 100644
--- a/gcc/cfgcleanup.c
+++ b/gcc/cfgcleanup.c
@@ -53,6 +53,7 @@ along with GCC; see the file COPYING3.  If not see
 #include "df.h"
 #include "dce.h"
 #include "dbgcnt.h"
+#include "emit-rtl.h"
 
 #define FORWARDER_BLOCK_P(BB) ((BB)->flags & BB_FORWARDER_BLOCK)
 
@@ -882,7 +883,7 @@ merge_memattrs (rtx x, rtx y)
   if (GET_MODE (x) != GET_MODE (y))
     return;
 
-  if (code == MEM && MEM_ATTRS (x) != MEM_ATTRS (y))
+  if (code == MEM && !mem_attrs_eq_p (MEM_ATTRS (x), MEM_ATTRS (y)))
     {
       if (! MEM_ATTRS (x))
 	MEM_ATTRS (y) = 0;
diff --git a/gcc/cgraph.h b/gcc/cgraph.h
index 6c3be6d..0d13ebe 100644
--- a/gcc/cgraph.h
+++ b/gcc/cgraph.h
@@ -797,6 +797,7 @@ void cgraph_unnest_node (struct cgraph_node *);
 
 enum availability cgraph_function_body_availability (struct cgraph_node *);
 void cgraph_add_new_function (tree, bool);
+void cgraph_analyze_function (struct cgraph_node *);
 const char* cgraph_inline_failed_string (cgraph_inline_failed_t);
 cgraph_inline_failed_type_t cgraph_inline_failed_type (cgraph_inline_failed_t);
 
diff --git a/gcc/cgraphclones.c b/gcc/cgraphclones.c
index 972ca07..9ad76dd 100644
--- a/gcc/cgraphclones.c
+++ b/gcc/cgraphclones.c
@@ -334,6 +334,22 @@ duplicate_thunk_for_node (cgraph_node *thunk, cgraph_node *node)
 						node->clone.args_to_skip,
 						false);
     }
+
+  tree *link = &DECL_ARGUMENTS (new_decl);
+  int i = 0;
+  for (tree pd = DECL_ARGUMENTS (thunk->decl); pd; pd = DECL_CHAIN (pd), i++)
+    {
+      if (!node->clone.args_to_skip
+	  || !bitmap_bit_p (node->clone.args_to_skip, i))
+	{
+	  tree nd = copy_node (pd);
+	  DECL_CONTEXT (nd) = new_decl;
+	  *link = nd;
+	  link = &DECL_CHAIN (nd);
+	}
+    }
+  *link = NULL_TREE;
+
   gcc_checking_assert (!DECL_STRUCT_FUNCTION (new_decl));
   gcc_checking_assert (!DECL_INITIAL (new_decl));
   gcc_checking_assert (!DECL_RESULT (new_decl));
@@ -358,6 +374,11 @@ duplicate_thunk_for_node (cgraph_node *thunk, cgraph_node *node)
   cgraph_call_edge_duplication_hooks (thunk->callees, e);
   if (!expand_thunk (new_thunk, false))
     new_thunk->analyzed = true;
+  else
+    {
+      new_thunk->thunk.thunk_p = false;
+      cgraph_analyze_function (new_thunk);
+    }
   cgraph_call_node_duplication_hooks (thunk, new_thunk);
   return new_thunk;
 }
diff --git a/gcc/cgraphunit.c b/gcc/cgraphunit.c
index 04ef6fa..8f57607 100644
--- a/gcc/cgraphunit.c
+++ b/gcc/cgraphunit.c
@@ -219,7 +219,6 @@ cgraph_node_set cgraph_new_nodes;
 static void expand_all_functions (void);
 static void mark_functions_to_output (void);
 static void expand_function (struct cgraph_node *);
-static void analyze_function (struct cgraph_node *);
 static void handle_alias_pairs (void);
 
 FILE *cgraph_dump_file;
@@ -331,7 +330,7 @@ cgraph_process_new_functions (void)
 
 	  gimple_register_cfg_hooks ();
 	  if (!node->analyzed)
-	    analyze_function (node);
+	    cgraph_analyze_function (node);
 	  push_cfun (DECL_STRUCT_FUNCTION (fndecl));
 	  if (cgraph_state == CGRAPH_STATE_IPA_SSA
 	      && !gimple_in_ssa_p (DECL_STRUCT_FUNCTION (fndecl)))
@@ -541,7 +540,7 @@ cgraph_add_new_function (tree fndecl, bool lowered)
 	if (lowered)
 	  node->lowered = true;
 	node->definition = true;
-	analyze_function (node);
+	cgraph_analyze_function (node);
 	push_cfun (DECL_STRUCT_FUNCTION (fndecl));
 	gimple_register_cfg_hooks ();
 	bitmap_obstack_initialize (NULL);
@@ -598,8 +597,8 @@ output_asm_statements (void)
 }
 
 /* Analyze the function scheduled to be output.  */
-static void
-analyze_function (struct cgraph_node *node)
+void
+cgraph_analyze_function (struct cgraph_node *node)
 {
   tree decl = node->decl;
   location_t saved_loc = input_location;
@@ -1014,7 +1013,7 @@ analyze_functions (void)
 		}
 
 	      if (!cnode->analyzed)
-		analyze_function (cnode);
+		cgraph_analyze_function (cnode);
 
 	      for (edge = cnode->callees; edge; edge = edge->next_callee)
 		if (edge->callee->definition)
@@ -1039,7 +1038,7 @@ analyze_functions (void)
 	      if (DECL_ABSTRACT_ORIGIN (decl))
 		{
 		  struct cgraph_node *origin_node
-	    	  = cgraph_get_node (DECL_ABSTRACT_ORIGIN (decl));
+		    = cgraph_get_create_node (DECL_ABSTRACT_ORIGIN (decl));
 		  origin_node->used_as_abstract_origin = true;
 		}
 	    }
@@ -1170,7 +1169,7 @@ handle_alias_pairs (void)
 	  /* We use local aliases for C++ thunks to force the tailcall
 	     to bind locally.  This is a hack - to keep it working do
 	     the following (which is not strictly correct).  */
-	  && (! TREE_CODE (target_node->decl) == FUNCTION_DECL
+	  && (TREE_CODE (target_node->decl) != FUNCTION_DECL
 	      || ! DECL_VIRTUAL_P (target_node->decl))
 	  && ! lookup_attribute ("weakref", DECL_ATTRIBUTES (p->decl)))
 	{
diff --git a/gcc/config.gcc b/gcc/config.gcc
index 63e1222..9d3fa57 100644
--- a/gcc/config.gcc
+++ b/gcc/config.gcc
@@ -432,7 +432,7 @@ nds32*)
 nios2-*-*)
 	cpu_type=nios2
 	extra_options="${extra_options} g.opt"
-	;;	
+	;;
 picochip-*-*)
         cpu_type=picochip
         ;;
@@ -791,7 +791,13 @@ case ${target} in
   ;;
 *-*-rtems*)
   case ${enable_threads} in
-    yes) thread_file='rtems' ;;
+    "" | yes | rtems) thread_file='rtems' ;;
+    posix) thread_file='posix' ;;
+    no) ;;
+    *)
+      echo 'Unknown thread configuration for RTEMS'
+      exit 1
+      ;;
   esac
   tmake_file="${tmake_file} t-rtems"
   extra_options="${extra_options} rtems.opt"
@@ -1129,8 +1135,7 @@ cris-*-elf | cris-*-none)
 	;;
 crisv32-*-linux* | cris-*-linux*)
 	tm_file="dbxelf.h elfos.h ${tm_file} gnu-user.h linux.h glibc-stdint.h cris/linux.h"
-	# We need to avoid using t-linux, so override default tmake_file
-	tmake_file="cris/t-cris cris/t-linux t-slibgcc t-linux"
+	tmake_file="${tmake_file} cris/t-cris cris/t-linux"
 	extra_options="${extra_options} cris/linux.opt"
 	case $target in
 	  cris-*-*)
@@ -2156,6 +2161,10 @@ nios2-*-*)
 		tm_file="${tm_file} newlib-stdint.h nios2/elf.h"
 		extra_options="${extra_options} nios2/elf.opt"
 		;;
+	nios2-*-rtems*)
+		tm_file="${tm_file} newlib-stdint.h nios2/rtems.h rtems.h"
+		tmake_file="${tmake_file} t-rtems nios2/t-rtems"
+		;;
         esac
 	;;
 pdp11-*-*)
@@ -3531,20 +3540,17 @@ case "${target}" in
 			;;
 		esac
 
-		case "$with_fpu" in
-		"" \
-		| vfp | vfp3 | vfpv3 \
-		| vfpv3-fp16 | vfpv3-d16 | vfpv3-d16-fp16 | vfpv3xd \
-		| vfpv3xd-fp16 | neon | neon-fp16 | vfpv4 | vfpv4-d16 \
-		| fpv4-sp-d16 | neon-vfpv4 | fp-arm-v8 | neon-fp-armv8 \
-                | crypto-neon-fp-armv8)
-			# OK
-			;;
-		*)
-			echo "Unknown fpu used in --with-fpu=$with_fpu" 2>&1
-			exit 1
-			;;
-		esac
+		# see if it matches any of the entries in arm-fpus.def
+		if [ x"$with_fpu" = x ] \
+		    || grep "^ARM_FPU(\"$with_fpu\"," \
+			    ${srcdir}/config/arm/arm-fpus.def \
+			    > /dev/null; then
+		  # OK
+		  true
+		else
+		  echo "Unknown fpu used in --with-fpu=$with_fpu" 1>&2
+		  exit 1
+		fi
 
 		case "$with_abi" in
 		"" \
diff --git a/gcc/config/i386/avx512fintrin.h b/gcc/config/i386/avx512fintrin.h
index 314895a..c4caa5a 100644
--- a/gcc/config/i386/avx512fintrin.h
+++ b/gcc/config/i386/avx512fintrin.h
@@ -8103,6 +8103,22 @@ _mm512_stream_load_si512 (void *__P)
   return __builtin_ia32_movntdqa512 ((__v8di *)__P);
 }
 
+/* Constants for mantissa extraction */
+typedef enum
+{
+  _MM_MANT_NORM_1_2,		/* interval [1, 2)      */
+  _MM_MANT_NORM_p5_2,		/* interval [0.5, 2)    */
+  _MM_MANT_NORM_p5_1,		/* interval [0.5, 1)    */
+  _MM_MANT_NORM_p75_1p5		/* interval [0.75, 1.5) */
+} _MM_MANTISSA_NORM_ENUM;
+
+typedef enum
+{
+  _MM_MANT_SIGN_src,		/* sign = sign(SRC)     */
+  _MM_MANT_SIGN_zero,		/* sign = 0             */
+  _MM_MANT_SIGN_nan		/* DEST = NaN if sign(SRC) = 1 */
+} _MM_MANTISSA_SIGN_ENUM;
+
 #ifdef __OPTIMIZE__
 extern __inline __m128
 __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
@@ -8182,22 +8198,6 @@ _mm512_maskz_getexp_round_pd (__mmask8 __U, __m512d __A, const int __R)
 						    (__mmask8) __U, __R);
 }
 
-/* Constants for mantissa extraction */
-typedef enum
-{
-  _MM_MANT_NORM_1_2,		/* interval [1, 2)      */
-  _MM_MANT_NORM_p5_2,		/* interval [0.5, 2)    */
-  _MM_MANT_NORM_p5_1,		/* interval [0.5, 1)    */
-  _MM_MANT_NORM_p75_1p5		/* interval [0.75, 1.5) */
-} _MM_MANTISSA_NORM_ENUM;
-
-typedef enum
-{
-  _MM_MANT_SIGN_src,		/* sign = sign(SRC)     */
-  _MM_MANT_SIGN_zero,		/* sign = 0             */
-  _MM_MANT_SIGN_nan		/* DEST = NaN if sign(SRC) = 1 */
-} _MM_MANTISSA_SIGN_ENUM;
-
 extern __inline __m512d
 __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
 _mm512_getmant_round_pd (__m512d __A, _MM_MANTISSA_NORM_ENUM __B,
diff --git a/gcc/config/i386/driver-i386.c b/gcc/config/i386/driver-i386.c
index 80f6a08..722c546 100644
--- a/gcc/config/i386/driver-i386.c
+++ b/gcc/config/i386/driver-i386.c
@@ -431,7 +431,8 @@ const char *host_detect_local_cpu (int argc, const char **argv)
 
   model = (eax >> 4) & 0x0f;
   family = (eax >> 8) & 0x0f;
-  if (vendor == signature_INTEL_ebx)
+  if (vendor == signature_INTEL_ebx
+      || vendor == signature_AMD_ebx)
     {
       unsigned int extended_model, extended_family;
 
@@ -570,7 +571,7 @@ const char *host_detect_local_cpu (int argc, const char **argv)
 
       if (name == signature_NSC_ebx)
 	processor = PROCESSOR_GEODE;
-      else if (has_movbe)
+      else if (has_movbe && family == 22)
 	processor = PROCESSOR_BTVER2;
       else if (has_avx2)
         processor = PROCESSOR_BDVER4;
diff --git a/gcc/config/i386/i386.c b/gcc/config/i386/i386.c
index 6dc6888..668c1d1 100644
--- a/gcc/config/i386/i386.c
+++ b/gcc/config/i386/i386.c
@@ -3258,12 +3258,13 @@ ix86_option_override_internal (bool main_args_p,
 	| PTA_FMA | PTA_PRFCHW | PTA_FXSR | PTA_XSAVE 
 	| PTA_XSAVEOPT | PTA_FSGSBASE},
      {"bdver4", PROCESSOR_BDVER4, CPU_BDVER4,
-        PTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3
-        | PTA_SSE4A | PTA_CX16 | PTA_ABM | PTA_SSSE3 | PTA_SSE4_1
-        | PTA_SSE4_2 | PTA_AES | PTA_PCLMUL | PTA_AVX | PTA_AVX2 
+	PTA_64BIT | PTA_MMX | PTA_SSE | PTA_SSE2 | PTA_SSE3
+	| PTA_SSE4A | PTA_CX16 | PTA_ABM | PTA_SSSE3 | PTA_SSE4_1
+	| PTA_SSE4_2 | PTA_AES | PTA_PCLMUL | PTA_AVX | PTA_AVX2 
 	| PTA_FMA4 | PTA_XOP | PTA_LWP | PTA_BMI | PTA_BMI2 
 	| PTA_TBM | PTA_F16C | PTA_FMA | PTA_PRFCHW | PTA_FXSR 
-	| PTA_XSAVE | PTA_XSAVEOPT | PTA_FSGSBASE},
+	| PTA_XSAVE | PTA_XSAVEOPT | PTA_FSGSBASE | PTA_RDRND
+	| PTA_MOVBE},
       {"btver1", PROCESSOR_BTVER1, CPU_GENERIC,
 	PTA_64BIT | PTA_MMX |  PTA_SSE  | PTA_SSE2 | PTA_SSE3
 	| PTA_SSSE3 | PTA_SSE4A |PTA_ABM | PTA_CX16 | PTA_PRFCHW
@@ -3331,8 +3332,9 @@ ix86_option_override_internal (bool main_args_p,
       /* When TARGET_BI_ARCH == 2, by default, OPTION_MASK_ABI_X32 is
 	 on and OPTION_MASK_ABI_64 is off.  We turn off
 	 OPTION_MASK_ABI_X32 if OPTION_MASK_ABI_64 is turned on by
-	 -m64.  */
-      if (TARGET_LP64_P (opts->x_ix86_isa_flags))
+	 -m64 or OPTION_MASK_CODE16 is turned on by -m16.  */
+      if (TARGET_LP64_P (opts->x_ix86_isa_flags)
+	  || TARGET_16BIT_P (opts->x_ix86_isa_flags))
 	opts->x_ix86_isa_flags &= ~OPTION_MASK_ABI_X32;
 #endif
     }
@@ -6552,7 +6554,7 @@ classify_argument (enum machine_mode mode, const_tree type,
 					   bit_offset);
 		  if (!num)
 		    return 0;
-		  for (i = 0; i < num; i++)
+		  for (i = 0; i < num && i < words; i++)
 		    classes[i] = merge_classes (subclasses[i], classes[i]);
 		}
 	    }
@@ -42699,8 +42701,8 @@ expand_vec_perm_pshufb (struct expand_vec_perm_d *d)
 	      op0 = gen_lowpart (V4DImode, d->op0);
 	      op1 = gen_lowpart (V4DImode, d->op1);
 	      rperm[0]
-		= GEN_INT (((d->perm[0] & (nelt / 2)) ? 1 : 0)
-			   || ((d->perm[nelt / 2] & (nelt / 2)) ? 2 : 0));
+		= GEN_INT ((d->perm[0] / (nelt / 2))
+			   | ((d->perm[nelt / 2] / (nelt / 2)) * 16));
 	      emit_insn (gen_avx2_permv2ti (target, op0, op1, rperm[0]));
 	      if (target != d->target)
 		emit_move_insn (d->target, gen_lowpart (d->vmode, target));
@@ -45092,8 +45094,10 @@ ix86_expand_sse2_mulvxdi3 (rtx op0, rtx op1, rtx op2)
       /* t4: ((B*E)+(A*F))<<32, ((D*G)+(C*H))<<32 */
       emit_insn (gen_ashlv2di3 (t4, t3, GEN_INT (32)));
 
-      /* op0: (((B*E)+(A*F))<<32)+(B*F), (((D*G)+(C*H))<<32)+(D*H) */
-      emit_insn (gen_xop_pmacsdql (op0, op1, op2, t4));
+      /* Multiply lower parts and add all */
+      t5 = gen_reg_rtx (V2DImode);
+      emit_insn (gen_vec_widen_umult_even_v4si (t5, gen_lowpart (V4SImode, op1), gen_lowpart (V4SImode, op2)));
+      op0 = expand_binop (mode, add_optab, t5, t4, op0, 1, OPTAB_DIRECT);
     }
   else
     {
diff --git a/gcc/config/i386/i386.h b/gcc/config/i386/i386.h
index 51659de..b3b7c8d 100644
--- a/gcc/config/i386/i386.h
+++ b/gcc/config/i386/i386.h
@@ -457,6 +457,8 @@ extern unsigned char ix86_tune_features[X86_TUNE_LAST];
 	ix86_tune_features[X86_TUNE_SPLIT_MEM_OPND_FOR_FP_CONVERTS]
 #define TARGET_ADJUST_UNROLL \
     ix86_tune_features[X86_TUNE_ADJUST_UNROLL]
+#define TARGET_AVOID_FALSE_DEP_FOR_BMI \
+	ix86_tune_features[X86_TUNE_AVOID_FALSE_DEP_FOR_BMI]
 
 /* Feature tests against the various architecture variations.  */
 enum ix86_arch_indices {
diff --git a/gcc/config/i386/i386.md b/gcc/config/i386/i386.md
index f677a7e..cd7eadb 100644
--- a/gcc/config/i386/i386.md
+++ b/gcc/config/i386/i386.md
@@ -111,6 +111,7 @@
   UNSPEC_LEA_ADDR
   UNSPEC_XBEGIN_ABORT
   UNSPEC_STOS
+  UNSPEC_INSN_FALSE_DEP
 
   ;; For SSE/MMX support:
   UNSPEC_FIX_NOTRUNC
@@ -11856,7 +11857,8 @@
       DONE;
     }
 
-  flags_mode = TARGET_BMI ? CCCmode : CCZmode;
+  flags_mode
+    = (TARGET_BMI && !TARGET_AVOID_FALSE_DEP_FOR_BMI) ? CCCmode : CCZmode;
 
   operands[2] = gen_reg_rtx (<MODE>mode);
   operands[3] = gen_rtx_REG (flags_mode, FLAGS_REG);
@@ -11882,7 +11884,8 @@
    (parallel [(set (match_dup 0) (plus:SI (match_dup 0) (const_int 1)))
 	      (clobber (reg:CC FLAGS_REG))])]
 {
-  enum machine_mode flags_mode = TARGET_BMI ? CCCmode : CCZmode;
+  enum machine_mode flags_mode
+    = (TARGET_BMI && !TARGET_AVOID_FALSE_DEP_FOR_BMI) ? CCCmode : CCZmode;
 
   operands[3] = gen_lowpart (QImode, operands[2]);
   operands[4] = gen_rtx_REG (flags_mode, FLAGS_REG);
@@ -11897,7 +11900,7 @@
 		     (const_int 0)))
    (set (match_operand:SWI48 0 "register_operand" "=r")
 	(ctz:SWI48 (match_dup 1)))]
-  "TARGET_BMI"
+  "TARGET_BMI && !TARGET_AVOID_FALSE_DEP_FOR_BMI"
   "tzcnt{<imodesuffix>}\t{%1, %0|%0, %1}"
   [(set_attr "type" "alu1")
    (set_attr "prefix_0f" "1")
@@ -11918,7 +11921,58 @@
    (set_attr "btver2_decode" "double")
    (set_attr "mode" "<MODE>")])
 
-(define_insn "ctz<mode>2"
+(define_expand "ctz<mode>2"
+  [(parallel
+    [(set (match_operand:SWI248 0 "register_operand")
+	  (ctz:SWI248
+	    (match_operand:SWI248 1 "nonimmediate_operand")))
+     (clobber (reg:CC FLAGS_REG))])])
+
+; False dependency happens when destination is only updated by tzcnt,
+; lzcnt or popcnt.  There is no false dependency when destination is
+; also used in source.
+(define_insn_and_split "*ctz<mode>2_falsedep_1"
+  [(set (match_operand:SWI48 0 "register_operand" "=r")
+	(ctz:SWI48
+	  (match_operand:SWI48 1 "nonimmediate_operand" "rm")))
+   (clobber (reg:CC FLAGS_REG))]
+  "(TARGET_BMI || TARGET_GENERIC)
+   && TARGET_AVOID_FALSE_DEP_FOR_BMI && optimize_function_for_speed_p (cfun)"
+  "#"
+  "&& reload_completed"
+  [(parallel
+    [(set (match_dup 0)
+	  (ctz:SWI48 (match_dup 1)))
+     (unspec [(match_dup 0)] UNSPEC_INSN_FALSE_DEP)
+     (clobber (reg:CC FLAGS_REG))])]
+{
+  if (!reg_mentioned_p (operands[0], operands[1]))
+    ix86_expand_clear (operands[0]);
+})
+
+(define_insn "*ctz<mode>2_falsedep"
+  [(set (match_operand:SWI48 0 "register_operand" "=r")
+	(ctz:SWI48
+	  (match_operand:SWI48 1 "nonimmediate_operand" "rm")))
+   (unspec [(match_operand:SWI48 2 "register_operand" "0")]
+	   UNSPEC_INSN_FALSE_DEP)
+   (clobber (reg:CC FLAGS_REG))]
+  ""
+{
+  if (TARGET_BMI)
+    return "tzcnt{<imodesuffix>}\t{%1, %0|%0, %1}";
+  else if (TARGET_GENERIC)
+    /* tzcnt expands to 'rep bsf' and we can use it even if !TARGET_BMI.  */
+    return "rep%; bsf{<imodesuffix>}\t{%1, %0|%0, %1}";
+  else
+    gcc_unreachable ();
+}
+  [(set_attr "type" "alu1")
+   (set_attr "prefix_0f" "1")
+   (set_attr "prefix_rep" "1")
+   (set_attr "mode" "<MODE>")])
+
+(define_insn "*ctz<mode>2"
   [(set (match_operand:SWI248 0 "register_operand" "=r")
 	(ctz:SWI248 (match_operand:SWI248 1 "nonimmediate_operand" "rm")))
    (clobber (reg:CC FLAGS_REG))]
@@ -11965,7 +12019,47 @@
   operands[2] = GEN_INT (GET_MODE_BITSIZE (<MODE>mode)-1);
 })
 
-(define_insn "clz<mode>2_lzcnt"
+(define_expand "clz<mode>2_lzcnt"
+  [(parallel
+    [(set (match_operand:SWI248 0 "register_operand")
+	  (clz:SWI248
+	    (match_operand:SWI248 1 "nonimmediate_operand")))
+     (clobber (reg:CC FLAGS_REG))])]
+  "TARGET_LZCNT")
+
+(define_insn_and_split "*clz<mode>2_lzcnt_falsedep_1"
+  [(set (match_operand:SWI48 0 "register_operand" "=r")
+	(clz:SWI48
+	  (match_operand:SWI48 1 "nonimmediate_operand" "rm")))
+   (clobber (reg:CC FLAGS_REG))]
+  "TARGET_LZCNT
+   && TARGET_AVOID_FALSE_DEP_FOR_BMI && optimize_function_for_speed_p (cfun)"
+  "#"
+  "&& reload_completed"
+  [(parallel
+    [(set (match_dup 0)
+	  (clz:SWI48 (match_dup 1)))
+     (unspec [(match_dup 0)] UNSPEC_INSN_FALSE_DEP)
+     (clobber (reg:CC FLAGS_REG))])]
+{
+  if (!reg_mentioned_p (operands[0], operands[1]))
+    ix86_expand_clear (operands[0]);
+})
+
+(define_insn "*clz<mode>2_lzcnt_falsedep"
+  [(set (match_operand:SWI48 0 "register_operand" "=r")
+	(clz:SWI48
+	  (match_operand:SWI48 1 "nonimmediate_operand" "rm")))
+   (unspec [(match_operand:SWI48 2 "register_operand" "0")]
+	   UNSPEC_INSN_FALSE_DEP)
+   (clobber (reg:CC FLAGS_REG))]
+  "TARGET_LZCNT"
+  "lzcnt{<imodesuffix>}\t{%1, %0|%0, %1}"
+  [(set_attr "prefix_rep" "1")
+   (set_attr "type" "bitmanip")
+   (set_attr "mode" "<MODE>")])
+
+(define_insn "*clz<mode>2_lzcnt"
   [(set (match_operand:SWI248 0 "register_operand" "=r")
 	(clz:SWI248 (match_operand:SWI248 1 "nonimmediate_operand" "rm")))
    (clobber (reg:CC FLAGS_REG))]
@@ -12248,10 +12342,39 @@
    (set_attr "prefix_0f" "1")
    (set_attr "mode" "HI")])
 
-(define_insn "popcount<mode>2"
-  [(set (match_operand:SWI248 0 "register_operand" "=r")
-	(popcount:SWI248
-	  (match_operand:SWI248 1 "nonimmediate_operand" "rm")))
+(define_expand "popcount<mode>2"
+  [(parallel
+    [(set (match_operand:SWI248 0 "register_operand")
+	  (popcount:SWI248
+	    (match_operand:SWI248 1 "nonimmediate_operand")))
+     (clobber (reg:CC FLAGS_REG))])]
+  "TARGET_POPCNT")
+
+(define_insn_and_split "*popcount<mode>2_falsedep_1"
+  [(set (match_operand:SWI48 0 "register_operand" "=r")
+	(popcount:SWI48
+	  (match_operand:SWI48 1 "nonimmediate_operand" "rm")))
+   (clobber (reg:CC FLAGS_REG))]
+  "TARGET_POPCNT
+   && TARGET_AVOID_FALSE_DEP_FOR_BMI && optimize_function_for_speed_p (cfun)"
+  "#"
+  "&& reload_completed"
+  [(parallel
+    [(set (match_dup 0)
+	  (popcount:SWI48 (match_dup 1)))
+     (unspec [(match_dup 0)] UNSPEC_INSN_FALSE_DEP)
+     (clobber (reg:CC FLAGS_REG))])]
+{
+  if (!reg_mentioned_p (operands[0], operands[1]))
+    ix86_expand_clear (operands[0]);
+})
+
+(define_insn "*popcount<mode>2_falsedep"
+  [(set (match_operand:SWI48 0 "register_operand" "=r")
+	(popcount:SWI48
+	  (match_operand:SWI48 1 "nonimmediate_operand" "rm")))
+   (unspec [(match_operand:SWI48 2 "register_operand" "0")]
+	   UNSPEC_INSN_FALSE_DEP)
    (clobber (reg:CC FLAGS_REG))]
   "TARGET_POPCNT"
 {
@@ -12265,15 +12388,12 @@
    (set_attr "type" "bitmanip")
    (set_attr "mode" "<MODE>")])
 
-(define_insn "*popcount<mode>2_cmp"
-  [(set (reg FLAGS_REG)
-	(compare
-	  (popcount:SWI248
-	    (match_operand:SWI248 1 "nonimmediate_operand" "rm"))
-	  (const_int 0)))
-   (set (match_operand:SWI248 0 "register_operand" "=r")
-	(popcount:SWI248 (match_dup 1)))]
-  "TARGET_POPCNT && ix86_match_ccmode (insn, CCZmode)"
+(define_insn "*popcount<mode>2"
+  [(set (match_operand:SWI248 0 "register_operand" "=r")
+	(popcount:SWI248
+	  (match_operand:SWI248 1 "nonimmediate_operand" "rm")))
+   (clobber (reg:CC FLAGS_REG))]
+  "TARGET_POPCNT"
 {
 #if TARGET_MACHO
   return "popcnt\t{%1, %0|%0, %1}";
@@ -12285,25 +12405,6 @@
    (set_attr "type" "bitmanip")
    (set_attr "mode" "<MODE>")])
 
-(define_insn "*popcountsi2_cmp_zext"
-  [(set (reg FLAGS_REG)
-        (compare
-          (popcount:SI (match_operand:SI 1 "nonimmediate_operand" "rm"))
-          (const_int 0)))
-   (set (match_operand:DI 0 "register_operand" "=r")
-        (zero_extend:DI(popcount:SI (match_dup 1))))]
-  "TARGET_64BIT && TARGET_POPCNT && ix86_match_ccmode (insn, CCZmode)"
-{
-#if TARGET_MACHO
-  return "popcnt\t{%1, %0|%0, %1}";
-#else
-  return "popcnt{l}\t{%1, %0|%0, %1}";
-#endif
-}
-  [(set_attr "prefix_rep" "1")
-   (set_attr "type" "bitmanip")
-   (set_attr "mode" "SI")])
-
 (define_expand "bswapdi2"
   [(set (match_operand:DI 0 "register_operand")
 	(bswap:DI (match_operand:DI 1 "nonimmediate_operand")))]
@@ -13395,7 +13496,8 @@
    (set (reg:CCFP FPSR_REG)
 	(unspec:CCFP [(match_dup 2) (match_dup 3)]
 		     UNSPEC_C2_FLAG))]
-  "TARGET_USE_FANCY_MATH_387"
+  "TARGET_USE_FANCY_MATH_387
+   && flag_finite_math_only"
   "fprem"
   [(set_attr "type" "fpspc")
    (set_attr "mode" "XF")])
@@ -13404,7 +13506,8 @@
   [(use (match_operand:XF 0 "register_operand"))
    (use (match_operand:XF 1 "general_operand"))
    (use (match_operand:XF 2 "general_operand"))]
-  "TARGET_USE_FANCY_MATH_387"
+  "TARGET_USE_FANCY_MATH_387
+   && flag_finite_math_only"
 {
   rtx label = gen_label_rtx ();
 
@@ -13427,7 +13530,8 @@
   [(use (match_operand:MODEF 0 "register_operand"))
    (use (match_operand:MODEF 1 "general_operand"))
    (use (match_operand:MODEF 2 "general_operand"))]
-  "TARGET_USE_FANCY_MATH_387"
+  "TARGET_USE_FANCY_MATH_387
+   && flag_finite_math_only"
 {
   rtx (*gen_truncxf) (rtx, rtx);
 
@@ -13466,7 +13570,8 @@
    (set (reg:CCFP FPSR_REG)
 	(unspec:CCFP [(match_dup 2) (match_dup 3)]
 		     UNSPEC_C2_FLAG))]
-  "TARGET_USE_FANCY_MATH_387"
+  "TARGET_USE_FANCY_MATH_387
+   && flag_finite_math_only"
   "fprem1"
   [(set_attr "type" "fpspc")
    (set_attr "mode" "XF")])
@@ -13475,7 +13580,8 @@
   [(use (match_operand:XF 0 "register_operand"))
    (use (match_operand:XF 1 "general_operand"))
    (use (match_operand:XF 2 "general_operand"))]
-  "TARGET_USE_FANCY_MATH_387"
+  "TARGET_USE_FANCY_MATH_387
+   && flag_finite_math_only"
 {
   rtx label = gen_label_rtx ();
 
@@ -13498,7 +13604,8 @@
   [(use (match_operand:MODEF 0 "register_operand"))
    (use (match_operand:MODEF 1 "general_operand"))
    (use (match_operand:MODEF 2 "general_operand"))]
-  "TARGET_USE_FANCY_MATH_387"
+  "TARGET_USE_FANCY_MATH_387
+   && flag_finite_math_only"
 {
   rtx (*gen_truncxf) (rtx, rtx);
 
diff --git a/gcc/config/i386/ia32intrin.h b/gcc/config/i386/ia32intrin.h
index 5e7c893..614b0fa 100644
--- a/gcc/config/i386/ia32intrin.h
+++ b/gcc/config/i386/ia32intrin.h
@@ -256,11 +256,7 @@ __writeeflags (unsigned long long X)
 
 #define _bswap64(a)		__bswapq(a)
 #define _popcnt64(a)		__popcntq(a)
-#define _lrotl(a,b)		__rolq((a), (b))
-#define _lrotr(a,b)		__rorq((a), (b))
 #else
-#define _lrotl(a,b)		__rold((a), (b))
-#define _lrotr(a,b)		__rord((a), (b))
 
 /* Read flags register */
 extern __inline unsigned int
@@ -280,6 +276,16 @@ __writeeflags (unsigned int X)
 
 #endif
 
+/* On LP64 systems, longs are 64-bit.  Use the appropriate rotate
+ * function.  */
+#ifdef __LP64__
+#define _lrotl(a,b)		__rolq((a), (b))
+#define _lrotr(a,b)		__rorq((a), (b))
+#else
+#define _lrotl(a,b)		__rold((a), (b))
+#define _lrotr(a,b)		__rord((a), (b))
+#endif
+
 #define _bit_scan_forward(a)	__bsfd(a)
 #define _bit_scan_reverse(a)	__bsrd(a)
 #define _bswap(a)		__bswapd(a)
diff --git a/gcc/config/i386/sse.md b/gcc/config/i386/sse.md
index 72a4d6d..c700425 100644
--- a/gcc/config/i386/sse.md
+++ b/gcc/config/i386/sse.md
@@ -5887,9 +5887,10 @@
 	      (match_operand 5  "const_0_to_15_operand")]))
 	  (match_operand:<ssequartermode> 6 "memory_operand" "0")
 	  (match_operand:QI 7 "register_operand" "Yk")))]
-  "TARGET_AVX512F && (INTVAL (operands[2]) = INTVAL (operands[3]) - 1)
-  && (INTVAL (operands[3]) = INTVAL (operands[4]) - 1)
-  && (INTVAL (operands[4]) = INTVAL (operands[5]) - 1)"
+  "TARGET_AVX512F
+   && (INTVAL (operands[2]) == (INTVAL (operands[3]) - 1)
+       && INTVAL (operands[3]) == (INTVAL (operands[4]) - 1)
+       && INTVAL (operands[4]) == (INTVAL (operands[5]) - 1))"
 {
   operands[2] = GEN_INT ((INTVAL (operands[2])) >> 2);
   return "vextract<shuffletype>32x4\t{%2, %1, %0%{%7%}|%0%{%7%}, %1, %2}";
@@ -5909,9 +5910,10 @@
             (match_operand 3  "const_0_to_15_operand")
             (match_operand 4  "const_0_to_15_operand")
             (match_operand 5  "const_0_to_15_operand")])))]
-  "TARGET_AVX512F && (INTVAL (operands[2]) = INTVAL (operands[3]) - 1)
-  && (INTVAL (operands[3]) = INTVAL (operands[4]) - 1)
-  && (INTVAL (operands[4]) = INTVAL (operands[5]) - 1)"
+  "TARGET_AVX512F
+   && (INTVAL (operands[2]) == (INTVAL (operands[3]) - 1)
+       && INTVAL (operands[3]) == (INTVAL (operands[4]) - 1)
+       && INTVAL (operands[4]) == (INTVAL (operands[5]) - 1))"
 {
   operands[2] = GEN_INT ((INTVAL (operands[2])) >> 2);
   return "vextract<shuffletype>32x4\t{%2, %1, %0<mask_operand6>|%0<mask_operand6>, %1, %2}";
@@ -5992,9 +5994,9 @@
    (set_attr "mode" "<sseinsnmode>")])
 
 (define_insn "vec_extract_lo_<mode><mask_name>"
-  [(set (match_operand:<ssehalfvecmode> 0 "<store_mask_predicate>" "=<store_mask_constraint>")
+  [(set (match_operand:<ssehalfvecmode> 0 "<store_mask_predicate>" "=<store_mask_constraint>,v")
 	(vec_select:<ssehalfvecmode>
-	  (match_operand:V8FI 1 "nonimmediate_operand" "vm")
+	  (match_operand:V8FI 1 "nonimmediate_operand" "v,m")
 	  (parallel [(const_int 0) (const_int 1)
             (const_int 2) (const_int 3)])))]
   "TARGET_AVX512F && !(MEM_P (operands[0]) && MEM_P (operands[1]))"
diff --git a/gcc/config/i386/x86-tune.def b/gcc/config/i386/x86-tune.def
index 8399102..c361748 100644
--- a/gcc/config/i386/x86-tune.def
+++ b/gcc/config/i386/x86-tune.def
@@ -500,6 +500,11 @@ DEF_TUNE (X86_TUNE_NOT_VECTORMODE, "not_vectormode", m_K6)
 DEF_TUNE (X86_TUNE_AVOID_VECTOR_DECODE, "avoid_vector_decode",
           m_K8)
 
+/* X86_TUNE_AVOID_FALSE_DEP_FOR_BMI: Avoid false dependency
+   for bit-manipulation instructions.  */
+DEF_TUNE (X86_TUNE_AVOID_FALSE_DEP_FOR_BMI, "avoid_false_dep_for_bmi",
+	  m_SANDYBRIDGE | m_HASWELL | m_INTEL | m_GENERIC)
+
 /*****************************************************************************/
 /* This never worked well before.                                            */
 /*****************************************************************************/
diff --git a/gcc/cp/call.c b/gcc/cp/call.c
index 7c11a53..709b6be 100644
--- a/gcc/cp/call.c
+++ b/gcc/cp/call.c
@@ -1208,9 +1208,10 @@ standard_conversion (tree to, tree from, tree expr, bool c_cast_p,
 	       && TREE_CODE (TREE_TYPE (from)) != FUNCTION_TYPE)
 	{
 	  tree nfrom = TREE_TYPE (from);
+	  /* Don't try to apply restrict to void.  */
+	  int quals = cp_type_quals (nfrom) & ~TYPE_QUAL_RESTRICT;
 	  from = build_pointer_type
-	    (cp_build_qualified_type (void_type_node, 
-			              cp_type_quals (nfrom)));
+	    (cp_build_qualified_type (void_type_node, quals));
 	  conv = build_conv (ck_ptr, from, conv);
 	}
       else if (TYPE_PTRDATAMEM_P (from))
@@ -6077,7 +6078,6 @@ convert_like_real (conversion *convs, tree expr, tree fn, int argnum,
 	return expr;
       }
     case ck_identity:
-      expr = mark_rvalue_use (expr);
       if (BRACE_ENCLOSED_INITIALIZER_P (expr))
 	{
 	  int nelts = CONSTRUCTOR_NELTS (expr);
@@ -6088,6 +6088,7 @@ convert_like_real (conversion *convs, tree expr, tree fn, int argnum,
 	  else
 	    gcc_unreachable ();
 	}
+      expr = mark_rvalue_use (expr);
 
       if (type_unknown_p (expr))
 	expr = instantiate_type (totype, expr, complain);
diff --git a/gcc/cp/class.c b/gcc/cp/class.c
index f4fb4c9..042a43d 100644
--- a/gcc/cp/class.c
+++ b/gcc/cp/class.c
@@ -7251,6 +7251,29 @@ currently_open_derived_class (tree t)
   return NULL_TREE;
 }
 
+/* Return the outermost enclosing class type that is still open, or
+   NULL_TREE.  */
+
+tree
+outermost_open_class (void)
+{
+  if (!current_class_type)
+    return NULL_TREE;
+  tree r = NULL_TREE;
+  if (TYPE_BEING_DEFINED (current_class_type))
+    r = current_class_type;
+  for (int i = current_class_depth - 1; i > 0; --i)
+    {
+      if (current_class_stack[i].hidden)
+	break;
+      tree t = current_class_stack[i].type;
+      if (!TYPE_BEING_DEFINED (t))
+	break;
+      r = t;
+    }
+  return r;
+}
+
 /* Returns the innermost class type which is not a lambda closure type.  */
 
 tree
diff --git a/gcc/cp/cp-array-notation.c b/gcc/cp/cp-array-notation.c
index fed60c9..a50ff1d 100644
--- a/gcc/cp/cp-array-notation.c
+++ b/gcc/cp/cp-array-notation.c
@@ -607,7 +607,7 @@ expand_an_in_modify_expr (location_t location, tree lhs,
     
   if (lhs_rank == 0 && rhs_rank != 0)
     {
-      error_at (location, "%qD cannot be scalar when %qD is not", lhs, rhs);
+      error_at (location, "%qE cannot be scalar when %qE is not", lhs, rhs);
       return error_mark_node;
     }
   if (lhs_rank != 0 && rhs_rank != 0 && lhs_rank != rhs_rank)
@@ -1147,13 +1147,13 @@ expand_array_notation_exprs (tree t)
     case PARM_DECL:
     case NON_LVALUE_EXPR:
     case NOP_EXPR:
-    case INIT_EXPR:
     case ADDR_EXPR:
     case ARRAY_REF:
     case BIT_FIELD_REF:
     case VECTOR_CST:
     case COMPLEX_CST:
       return t;
+    case INIT_EXPR:
     case MODIFY_EXPR:
       if (contains_array_notation_expr (t))
 	t = expand_an_in_modify_expr (loc, TREE_OPERAND (t, 0), NOP_EXPR, 
@@ -1175,13 +1175,24 @@ expand_array_notation_exprs (tree t)
 	return t;
       }
     case DECL_EXPR:
-      {
-	tree x = DECL_EXPR_DECL (t);
-	if (t && TREE_CODE (x) != FUNCTION_DECL)
+      if (contains_array_notation_expr (t))
+	{
+	  tree x = DECL_EXPR_DECL (t);
 	  if (DECL_INITIAL (x))
-	    t = expand_unary_array_notation_exprs (t);
+	    {
+	      location_t loc = DECL_SOURCE_LOCATION (x);
+	      tree lhs = x;
+	      tree rhs = DECL_INITIAL (x);
+	      DECL_INITIAL (x) = NULL;
+	      tree new_modify_expr = build_modify_expr (loc, lhs,
+							TREE_TYPE (lhs),
+							NOP_EXPR,
+							loc, rhs,
+							TREE_TYPE(rhs));
+	      t = expand_array_notation_exprs (new_modify_expr);
+	    }
+	}
       return t;
-      }
     case STATEMENT_LIST:
       {
 	tree_stmt_iterator i;
@@ -1392,7 +1403,10 @@ build_array_notation_ref (location_t loc, tree array, tree start, tree length,
   if (TREE_CODE (type) == ARRAY_TYPE || TREE_CODE (type) == POINTER_TYPE)
     TREE_TYPE (array_ntn_expr) = TREE_TYPE (type);
   else
-    gcc_unreachable ();
+    {
+      error_at (loc, "base of array section must be pointer or array type");
+      return error_mark_node;
+    }
 
   SET_EXPR_LOCATION (array_ntn_expr, loc);
   return array_ntn_expr;
diff --git a/gcc/cp/cp-tree.h b/gcc/cp/cp-tree.h
index 26a63d0..99cc7ec 100644
--- a/gcc/cp/cp-tree.h
+++ b/gcc/cp/cp-tree.h
@@ -5112,6 +5112,7 @@ extern void resort_type_method_vec		(void *, void *,
 extern bool add_method				(tree, tree, tree);
 extern bool currently_open_class		(tree);
 extern tree currently_open_derived_class	(tree);
+extern tree outermost_open_class		(void);
 extern tree current_nonlambda_class_type	(void);
 extern tree finish_struct			(tree, tree);
 extern void finish_struct_1			(tree);
@@ -5351,6 +5352,7 @@ extern tree get_tls_wrapper_fn			(tree);
 extern void mark_needed				(tree);
 extern bool decl_needed_p			(tree);
 extern void note_vague_linkage_fn		(tree);
+extern void note_comdat_fn			(tree);
 extern tree build_artificial_parm		(tree, tree);
 extern bool possibly_inlined_p			(tree);
 extern int parm_index                           (tree);
diff --git a/gcc/cp/decl.c b/gcc/cp/decl.c
index 19944ab..1f3a552 100644
--- a/gcc/cp/decl.c
+++ b/gcc/cp/decl.c
@@ -14177,8 +14177,8 @@ grokmethod (cp_decl_specifier_seq *declspecs,
 /* VAR is a VAR_DECL.  If its type is incomplete, remember VAR so that
    we can lay it out later, when and if its type becomes complete.
 
-   Also handle constexpr pointer to member variables where the initializer
-   is an unlowered PTRMEM_CST because the class isn't complete yet.  */
+   Also handle constexpr variables where the initializer involves
+   an unlowered PTRMEM_CST because the class isn't complete yet.  */
 
 void
 maybe_register_incomplete_var (tree var)
@@ -14203,12 +14203,13 @@ maybe_register_incomplete_var (tree var)
 	  incomplete_var iv = {var, inner_type};
 	  vec_safe_push (incomplete_vars, iv);
 	}
-      else if (TYPE_PTRMEM_P (inner_type)
-	       && DECL_INITIAL (var)
-	       && TREE_CODE (DECL_INITIAL (var)) == PTRMEM_CST)
+      else if (!(DECL_LANG_SPECIFIC (var) && DECL_TEMPLATE_INFO (var))
+	       && decl_constant_var_p (var)
+	       && (TYPE_PTRMEM_P (inner_type) || CLASS_TYPE_P (inner_type)))
 	{
-	  tree context = TYPE_PTRMEM_CLASS_TYPE (inner_type);
-	  gcc_assert (TYPE_BEING_DEFINED (context));
+	  /* When the outermost open class is complete we can resolve any
+	     pointers-to-members.  */
+	  tree context = outermost_open_class ();
 	  incomplete_var iv = {var, context};
 	  vec_safe_push (incomplete_vars, iv);
 	}
@@ -14232,9 +14233,8 @@ complete_vars (tree type)
 	  tree var = iv->decl;
 	  tree type = TREE_TYPE (var);
 
-	  if (TYPE_PTRMEM_P (type))
-	    DECL_INITIAL (var) = cplus_expand_constant (DECL_INITIAL (var));
-	  else
+	  if (TYPE_MAIN_VARIANT (strip_array_types (type))
+	      == iv->incomplete_type)
 	    {
 	      /* Complete the type of the variable.  The VAR_DECL itself
 		 will be laid out in expand_expr.  */
@@ -14242,6 +14242,10 @@ complete_vars (tree type)
 	      cp_apply_type_quals_to_decl (cp_type_quals (type), var);
 	    }
 
+	  if (DECL_INITIAL (var)
+	      && decl_constant_var_p (var))
+	    DECL_INITIAL (var) = cplus_expand_constant (DECL_INITIAL (var));
+
 	  /* Remove this entry from the list.  */
 	  incomplete_vars->unordered_remove (ix);
 	}
diff --git a/gcc/cp/decl2.c b/gcc/cp/decl2.c
index 6c52e53..a2626d4 100644
--- a/gcc/cp/decl2.c
+++ b/gcc/cp/decl2.c
@@ -99,6 +99,10 @@ static GTY(()) vec<tree, va_gc> *pending_statics;
    may need to emit outline anyway.  */
 static GTY(()) vec<tree, va_gc> *deferred_fns;
 
+/* A list of functions which we might want to set DECL_COMDAT on at EOF.  */
+
+static GTY(()) vec<tree, va_gc> *maybe_comdat_fns;
+
 /* A list of decls that use types with no linkage, which we need to make
    sure are defined.  */
 static GTY(()) vec<tree, va_gc> *no_linkage_decls;
@@ -1896,6 +1900,12 @@ mark_needed (tree decl)
 	 definition.  */
       struct cgraph_node *node = cgraph_get_create_node (decl);
       node->forced_by_abi = true;
+
+      /* #pragma interface and -frepo code can call mark_needed for
+          maybe-in-charge 'tors; mark the clones as well.  */
+      tree clone;
+      FOR_EACH_CLONE (clone, decl)
+	mark_needed (clone);
     }
   else if (TREE_CODE (decl) == VAR_DECL)
     {
@@ -2678,17 +2688,7 @@ import_export_decl (tree decl)
     {
       /* The repository indicates that this entity should be defined
 	 here.  Make sure the back end honors that request.  */
-      if (VAR_P (decl))
-	mark_needed (decl);
-      else if (DECL_MAYBE_IN_CHARGE_CONSTRUCTOR_P (decl)
-	       || DECL_MAYBE_IN_CHARGE_DESTRUCTOR_P (decl))
-	{
-	  tree clone;
-	  FOR_EACH_CLONE (clone, decl)
-	    mark_needed (clone);
-	}
-      else
-	mark_needed (decl);
+      mark_needed (decl);
       /* Output the definition as an ordinary strong definition.  */
       DECL_EXTERNAL (decl) = 0;
       DECL_INTERFACE_KNOWN (decl) = 1;
@@ -4231,6 +4231,34 @@ dump_tu (void)
     }
 }
 
+/* Much like the above, but not necessarily defined.  4.9 hack for setting
+   DECL_COMDAT on DECL_EXTERNAL functions, along with set_comdat.  */
+
+void
+note_comdat_fn (tree decl)
+{
+  vec_safe_push (maybe_comdat_fns, decl);
+}
+
+/* DECL is a function with vague linkage that was not
+   instantiated/synthesized in this translation unit.  Set DECL_COMDAT for
+   the benefit of can_refer_decl_in_current_unit_p.  */
+
+static void
+set_comdat (tree decl)
+{
+  DECL_COMDAT (decl) = true;
+
+  tree clone;
+  FOR_EACH_CLONE (clone, decl)
+    set_comdat (clone);
+
+  if (DECL_VIRTUAL_P (decl))
+    for (tree thunk = DECL_THUNKS (decl); thunk;
+	 thunk = DECL_CHAIN (thunk))
+      DECL_COMDAT (thunk) = true;
+}
+
 /* This routine is called at the end of compilation.
    Its job is to create all the code needed to initialize and
    destroy the global aggregates.  We do the destruction
@@ -4608,6 +4636,10 @@ cp_write_global_declarations (void)
       vtv_build_vtable_verify_fndecl ();
     }
 
+  FOR_EACH_VEC_SAFE_ELT (maybe_comdat_fns, i, decl)
+    if (!DECL_COMDAT (decl) && vague_linkage_p (decl))
+      set_comdat (decl);
+
   finalize_compilation_unit ();
 
   if (flag_vtable_verify)
diff --git a/gcc/cp/expr.c b/gcc/cp/expr.c
index a62e0f9..99f8006 100644
--- a/gcc/cp/expr.c
+++ b/gcc/cp/expr.c
@@ -74,6 +74,14 @@ cplus_expand_constant (tree cst)
       }
       break;
 
+    case CONSTRUCTOR:
+      {
+	constructor_elt *elt;
+	unsigned HOST_WIDE_INT idx;
+	FOR_EACH_VEC_SAFE_ELT (CONSTRUCTOR_ELTS (cst), idx, elt)
+	  elt->value = cplus_expand_constant (elt->value);
+      }
+
     default:
       /* There's nothing to do.  */
       break;
diff --git a/gcc/cp/init.c b/gcc/cp/init.c
index 960c39c..bf9c538 100644
--- a/gcc/cp/init.c
+++ b/gcc/cp/init.c
@@ -3557,19 +3557,11 @@ build_vec_init (tree base, tree maxindex, tree init,
       try_block = begin_try_block ();
     }
 
-  /* If the initializer is {}, then all elements are initialized from {}.
-     But for non-classes, that's the same as value-initialization.  */
+  bool empty_list = false;
   if (init && BRACE_ENCLOSED_INITIALIZER_P (init)
       && CONSTRUCTOR_NELTS (init) == 0)
-    {
-      if (CLASS_TYPE_P (type))
-	/* Leave init alone.  */;
-      else
-	{
-	  init = NULL_TREE;
-	  explicit_value_init_p = true;
-	}
-    }
+    /* Skip over the handling of non-empty init lists.  */
+    empty_list = true;
 
   /* Maybe pull out constant value when from_array? */
 
@@ -3689,14 +3681,8 @@ build_vec_init (tree base, tree maxindex, tree init,
 	    vec_free (new_vec);
 	}
 
-      /* Any elements without explicit initializers get {}.  */
-      if (cxx_dialect >= cxx11 && AGGREGATE_TYPE_P (type))
-	init = build_constructor (init_list_type_node, NULL);
-      else
-	{
-	  init = NULL_TREE;
-	  explicit_value_init_p = true;
-	}
+      /* Any elements without explicit initializers get T{}.  */
+      empty_list = true;
     }
   else if (from_array)
     {
@@ -3742,6 +3728,26 @@ build_vec_init (tree base, tree maxindex, tree init,
 
       to = build1 (INDIRECT_REF, type, base);
 
+      /* If the initializer is {}, then all elements are initialized from T{}.
+	 But for non-classes, that's the same as value-initialization.  */
+      if (empty_list)
+	{
+	  if (cxx_dialect >= cxx11 && AGGREGATE_TYPE_P (type))
+	    {
+	      if (BRACE_ENCLOSED_INITIALIZER_P (init)
+		  && CONSTRUCTOR_NELTS (init) == 0)
+		/* Reuse it.  */;
+	      else
+		init = build_constructor (init_list_type_node, NULL);
+	      CONSTRUCTOR_IS_DIRECT_INIT (init) = true;
+	    }
+	  else
+	    {
+	      init = NULL_TREE;
+	      explicit_value_init_p = true;
+	    }
+	}
+
       if (from_array)
 	{
 	  tree from;
@@ -3846,6 +3852,13 @@ build_vec_init (tree base, tree maxindex, tree init,
 
   stmt_expr = finish_init_stmts (is_global, stmt_expr, compound_stmt);
 
+  current_stmt_tree ()->stmts_are_full_exprs_p = destroy_temps;
+
+  if (errors)
+    return error_mark_node;
+  if (const_init)
+    return build2 (INIT_EXPR, atype, obase, const_init);
+
   /* Now make the result have the correct type.  */
   if (TREE_CODE (atype) == ARRAY_TYPE)
     {
@@ -3855,12 +3868,6 @@ build_vec_init (tree base, tree maxindex, tree init,
       TREE_NO_WARNING (stmt_expr) = 1;
     }
 
-  current_stmt_tree ()->stmts_are_full_exprs_p = destroy_temps;
-
-  if (const_init)
-    return build2 (INIT_EXPR, atype, obase, const_init);
-  if (errors)
-    return error_mark_node;
   return stmt_expr;
 }
 
diff --git a/gcc/cp/lambda.c b/gcc/cp/lambda.c
index 7bd0de1..6acbdd9 100644
--- a/gcc/cp/lambda.c
+++ b/gcc/cp/lambda.c
@@ -820,6 +820,7 @@ void
 maybe_add_lambda_conv_op (tree type)
 {
   bool nested = (current_function_decl != NULL_TREE);
+  bool nested_def = decl_function_context (TYPE_MAIN_DECL (type));
   tree callop = lambda_function (type);
 
   if (LAMBDA_EXPR_CAPTURE_LIST (CLASSTYPE_LAMBDA_EXPR (type)) != NULL_TREE)
@@ -972,7 +973,7 @@ maybe_add_lambda_conv_op (tree type)
   DECL_NOT_REALLY_EXTERN (fn) = 1;
   DECL_DECLARED_INLINE_P (fn) = 1;
   DECL_ARGUMENTS (fn) = build_this_parm (fntype, TYPE_QUAL_CONST);
-  if (nested)
+  if (nested_def)
     DECL_INTERFACE_KNOWN (fn) = 1;
 
   if (generic_lambda_p)
@@ -1012,7 +1013,7 @@ maybe_add_lambda_conv_op (tree type)
       DECL_NAME (arg) = NULL_TREE;
       DECL_CONTEXT (arg) = fn;
     }
-  if (nested)
+  if (nested_def)
     DECL_INTERFACE_KNOWN (fn) = 1;
 
   if (generic_lambda_p)
diff --git a/gcc/cp/method.c b/gcc/cp/method.c
index 11bff7f..b074d74 100644
--- a/gcc/cp/method.c
+++ b/gcc/cp/method.c
@@ -1773,6 +1773,7 @@ implicitly_declare_fn (special_function_kind kind, tree type,
   DECL_EXTERNAL (fn) = true;
   DECL_NOT_REALLY_EXTERN (fn) = 1;
   DECL_DECLARED_INLINE_P (fn) = 1;
+  note_comdat_fn (fn);
   gcc_assert (!TREE_USED (fn));
 
   /* Restore PROCESSING_TEMPLATE_DECL.  */
diff --git a/gcc/cp/parser.c b/gcc/cp/parser.c
index 054f160..e6f9430 100644
--- a/gcc/cp/parser.c
+++ b/gcc/cp/parser.c
@@ -6306,7 +6306,7 @@ cp_parser_array_notation (location_t loc, cp_parser *parser, tree *init_index,
   parser->colon_corrects_to_scope_p = saved_colon_corrects;
 
   if (*init_index == error_mark_node || length_index == error_mark_node
-      || stride == error_mark_node)
+      || stride == error_mark_node || array_type == error_mark_node)
     {
       if (cp_lexer_peek_token (parser->lexer)->type == CPP_CLOSE_SQUARE)
 	cp_lexer_consume_token (parser->lexer);
diff --git a/gcc/cp/pt.c b/gcc/cp/pt.c
index 05ae382..6e292a2 100644
--- a/gcc/cp/pt.c
+++ b/gcc/cp/pt.c
@@ -4430,9 +4430,11 @@ check_default_tmpl_args (tree decl, tree parms, bool is_primary,
        local scope.  */
     return true;
 
-  if (TREE_CODE (decl) == TYPE_DECL
-      && TREE_TYPE (decl)
-      && LAMBDA_TYPE_P (TREE_TYPE (decl)))
+  if ((TREE_CODE (decl) == TYPE_DECL
+       && TREE_TYPE (decl)
+       && LAMBDA_TYPE_P (TREE_TYPE (decl)))
+      || (TREE_CODE (decl) == FUNCTION_DECL
+	  && LAMBDA_FUNCTION_P (decl)))
     /* A lambda doesn't have an explicit declaration; don't complain
        about the parms of the enclosing class.  */
     return true;
@@ -4697,6 +4699,9 @@ push_template_decl_real (tree decl, bool is_friend)
          template <typename T> friend void A<T>::f();
        is not primary.  */
     is_primary = false;
+  else if (TREE_CODE (decl) == TYPE_DECL
+	   && LAMBDA_TYPE_P (TREE_TYPE (decl)))
+    is_primary = false;
   else
     is_primary = template_parm_scope_p ();
 
@@ -9135,6 +9140,11 @@ instantiate_class_template_1 (tree type)
 		  && DECL_OMP_DECLARE_REDUCTION_P (r))
 		cp_check_omp_declare_reduction (r);
 	    }
+	  else if (DECL_CLASS_TEMPLATE_P (t)
+		   && LAMBDA_TYPE_P (TREE_TYPE (t)))
+	    /* A closure type for a lambda in a default argument for a
+	       member template.  Ignore it; it will be instantiated with
+	       the default argument.  */;
 	  else
 	    {
 	      /* Build new TYPE_FIELDS.  */
@@ -9808,6 +9818,11 @@ tsubst_pack_expansion (tree t, tree args, tsubst_flags_t complain,
 	}
     }
 
+  /* If the expansion is just T..., return the matching argument pack.  */
+  if (!unsubstituted_packs
+      && TREE_PURPOSE (packs) == pattern)
+    return ARGUMENT_PACK_ARGS (TREE_VALUE (packs));
+
   /* We cannot expand this expansion expression, because we don't have
      all of the argument packs we need.  */
   if (use_pack_expansion_extra_args_p (packs, len, unsubstituted_packs))
@@ -10669,6 +10684,9 @@ tsubst_decl (tree t, tree args, tsubst_flags_t complain)
 		 the type earlier (template/friend54.C).  */
 	      RETURN (new_r);
 
+	    if (!DECL_FRIEND_P (r))
+	      note_comdat_fn (r);
+
 	    /* We're not supposed to instantiate default arguments
 	       until they are called, for a template.  But, for a
 	       declaration like:
@@ -13852,8 +13870,6 @@ tsubst_expr (tree t, tree args, tsubst_flags_t complain, tree in_decl,
     case OMP_SECTIONS:
     case OMP_SINGLE:
     case OMP_TEAMS:
-    case OMP_TARGET_DATA:
-    case OMP_TARGET:
       tmp = tsubst_omp_clauses (OMP_CLAUSES (t), false,
 				args, complain, in_decl);
       stmt = push_stmt_list ();
@@ -13866,6 +13882,22 @@ tsubst_expr (tree t, tree args, tsubst_flags_t complain, tree in_decl,
       add_stmt (t);
       break;
 
+    case OMP_TARGET_DATA:
+    case OMP_TARGET:
+      tmp = tsubst_omp_clauses (OMP_CLAUSES (t), false,
+				args, complain, in_decl);
+      keep_next_level (true);
+      stmt = begin_omp_structured_block ();
+
+      RECUR (OMP_BODY (t));
+      stmt = finish_omp_structured_block (stmt);
+
+      t = copy_node (t);
+      OMP_BODY (t) = stmt;
+      OMP_CLAUSES (t) = tmp;
+      add_stmt (t);
+      break;
+
     case OMP_TARGET_UPDATE:
       tmp = tsubst_omp_clauses (OMP_TARGET_UPDATE_CLAUSES (t), false,
 				args, complain, in_decl);
@@ -15185,6 +15217,16 @@ tsubst_copy_and_build (tree t,
     case PARM_DECL:
       {
 	tree r = tsubst_copy (t, args, complain, in_decl);
+	if (TREE_CODE (r) == VAR_DECL
+	    && !processing_template_decl
+	    && !cp_unevaluated_operand
+	    && DECL_THREAD_LOCAL_P (r))
+	  {
+	    if (tree wrap = get_tls_wrapper_fn (r))
+	      /* Replace an evaluated use of the thread_local variable with
+		 a call to its wrapper.  */
+	      r = build_cxx_call (wrap, 0, NULL, tf_warning_or_error);
+	  }
 
 	if (TREE_CODE (TREE_TYPE (t)) != REFERENCE_TYPE)
 	  /* If the original type was a reference, we'll be wrapped in
diff --git a/gcc/cp/semantics.c b/gcc/cp/semantics.c
index d6f3a73..8174eca 100644
--- a/gcc/cp/semantics.c
+++ b/gcc/cp/semantics.c
@@ -3490,6 +3490,7 @@ finish_id_expression (tree id_expression,
       tree wrap;
       if (VAR_P (decl)
 	  && !cp_unevaluated_operand
+	  && !processing_template_decl
 	  && DECL_THREAD_LOCAL_P (decl)
 	  && (wrap = get_tls_wrapper_fn (decl)))
 	{
@@ -4261,6 +4262,10 @@ handle_omp_array_sections_1 (tree c, tree t, vec<tree> &types,
 		length);
       return error_mark_node;
     }
+  if (low_bound)
+    low_bound = mark_rvalue_use (low_bound);
+  if (length)
+    length = mark_rvalue_use (length);
   if (low_bound
       && TREE_CODE (low_bound) == INTEGER_CST
       && TYPE_PRECISION (TREE_TYPE (low_bound))
@@ -5626,7 +5631,9 @@ finish_omp_clauses (tree clauses)
 	      else
 		{
 		  t = OMP_CLAUSE_DECL (c);
-		  if (!cp_omp_mappable_type (TREE_TYPE (t)))
+		  if (TREE_CODE (t) != TREE_LIST
+		      && !type_dependent_expression_p (t)
+		      && !cp_omp_mappable_type (TREE_TYPE (t)))
 		    {
 		      error_at (OMP_CLAUSE_LOCATION (c),
 				"array section does not have mappable type "
@@ -5666,6 +5673,7 @@ finish_omp_clauses (tree clauses)
 	    remove = true;
 	  else if (!(OMP_CLAUSE_CODE (c) == OMP_CLAUSE_MAP
 		     && OMP_CLAUSE_MAP_KIND (c) == OMP_CLAUSE_MAP_POINTER)
+		   && !type_dependent_expression_p (t)
 		   && !cp_omp_mappable_type ((TREE_CODE (TREE_TYPE (t))
 					      == REFERENCE_TYPE)
 					     ? TREE_TYPE (TREE_TYPE (t))
@@ -8955,7 +8963,9 @@ cxx_eval_bare_aggregate (const constexpr_call *call, tree t,
 	  constructor_elt *inner = base_field_constructor_elt (n, ce->index);
 	  inner->value = elt;
 	}
-      else if (ce->index && TREE_CODE (ce->index) == NOP_EXPR)
+      else if (ce->index
+	       && (TREE_CODE (ce->index) == NOP_EXPR
+		   || TREE_CODE (ce->index) == POINTER_PLUS_EXPR))
 	{
 	  /* This is an initializer for an empty base; now that we've
 	     checked that it's constant, we can ignore it.  */
@@ -10178,6 +10188,11 @@ potential_constant_expression_1 (tree t, bool want_rval, tsubst_flags_t flags)
             designates an object with thread or automatic storage
             duration;  */
       t = TREE_OPERAND (t, 0);
+
+      if (TREE_CODE (t) == OFFSET_REF && PTRMEM_OK_P (t))
+	/* A pointer-to-member constant.  */
+	return true;
+
 #if 0
       /* FIXME adjust when issue 1197 is fully resolved.  For now don't do
          any checking here, as we might dereference the pointer later.  If
diff --git a/gcc/cp/tree.c b/gcc/cp/tree.c
index 622ba99..2820ba0 100644
--- a/gcc/cp/tree.c
+++ b/gcc/cp/tree.c
@@ -3795,6 +3795,10 @@ stabilize_expr (tree exp, tree* initp)
     {
       init_expr = get_target_expr (exp);
       exp = TARGET_EXPR_SLOT (init_expr);
+      if (CLASS_TYPE_P (TREE_TYPE (exp)))
+	exp = move (exp);
+      else
+	exp = rvalue (exp);
     }
   else
     {
diff --git a/gcc/cp/typeck2.c b/gcc/cp/typeck2.c
index 0bdad2a..f8af096 100644
--- a/gcc/cp/typeck2.c
+++ b/gcc/cp/typeck2.c
@@ -1237,8 +1237,9 @@ process_init_constructor_array (tree type, tree init,
 	  {
 	    /* If this type needs constructors run for default-initialization,
 	       we can't rely on the back end to do it for us, so make the
-	       initialization explicit by list-initializing from {}.  */
+	       initialization explicit by list-initializing from T{}.  */
 	    next = build_constructor (init_list_type_node, NULL);
+	    CONSTRUCTOR_IS_DIRECT_INIT (next) = true;
 	    next = massage_init_elt (TREE_TYPE (type), next, complain);
 	    if (initializer_zerop (next))
 	      /* The default zero-initialization is fine for us; don't
diff --git a/gcc/cse.c b/gcc/cse.c
index b8223f7..ec9aff4 100644
--- a/gcc/cse.c
+++ b/gcc/cse.c
@@ -2680,7 +2680,7 @@ exp_equiv_p (const_rtx x, const_rtx y, int validate, bool for_gcse)
 	     But because really all MEM attributes should be the same for
 	     equivalent MEMs, we just use the invariant that MEMs that have
 	     the same attributes share the same mem_attrs data structure.  */
-	  if (MEM_ATTRS (x) != MEM_ATTRS (y))
+	  if (!mem_attrs_eq_p (MEM_ATTRS (x), MEM_ATTRS (y)))
 	    return 0;
 	}
       break;
diff --git a/gcc/dwarf2out.c b/gcc/dwarf2out.c
index 13b2de7..d48895c 100644
--- a/gcc/dwarf2out.c
+++ b/gcc/dwarf2out.c
@@ -12561,7 +12561,7 @@ mem_loc_descriptor (rtx rtl, enum machine_mode mode,
 	      op1 = mem_loc_descriptor (XEXP (rtl, 1), mode, mem_mode,
 					VAR_INIT_STATUS_INITIALIZED);
 	      if (op1 == 0)
-		break;
+		return NULL;
 	      add_loc_descr (&mem_loc_result, op1);
 	      add_loc_descr (&mem_loc_result,
 			     new_loc_descr (DW_OP_plus, 0, 0));
@@ -14223,6 +14223,10 @@ loc_list_from_tree (tree loc, int want_address)
       have_address = 1;
       break;
 
+    case TARGET_MEM_REF:
+    case SSA_NAME:
+      return NULL;
+
     case COMPOUND_EXPR:
       return loc_list_from_tree (TREE_OPERAND (loc, 1), want_address);
 
diff --git a/gcc/emit-rtl.c b/gcc/emit-rtl.c
index 4736f8d..3041b9e 100644
--- a/gcc/emit-rtl.c
+++ b/gcc/emit-rtl.c
@@ -245,9 +245,13 @@ const_fixed_htab_eq (const void *x, const void *y)
 
 /* Return true if the given memory attributes are equal.  */
 
-static bool
+bool
 mem_attrs_eq_p (const struct mem_attrs *p, const struct mem_attrs *q)
 {
+  if (p == q)
+    return true;
+  if (!p || !q)
+    return false;
   return (p->alias == q->alias
 	  && p->offset_known_p == q->offset_known_p
 	  && (!p->offset_known_p || p->offset == q->offset)
diff --git a/gcc/emit-rtl.h b/gcc/emit-rtl.h
index fe68de9..36eb0c8 100644
--- a/gcc/emit-rtl.h
+++ b/gcc/emit-rtl.h
@@ -20,6 +20,9 @@ along with GCC; see the file COPYING3.  If not see
 #ifndef GCC_EMIT_RTL_H
 #define GCC_EMIT_RTL_H
 
+/* Return whether two MEM_ATTRs are equal.  */
+bool mem_attrs_eq_p (const struct mem_attrs *, const struct mem_attrs *);
+
 /* Set the alias set of MEM to SET.  */
 extern void set_mem_alias_set (rtx, alias_set_type);
 
diff --git a/gcc/expr.c b/gcc/expr.c
index 72e4401..bf14114 100644
--- a/gcc/expr.c
+++ b/gcc/expr.c
@@ -6605,7 +6605,7 @@ store_field (rtx target, HOST_WIDE_INT bitsize, HOST_WIDE_INT bitpos,
 	{
 	  HOST_WIDE_INT size = int_size_in_bytes (TREE_TYPE (exp));
 	  rtx temp_target;
-	  if (mode == BLKmode)
+	  if (mode == BLKmode || mode == VOIDmode)
 	    mode = smallest_mode_for_size (size * BITS_PER_UNIT, MODE_INT);
 	  temp_target = gen_reg_rtx (mode);
 	  emit_group_store (temp_target, temp, TREE_TYPE (exp), size);
@@ -10667,7 +10667,7 @@ is_aligning_offset (const_tree offset, const_tree exp)
       || !tree_fits_uhwi_p (TREE_OPERAND (offset, 1))
       || compare_tree_int (TREE_OPERAND (offset, 1),
 			   BIGGEST_ALIGNMENT / BITS_PER_UNIT) <= 0
-      || !exact_log2 (tree_to_uhwi (TREE_OPERAND (offset, 1)) + 1) < 0)
+      || exact_log2 (tree_to_uhwi (TREE_OPERAND (offset, 1)) + 1) < 0)
     return 0;
 
   /* Look at the first operand of BIT_AND_EXPR and strip any conversion.
diff --git a/gcc/gcc.c b/gcc/gcc.c
index 5cb485a..9c4c40c 100644
--- a/gcc/gcc.c
+++ b/gcc/gcc.c
@@ -576,15 +576,21 @@ proper position among the other output files.  */
 #ifndef LIBLSAN_SPEC
 #define STATIC_LIBLSAN_LIBS \
   " %{static-liblsan:%:include(libsanitizer.spec)%(link_liblsan)}"
-#ifdef HAVE_LD_STATIC_DYNAMIC
-#define LIBLSAN_SPEC "%{!shared:%{static-liblsan:" LD_STATIC_OPTION \
+#ifdef LIBLSAN_EARLY_SPEC
+#define LIBLSAN_SPEC STATIC_LIBLSAN_LIBS
+#elif defined(HAVE_LD_STATIC_DYNAMIC)
+#define LIBLSAN_SPEC "%{static-liblsan:" LD_STATIC_OPTION \
 		     "} -llsan %{static-liblsan:" LD_DYNAMIC_OPTION "}" \
-		     STATIC_LIBLSAN_LIBS "}"
+		     STATIC_LIBLSAN_LIBS
 #else
-#define LIBLSAN_SPEC "%{!shared:-llsan" STATIC_LIBLSAN_LIBS "}"
+#define LIBLSAN_SPEC "-llsan" STATIC_LIBLSAN_LIBS
 #endif
 #endif
 
+#ifndef LIBLSAN_EARLY_SPEC
+#define LIBLSAN_EARLY_SPEC ""
+#endif
+
 #ifndef LIBUBSAN_SPEC
 #define STATIC_LIBUBSAN_LIBS \
   " %{static-libubsan:%:include(libsanitizer.spec)%(link_libubsan)}"
@@ -720,7 +726,8 @@ proper position among the other output files.  */
 #ifndef SANITIZER_EARLY_SPEC
 #define SANITIZER_EARLY_SPEC "\
 %{!nostdlib:%{!nodefaultlibs:%{%:sanitize(address):" LIBASAN_EARLY_SPEC "} \
-    %{%:sanitize(thread):" LIBTSAN_EARLY_SPEC "}}}"
+    %{%:sanitize(thread):" LIBTSAN_EARLY_SPEC "} \
+    %{%:sanitize(leak):" LIBLSAN_EARLY_SPEC "}}}"
 #endif
 
 /* Linker command line options for -fsanitize= late on the command line.  */
diff --git a/gcc/gimple-fold.c b/gcc/gimple-fold.c
index 6402cce..2527d29 100644
--- a/gcc/gimple-fold.c
+++ b/gcc/gimple-fold.c
@@ -146,7 +146,8 @@ can_refer_decl_in_current_unit_p (tree decl, tree from_decl)
          The second is important when devirtualization happens during final
          compilation stage when making a new reference no longer makes callee
          to be compiled.  */
-      if (!node || !node->definition || node->global.inlined_to)
+      if (!node || !node->definition
+	  || DECL_EXTERNAL (decl) || node->global.inlined_to)
 	{
 	  gcc_checking_assert (!TREE_ASM_WRITTEN (decl));
 	  return false;
@@ -3104,8 +3105,8 @@ fold_ctor_reference (tree type, tree ctor, unsigned HOST_WIDE_INT offset,
      result.  */
   if (!AGGREGATE_TYPE_P (TREE_TYPE (ctor)) && !offset
       /* VIEW_CONVERT_EXPR is defined only for matching sizes.  */
-      && operand_equal_p (TYPE_SIZE (type),
-			  TYPE_SIZE (TREE_TYPE (ctor)), 0))
+      && !compare_tree_int (TYPE_SIZE (type), size)
+      && !compare_tree_int (TYPE_SIZE (TREE_TYPE (ctor)), size))
     {
       ret = canonicalize_constructor_val (unshare_expr (ctor), from_decl);
       ret = fold_unary (VIEW_CONVERT_EXPR, type, ret);
diff --git a/gcc/gimple.h b/gcc/gimple.h
index 11959a8..50a5a86 100644
--- a/gcc/gimple.h
+++ b/gcc/gimple.h
@@ -90,6 +90,7 @@ enum gf_mask {
     GF_CALL_NOTHROW		= 1 << 4,
     GF_CALL_ALLOCA_FOR_VAR	= 1 << 5,
     GF_CALL_INTERNAL		= 1 << 6,
+    GF_CALL_CTRL_ALTERING       = 1 << 7,
     GF_OMP_PARALLEL_COMBINED	= 1 << 0,
     GF_OMP_FOR_KIND_MASK	= 3 << 0,
     GF_OMP_FOR_KIND_FOR		= 0 << 0,
@@ -2447,6 +2448,29 @@ gimple_call_internal_fn (const_gimple gs)
   return static_cast <const gimple_statement_call *> (gs)->u.internal_fn;
 }
 
+/* If CTRL_ALTERING_P is true, mark GIMPLE_CALL S to be a stmt
+   that could alter control flow.  */
+
+static inline void
+gimple_call_set_ctrl_altering (gimple s, bool ctrl_altering_p)
+{
+  GIMPLE_CHECK (s, GIMPLE_CALL);
+  if (ctrl_altering_p)
+    s->subcode |= GF_CALL_CTRL_ALTERING;
+  else
+    s->subcode &= ~GF_CALL_CTRL_ALTERING;
+}
+
+/* Return true if call GS calls an func whose GF_CALL_CTRL_ALTERING
+   flag is set. Such call could not be a stmt in the middle of a bb.  */
+
+static inline bool
+gimple_call_ctrl_altering_p (const_gimple gs)
+{
+  GIMPLE_CHECK (gs, GIMPLE_CALL);
+  return (gs->subcode & GF_CALL_CTRL_ALTERING) != 0;
+}
+
 
 /* Return the function type of the function called by GS.  */
 
diff --git a/gcc/gimplify.c b/gcc/gimplify.c
index 4121bf3..89e7334 100644
--- a/gcc/gimplify.c
+++ b/gcc/gimplify.c
@@ -6263,7 +6263,7 @@ gimplify_adjust_omp_clauses_1 (splay_tree_node n, void *data)
 		= splay_tree_lookup (ctx->variables, (splay_tree_key) decl);
 	      if (on && (on->value & (GOVD_FIRSTPRIVATE | GOVD_LASTPRIVATE
 				      | GOVD_PRIVATE | GOVD_REDUCTION
-				      | GOVD_LINEAR)) != 0)
+				      | GOVD_LINEAR | GOVD_MAP)) != 0)
 		break;
 	      ctx = ctx->outer_context;
 	    }
diff --git a/gcc/haifa-sched.c b/gcc/haifa-sched.c
index 2d66e5c..e437e0a 100644
--- a/gcc/haifa-sched.c
+++ b/gcc/haifa-sched.c
@@ -2972,7 +2972,7 @@ advance_one_cycle (void)
 {
   advance_state (curr_state);
   if (sched_verbose >= 6)
-    fprintf (sched_dump, ";;\tAdvanced a state.\n");
+    fprintf (sched_dump, ";;\tAdvance the current state.\n");
 }
 
 /* Update register pressure after scheduling INSN.  */
@@ -6007,6 +6007,7 @@ schedule_block (basic_block *target_bb, state_t init_state)
   modulo_insns_scheduled = 0;
 
   ls.modulo_epilogue = false;
+  ls.first_cycle_insn_p = true;
 
   /* Loop until all the insns in BB are scheduled.  */
   while ((*current_sched_info->schedule_more_p) ())
@@ -6077,7 +6078,6 @@ schedule_block (basic_block *target_bb, state_t init_state)
       if (must_backtrack)
 	goto do_backtrack;
 
-      ls.first_cycle_insn_p = true;
       ls.shadows_only_p = false;
       cycle_issued_insns = 0;
       ls.can_issue_more = issue_rate;
@@ -6363,11 +6363,13 @@ schedule_block (basic_block *target_bb, state_t init_state)
 	      break;
 	    }
 	}
+      ls.first_cycle_insn_p = true;
     }
   if (ls.modulo_epilogue)
     success = true;
  end_schedule:
-  advance_one_cycle ();
+  if (!ls.first_cycle_insn_p || advance)
+    advance_one_cycle ();
   perform_replacements_new_cycle ();
   if (modulo_ii > 0)
     {
diff --git a/gcc/ifcvt.c b/gcc/ifcvt.c
index 0d1adce..2097de6 100644
--- a/gcc/ifcvt.c
+++ b/gcc/ifcvt.c
@@ -306,6 +306,28 @@ block_fallthru (basic_block bb)
 
   return (e) ? e->dest : NULL_BLOCK;
 }
+
+/* Return true if RTXs A and B can be safely interchanged.  */
+
+static bool
+rtx_interchangeable_p (const_rtx a, const_rtx b)
+{
+  if (!rtx_equal_p (a, b))
+    return false;
+
+  if (GET_CODE (a) != MEM)
+    return true;
+
+  /* A dead type-unsafe memory reference is legal, but a live type-unsafe memory
+     reference is not.  Interchanging a dead type-unsafe memory reference with
+     a live type-safe one creates a live type-unsafe memory reference, in other
+     words, it makes the program illegal.
+     We check here conservatively whether the two memory references have equal
+     memory attributes.  */
+
+  return mem_attrs_eq_p (get_mem_attrs (a), get_mem_attrs (b));
+}
+
 
 /* Go through a bunch of insns, converting them to conditional
    execution format if possible.  Return TRUE if all of the non-note
@@ -1034,6 +1056,9 @@ noce_try_move (struct noce_if_info *if_info)
       || (rtx_equal_p (if_info->a, XEXP (cond, 1))
 	  && rtx_equal_p (if_info->b, XEXP (cond, 0))))
     {
+      if (!rtx_interchangeable_p (if_info->a, if_info->b))
+	return FALSE;
+
       y = (code == EQ) ? if_info->a : if_info->b;
 
       /* Avoid generating the move if the source is the destination.  */
@@ -2504,7 +2529,7 @@ noce_process_if_block (struct noce_if_info *if_info)
       if (! insn_b
 	  || insn_b != last_active_insn (else_bb, FALSE)
 	  || (set_b = single_set (insn_b)) == NULL_RTX
-	  || ! rtx_equal_p (x, SET_DEST (set_b)))
+	  || ! rtx_interchangeable_p (x, SET_DEST (set_b)))
 	return FALSE;
     }
   else
@@ -2517,7 +2542,7 @@ noce_process_if_block (struct noce_if_info *if_info)
 	  || BLOCK_FOR_INSN (insn_b) != BLOCK_FOR_INSN (if_info->cond_earliest)
 	  || !NONJUMP_INSN_P (insn_b)
 	  || (set_b = single_set (insn_b)) == NULL_RTX
-	  || ! rtx_equal_p (x, SET_DEST (set_b))
+	  || ! rtx_interchangeable_p (x, SET_DEST (set_b))
 	  || ! noce_operand_ok (SET_SRC (set_b))
 	  || reg_overlap_mentioned_p (x, SET_SRC (set_b))
 	  || modified_between_p (SET_SRC (set_b), insn_b, jump)
@@ -2583,7 +2608,7 @@ noce_process_if_block (struct noce_if_info *if_info)
 
   /* Look and see if A and B are really the same.  Avoid creating silly
      cmove constructs that no one will fix up later.  */
-  if (rtx_equal_p (a, b))
+  if (rtx_interchangeable_p (a, b))
     {
       /* If we have an INSN_B, we don't have to create any new rtl.  Just
 	 move the instruction that we already have.  If we don't have an
@@ -4312,6 +4337,9 @@ dead_or_predicable (basic_block test_bb, basic_block merge_bb,
   old_dest = JUMP_LABEL (jump);
   if (other_bb != new_dest)
     {
+      if (!any_condjump_p (jump))
+	goto cancel;
+
       if (JUMP_P (BB_END (dest_edge->src)))
 	new_dest_label = JUMP_LABEL (BB_END (dest_edge->src));
       else if (new_dest == EXIT_BLOCK_PTR_FOR_FN (cfun))
@@ -4362,17 +4390,14 @@ dead_or_predicable (basic_block test_bb, basic_block merge_bb,
       insn = head;
       do
 	{
-	  rtx note, set;
+	  rtx note;
 
 	  if (! INSN_P (insn))
 	    continue;
 	  note = find_reg_note (insn, REG_EQUAL, NULL_RTX);
 	  if (! note)
 	    continue;
-	  set = single_set (insn);
-	  if (!set || !function_invariant_p (SET_SRC (set))
-	      || !function_invariant_p (XEXP (note, 0)))
-	    remove_note (insn, note);
+	  remove_note (insn, note);
 	} while (insn != end && (insn = NEXT_INSN (insn)));
 
       /* PR46315: when moving insns above a conditional branch, the REG_EQUAL
diff --git a/gcc/ipa-cp.c b/gcc/ipa-cp.c
index 52d37fb..a6818ba 100644
--- a/gcc/ipa-cp.c
+++ b/gcc/ipa-cp.c
@@ -3032,6 +3032,11 @@ intersect_aggregates_with_edge (struct cgraph_edge *cs, int index,
 		intersect_with_agg_replacements (cs->caller, src_idx,
 						 &inter, 0);
 	    }
+	  else
+	    {
+	      inter.release ();
+	      return vNULL;
+	    }
 	}
       else
 	{
@@ -3047,6 +3052,11 @@ intersect_aggregates_with_edge (struct cgraph_edge *cs, int index,
 	      else
 		intersect_with_plats (src_plats, &inter, 0);
 	    }
+	  else
+	    {
+	      inter.release ();
+	      return vNULL;
+	    }
 	}
     }
   else if (jfunc->type == IPA_JF_ANCESTOR
@@ -3130,7 +3140,8 @@ find_aggregate_values_for_callers_subset (struct cgraph_node *node,
 					  vec<cgraph_edge_p> callers)
 {
   struct ipa_node_params *dest_info = IPA_NODE_REF (node);
-  struct ipa_agg_replacement_value *res = NULL;
+  struct ipa_agg_replacement_value *res;
+  struct ipa_agg_replacement_value **tail = &res;
   struct cgraph_edge *cs;
   int i, j, count = ipa_get_param_count (dest_info);
 
@@ -3174,14 +3185,15 @@ find_aggregate_values_for_callers_subset (struct cgraph_node *node,
 	  v->offset = item->offset;
 	  v->value = item->value;
 	  v->by_ref = plats->aggs_by_ref;
-	  v->next = res;
-	  res = v;
+	  *tail = v;
+	  tail = &v->next;
 	}
 
     next_param:
       if (inter.exists ())
 	inter.release ();
     }
+  *tail = NULL;
   return res;
 }
 
@@ -3190,7 +3202,8 @@ find_aggregate_values_for_callers_subset (struct cgraph_node *node,
 static struct ipa_agg_replacement_value *
 known_aggs_to_agg_replacement_list (vec<ipa_agg_jump_function> known_aggs)
 {
-  struct ipa_agg_replacement_value *res = NULL;
+  struct ipa_agg_replacement_value *res;
+  struct ipa_agg_replacement_value **tail = &res;
   struct ipa_agg_jump_function *aggjf;
   struct ipa_agg_jf_item *item;
   int i, j;
@@ -3204,9 +3217,10 @@ known_aggs_to_agg_replacement_list (vec<ipa_agg_jump_function> known_aggs)
 	v->offset = item->offset;
 	v->value = item->value;
 	v->by_ref = aggjf->by_ref;
-	v->next = res;
-	res = v;
+	*tail = v;
+	tail = &v->next;
       }
+  *tail = NULL;
   return res;
 }
 
diff --git a/gcc/ipa-devirt.c b/gcc/ipa-devirt.c
index 0671a8b..f1c36aa 100644
--- a/gcc/ipa-devirt.c
+++ b/gcc/ipa-devirt.c
@@ -1869,8 +1869,7 @@ ipa_devirt (void)
 	    /* Don't use an implicitly-declared destructor (c++/58678).  */
 	    struct cgraph_node *non_thunk_target
 	      = cgraph_function_node (likely_target);
-	    if (DECL_ARTIFICIAL (non_thunk_target->decl)
-		&& DECL_COMDAT (non_thunk_target->decl))
+	    if (DECL_ARTIFICIAL (non_thunk_target->decl))
 	      {
 		if (dump_file)
 		  fprintf (dump_file, "Target is artificial\n\n");
diff --git a/gcc/ipa-split.c b/gcc/ipa-split.c
index 38bd883..0d1495d 100644
--- a/gcc/ipa-split.c
+++ b/gcc/ipa-split.c
@@ -167,7 +167,11 @@ test_nonssa_use (gimple, tree t, tree, void *data)
       || (TREE_CODE (t) == VAR_DECL
 	  && auto_var_in_fn_p (t, current_function_decl))
       || TREE_CODE (t) == RESULT_DECL
-      || TREE_CODE (t) == LABEL_DECL)
+	 /* Normal labels are part of CFG and will be handled gratefuly.
+	    Forced labels however can be used directly by statements and
+	    need to stay in one partition along with their uses.  */
+      || (TREE_CODE (t) == LABEL_DECL
+	  && FORCED_LABEL (t)))
     return bitmap_bit_p ((bitmap)data, DECL_UID (t));
 
   /* For DECL_BY_REFERENCE, the return value is actually a pointer.  We want
@@ -213,6 +217,7 @@ verify_non_ssa_vars (struct split_point *current, bitmap non_ssa_vars,
   edge e;
   edge_iterator ei;
   bool ok = true;
+  basic_block bb;
 
   FOR_EACH_EDGE (e, ei, current->entry_bb->preds)
     if (e->src != ENTRY_BLOCK_PTR_FOR_FN (cfun)
@@ -225,8 +230,8 @@ verify_non_ssa_vars (struct split_point *current, bitmap non_ssa_vars,
   while (!worklist.is_empty ())
     {
       gimple_stmt_iterator bsi;
-      basic_block bb = worklist.pop ();
 
+      bb = worklist.pop ();
       FOR_EACH_EDGE (e, ei, bb->preds)
 	if (e->src != ENTRY_BLOCK_PTR_FOR_FN (cfun)
 	    && bitmap_set_bit (seen, e->src->index))
@@ -250,10 +255,10 @@ verify_non_ssa_vars (struct split_point *current, bitmap non_ssa_vars,
 	  if (gimple_code (stmt) == GIMPLE_LABEL
 	      && test_nonssa_use (stmt, gimple_label_label (stmt),
 				  NULL_TREE, non_ssa_vars))
-	  {
-	    ok = false;
-	    goto done;
-	  }
+	    {
+	      ok = false;
+	      goto done;
+	    }
 	}
       for (bsi = gsi_start_phis (bb); !gsi_end_p (bsi); gsi_next (&bsi))
 	{
@@ -286,6 +291,27 @@ verify_non_ssa_vars (struct split_point *current, bitmap non_ssa_vars,
 	    }
 	}
     }
+
+  /* Verify that the rest of function does not define any label
+     used by the split part.  */
+  FOR_EACH_BB_FN (bb, cfun)
+    if (!bitmap_bit_p (current->split_bbs, bb->index)
+	&& !bitmap_bit_p (seen, bb->index))
+      {
+        gimple_stmt_iterator bsi;
+        for (bsi = gsi_start_bb (bb); !gsi_end_p (bsi); gsi_next (&bsi))
+	  if (gimple_code (gsi_stmt (bsi)) == GIMPLE_LABEL
+	      && test_nonssa_use (gsi_stmt (bsi),
+				  gimple_label_label (gsi_stmt (bsi)),
+				  NULL_TREE, non_ssa_vars))
+	    {
+	      ok = false;
+	      goto done;
+	    }
+	  else if (gimple_code (gsi_stmt (bsi)) != GIMPLE_LABEL)
+	    break;
+      }
+    
 done:
   BITMAP_FREE (seen);
   worklist.release ();
@@ -734,7 +760,8 @@ mark_nonssa_use (gimple, tree t, tree, void *data)
   if ((TREE_CODE (t) == VAR_DECL
        && auto_var_in_fn_p (t, current_function_decl))
       || TREE_CODE (t) == RESULT_DECL
-      || TREE_CODE (t) == LABEL_DECL)
+      || (TREE_CODE (t) == LABEL_DECL
+	  && FORCED_LABEL (t)))
     bitmap_set_bit ((bitmap)data, DECL_UID (t));
 
   /* For DECL_BY_REFERENCE, the return value is actually a pointer.  We want
diff --git a/gcc/lra-constraints.c b/gcc/lra-constraints.c
index 3970081..3691ab8 100644
--- a/gcc/lra-constraints.c
+++ b/gcc/lra-constraints.c
@@ -5752,6 +5752,20 @@ remove_inheritance_pseudos (bitmap remove_pseudos)
 			SUBREG_REG (SET_SRC (set)) = SET_SRC (prev_set);
 		      else
 			SET_SRC (set) = SET_SRC (prev_set);
+		      /* As we are finishing with processing the insn
+			 here, check the destination too as it might
+			 inheritance pseudo for another pseudo.  */
+		      if (bitmap_bit_p (remove_pseudos, dregno)
+			  && bitmap_bit_p (&lra_inheritance_pseudos, dregno)
+			  && (restore_regno
+			      = lra_reg_info[dregno].restore_regno) >= 0)
+			{
+			  if (GET_CODE (SET_DEST (set)) == SUBREG)
+			    SUBREG_REG (SET_DEST (set))
+			      = regno_reg_rtx[restore_regno];
+			  else
+			    SET_DEST (set) = regno_reg_rtx[restore_regno];
+			}
 		      lra_push_insn_and_update_insn_regno_info (curr_insn);
 		      lra_set_used_insn_alternative_by_uid
 			(INSN_UID (curr_insn), -1);
diff --git a/gcc/lto/lto-lang.c b/gcc/lto/lto-lang.c
index f60d212..1a4da91 100644
--- a/gcc/lto/lto-lang.c
+++ b/gcc/lto/lto-lang.c
@@ -1186,10 +1186,10 @@ lto_init (void)
     }
   else
     {
-      lto_define_builtins (va_list_type_node,
-			   build_reference_type (va_list_type_node));
+      lto_define_builtins (build_reference_type (va_list_type_node),
+			   va_list_type_node);
     }
-  
+
   if (flag_cilkplus)
     cilk_init_builtins ();
 
diff --git a/gcc/omp-low.c b/gcc/omp-low.c
index a605c45..f77df897 100644
--- a/gcc/omp-low.c
+++ b/gcc/omp-low.c
@@ -204,6 +204,7 @@ static int taskreg_nesting_level;
 static int target_nesting_level;
 static struct omp_region *root_omp_region;
 static bitmap task_shared_vars;
+static vec<omp_context *> taskreg_contexts;
 
 static void scan_omp (gimple_seq *, omp_context *);
 static tree scan_omp_1_op (tree *, int *, void *);
@@ -1872,7 +1873,6 @@ create_omp_child_function (omp_context *ctx, bool task_copy)
   TREE_STATIC (decl) = 1;
   TREE_USED (decl) = 1;
   DECL_ARTIFICIAL (decl) = 1;
-  DECL_NAMELESS (decl) = 1;
   DECL_IGNORED_P (decl) = 0;
   TREE_PUBLIC (decl) = 0;
   DECL_UNINLINABLE (decl) = 1;
@@ -2025,6 +2025,7 @@ scan_omp_parallel (gimple_stmt_iterator *gsi, omp_context *outer_ctx)
     }
 
   ctx = new_omp_context (stmt, outer_ctx);
+  taskreg_contexts.safe_push (ctx);
   if (taskreg_nesting_level > 1)
     ctx->is_nested = true;
   ctx->field_map = splay_tree_new (splay_tree_compare_pointers, 0, 0);
@@ -2044,11 +2045,6 @@ scan_omp_parallel (gimple_stmt_iterator *gsi, omp_context *outer_ctx)
 
   if (TYPE_FIELDS (ctx->record_type) == NULL)
     ctx->record_type = ctx->receiver_decl = NULL;
-  else
-    {
-      layout_type (ctx->record_type);
-      fixup_child_record_type (ctx);
-    }
 }
 
 /* Scan an OpenMP task directive.  */
@@ -2059,7 +2055,6 @@ scan_omp_task (gimple_stmt_iterator *gsi, omp_context *outer_ctx)
   omp_context *ctx;
   tree name, t;
   gimple stmt = gsi_stmt (*gsi);
-  location_t loc = gimple_location (stmt);
 
   /* Ignore task directives with empty bodies.  */
   if (optimize > 0
@@ -2070,6 +2065,7 @@ scan_omp_task (gimple_stmt_iterator *gsi, omp_context *outer_ctx)
     }
 
   ctx = new_omp_context (stmt, outer_ctx);
+  taskreg_contexts.safe_push (ctx);
   if (taskreg_nesting_level > 1)
     ctx->is_nested = true;
   ctx->field_map = splay_tree_new (splay_tree_compare_pointers, 0, 0);
@@ -2107,8 +2103,71 @@ scan_omp_task (gimple_stmt_iterator *gsi, omp_context *outer_ctx)
       t = build_int_cst (long_integer_type_node, 1);
       gimple_omp_task_set_arg_align (stmt, t);
     }
+}
+
+
+/* If any decls have been made addressable during scan_omp,
+   adjust their fields if needed, and layout record types
+   of parallel/task constructs.  */
+
+static void
+finish_taskreg_scan (omp_context *ctx)
+{
+  if (ctx->record_type == NULL_TREE)
+    return;
+
+  /* If any task_shared_vars were needed, verify all
+     OMP_CLAUSE_SHARED clauses on GIMPLE_OMP_{PARALLEL,TASK}
+     statements if use_pointer_for_field hasn't changed
+     because of that.  If it did, update field types now.  */
+  if (task_shared_vars)
+    {
+      tree c;
+
+      for (c = gimple_omp_taskreg_clauses (ctx->stmt);
+	   c; c = OMP_CLAUSE_CHAIN (c))
+	if (OMP_CLAUSE_CODE (c) == OMP_CLAUSE_SHARED)
+	  {
+	    tree decl = OMP_CLAUSE_DECL (c);
+
+	    /* Global variables don't need to be copied,
+	       the receiver side will use them directly.  */
+	    if (is_global_var (maybe_lookup_decl_in_outer_ctx (decl, ctx)))
+	      continue;
+	    if (!bitmap_bit_p (task_shared_vars, DECL_UID (decl))
+		|| !use_pointer_for_field (decl, ctx))
+	      continue;
+	    tree field = lookup_field (decl, ctx);
+	    if (TREE_CODE (TREE_TYPE (field)) == POINTER_TYPE
+		&& TREE_TYPE (TREE_TYPE (field)) == TREE_TYPE (decl))
+	      continue;
+	    TREE_TYPE (field) = build_pointer_type (TREE_TYPE (decl));
+	    TREE_THIS_VOLATILE (field) = 0;
+	    DECL_USER_ALIGN (field) = 0;
+	    DECL_ALIGN (field) = TYPE_ALIGN (TREE_TYPE (field));
+	    if (TYPE_ALIGN (ctx->record_type) < DECL_ALIGN (field))
+	      TYPE_ALIGN (ctx->record_type) = DECL_ALIGN (field);
+	    if (ctx->srecord_type)
+	      {
+		tree sfield = lookup_sfield (decl, ctx);
+		TREE_TYPE (sfield) = TREE_TYPE (field);
+		TREE_THIS_VOLATILE (sfield) = 0;
+		DECL_USER_ALIGN (sfield) = 0;
+		DECL_ALIGN (sfield) = DECL_ALIGN (field);
+		if (TYPE_ALIGN (ctx->srecord_type) < DECL_ALIGN (sfield))
+		  TYPE_ALIGN (ctx->srecord_type) = DECL_ALIGN (sfield);
+	      }
+	  }
+    }
+
+  if (gimple_code (ctx->stmt) == GIMPLE_OMP_PARALLEL)
+    {
+      layout_type (ctx->record_type);
+      fixup_child_record_type (ctx);
+    }
   else
     {
+      location_t loc = gimple_location (ctx->stmt);
       tree *p, vla_fields = NULL_TREE, *q = &vla_fields;
       /* Move VLA fields to the end.  */
       p = &TYPE_FIELDS (ctx->record_type);
@@ -2128,12 +2187,12 @@ scan_omp_task (gimple_stmt_iterator *gsi, omp_context *outer_ctx)
       fixup_child_record_type (ctx);
       if (ctx->srecord_type)
 	layout_type (ctx->srecord_type);
-      t = fold_convert_loc (loc, long_integer_type_node,
-			TYPE_SIZE_UNIT (ctx->record_type));
-      gimple_omp_task_set_arg_size (stmt, t);
+      tree t = fold_convert_loc (loc, long_integer_type_node,
+				 TYPE_SIZE_UNIT (ctx->record_type));
+      gimple_omp_task_set_arg_size (ctx->stmt, t);
       t = build_int_cst (long_integer_type_node,
 			 TYPE_ALIGN_UNIT (ctx->record_type));
-      gimple_omp_task_set_arg_align (stmt, t);
+      gimple_omp_task_set_arg_align (ctx->stmt, t);
     }
 }
 
@@ -9828,6 +9887,9 @@ lower_omp_target (gimple_stmt_iterator *gsi_p, omp_context *ctx)
 		  continue;
 	      }
 
+	    unsigned int talign = TYPE_ALIGN_UNIT (TREE_TYPE (ovar));
+	    if (DECL_P (ovar) && DECL_ALIGN_UNIT (ovar) > talign)
+	      talign = DECL_ALIGN_UNIT (ovar);
 	    if (nc)
 	      {
 		tree var = lookup_decl_in_outer_ctx (ovar, ctx);
@@ -9842,6 +9904,7 @@ lower_omp_target (gimple_stmt_iterator *gsi_p, omp_context *ctx)
 		      = create_tmp_var (TREE_TYPE (TREE_TYPE (x)), NULL);
 		    mark_addressable (avar);
 		    gimplify_assign (avar, build_fold_addr_expr (var), &ilist);
+		    talign = DECL_ALIGN_UNIT (avar);
 		    avar = build_fold_addr_expr (avar);
 		    gimplify_assign (x, avar, &ilist);
 		  }
@@ -9894,9 +9957,6 @@ lower_omp_target (gimple_stmt_iterator *gsi_p, omp_context *ctx)
 	      default:
 		gcc_unreachable ();
 	      }
-	    unsigned int talign = TYPE_ALIGN_UNIT (TREE_TYPE (ovar));
-	    if (DECL_P (ovar) && DECL_ALIGN_UNIT (ovar) > talign)
-	      talign = DECL_ALIGN_UNIT (ovar);
 	    talign = ceil_log2 (talign);
 	    tkind |= talign << 3;
 	    CONSTRUCTOR_APPEND_ELT (vkind, purpose,
@@ -10270,6 +10330,8 @@ static unsigned int
 execute_lower_omp (void)
 {
   gimple_seq body;
+  int i;
+  omp_context *ctx;
 
   /* This pass always runs, to provide PROP_gimple_lomp.
      But there is nothing to do unless -fopenmp is given.  */
@@ -10282,6 +10344,9 @@ execute_lower_omp (void)
   body = gimple_body (current_function_decl);
   scan_omp (&body, NULL);
   gcc_assert (taskreg_nesting_level == 0);
+  FOR_EACH_VEC_ELT (taskreg_contexts, i, ctx)
+    finish_taskreg_scan (ctx);
+  taskreg_contexts.release ();
 
   if (all_contexts->root)
     {
@@ -11437,9 +11502,22 @@ ipa_simd_modify_stmt_ops (tree *tp, int *walk_subtrees, void *data)
   if (tp != orig_tp)
     {
       repl = build_fold_addr_expr (repl);
-      gimple stmt
-	= gimple_build_assign (make_ssa_name (TREE_TYPE (repl), NULL), repl);
-      repl = gimple_assign_lhs (stmt);
+      gimple stmt;
+      if (is_gimple_debug (info->stmt))
+	{
+	  tree vexpr = make_node (DEBUG_EXPR_DECL);
+	  stmt = gimple_build_debug_source_bind (vexpr, repl, NULL);
+	  DECL_ARTIFICIAL (vexpr) = 1;
+	  TREE_TYPE (vexpr) = TREE_TYPE (repl);
+	  DECL_MODE (vexpr) = TYPE_MODE (TREE_TYPE (repl));
+	  repl = vexpr;
+	}
+      else
+	{
+	  stmt = gimple_build_assign (make_ssa_name (TREE_TYPE (repl),
+						     NULL), repl);
+	  repl = gimple_assign_lhs (stmt);
+	}
       gimple_stmt_iterator gsi = gsi_for_stmt (info->stmt);
       gsi_insert_before (&gsi, stmt, GSI_SAME_STMT);
       *orig_tp = repl;
diff --git a/gcc/optabs.c b/gcc/optabs.c
index 54f07ab..5359257 100644
--- a/gcc/optabs.c
+++ b/gcc/optabs.c
@@ -7334,7 +7334,10 @@ expand_atomic_test_and_set (rtx target, rtx mem, enum memmodel model)
      perform the operation.  */
   if (!ret)
     {
-      emit_move_insn (subtarget, mem);
+      /* If the result is ignored skip the move to target.  */
+      if (subtarget != const0_rtx)
+        emit_move_insn (subtarget, mem);
+
       emit_move_insn (mem, trueval);
       ret = subtarget;
     }
diff --git a/gcc/recog.c b/gcc/recog.c
index f2647e3..0481d7d 100644
--- a/gcc/recog.c
+++ b/gcc/recog.c
@@ -3659,6 +3659,8 @@ peephole2_optimize (void)
   BITMAP_FREE (live);
   if (peep2_do_rebuild_jump_labels)
     rebuild_jump_labels (get_insns ());
+  if (peep2_do_cleanup_cfg)
+    cleanup_cfg (CLEANUP_CFG_CHANGED);
 }
 #endif /* HAVE_peephole2 */
 
diff --git a/gcc/sched-deps.c b/gcc/sched-deps.c
index efc4223..dc87187 100644
--- a/gcc/sched-deps.c
+++ b/gcc/sched-deps.c
@@ -1233,6 +1233,13 @@ add_or_update_dep_1 (dep_t new_dep, bool resolved_p,
       switch (ask_dependency_caches (new_dep))
 	{
 	case DEP_PRESENT:
+	  dep_t present_dep;
+	  sd_iterator_def sd_it;
+      
+	  present_dep = sd_find_dep_between_no_cache (DEP_PRO (new_dep),
+						      DEP_CON (new_dep),
+						      resolved_p, &sd_it);
+	  DEP_MULTIPLE (present_dep) = 1;
 	  return DEP_PRESENT;
 
 	case DEP_CHANGED:
@@ -2750,7 +2757,8 @@ sched_analyze_2 (struct deps_desc *deps, rtx x, rtx insn)
 	   Consider for instance a volatile asm that changes the fpu rounding
 	   mode.  An insn should not be moved across this even if it only uses
 	   pseudo-regs because it might give an incorrectly rounded result.  */
-	if (code != ASM_OPERANDS || MEM_VOLATILE_P (x))
+	if ((code != ASM_OPERANDS || MEM_VOLATILE_P (x))
+	    && !DEBUG_INSN_P (insn))
 	  reg_pending_barrier = TRUE_BARRIER;
 
 	/* For all ASM_OPERANDS, we must traverse the vector of input operands.
diff --git a/gcc/toplev.c b/gcc/toplev.c
index 0f7d452..d646faf 100644
--- a/gcc/toplev.c
+++ b/gcc/toplev.c
@@ -1052,16 +1052,19 @@ output_stack_usage (void)
 
   if (warn_stack_usage >= 0)
     {
+      const location_t loc = DECL_SOURCE_LOCATION (current_function_decl);
+
       if (stack_usage_kind == DYNAMIC)
-	warning (OPT_Wstack_usage_, "stack usage might be unbounded");
+	warning_at (loc, OPT_Wstack_usage_, "stack usage might be unbounded");
       else if (stack_usage > warn_stack_usage)
 	{
 	  if (stack_usage_kind == DYNAMIC_BOUNDED)
-	    warning (OPT_Wstack_usage_, "stack usage might be %wd bytes",
-		     stack_usage);
+	    warning_at (loc,
+			OPT_Wstack_usage_, "stack usage might be %wd bytes",
+			stack_usage);
 	  else
-	    warning (OPT_Wstack_usage_, "stack usage is %wd bytes",
-		     stack_usage);
+	    warning_at (loc, OPT_Wstack_usage_, "stack usage is %wd bytes",
+			stack_usage);
 	}
     }
 }
diff --git a/gcc/tree-cfg.c b/gcc/tree-cfg.c
index 56b6c35..1469d78 100644
--- a/gcc/tree-cfg.c
+++ b/gcc/tree-cfg.c
@@ -162,6 +162,7 @@ static int gimple_verify_flow_info (void);
 static void gimple_make_forwarder_block (edge);
 static gimple first_non_label_stmt (basic_block);
 static bool verify_gimple_transaction (gimple);
+static bool call_can_make_abnormal_goto (gimple);
 
 /* Flowgraph optimization and cleanup.  */
 static void gimple_merge_blocks (basic_block, basic_block);
@@ -424,6 +425,32 @@ assert_unreachable_fallthru_edge_p (edge e)
 }
 
 
+/* Initialize GF_CALL_CTRL_ALTERING flag, which indicates the call
+   could alter control flow except via eh. We initialize the flag at
+   CFG build time and only ever clear it later.  */
+
+static void
+gimple_call_initialize_ctrl_altering (gimple stmt)
+{
+  int flags = gimple_call_flags (stmt);
+
+  /* A call alters control flow if it can make an abnormal goto.  */
+  if (call_can_make_abnormal_goto (stmt)
+      /* A call also alters control flow if it does not return.  */
+      || flags & ECF_NORETURN
+      /* TM ending statements have backedges out of the transaction.
+	 Return true so we split the basic block containing them.
+	 Note that the TM_BUILTIN test is merely an optimization.  */
+      || ((flags & ECF_TM_BUILTIN)
+	  && is_tm_ending_fndecl (gimple_call_fndecl (stmt)))
+      /* BUILT_IN_RETURN call is same as return statement.  */
+      || gimple_call_builtin_p (stmt, BUILT_IN_RETURN))
+    gimple_call_set_ctrl_altering (stmt, true);
+  else
+    gimple_call_set_ctrl_altering (stmt, false);
+}
+
+
 /* Build a flowgraph for the sequence of stmts SEQ.  */
 
 static void
@@ -442,6 +469,9 @@ make_blocks (gimple_seq seq)
       prev_stmt = stmt;
       stmt = gsi_stmt (i);
 
+      if (stmt && is_gimple_call (stmt))
+	gimple_call_initialize_ctrl_altering (stmt);
+
       /* If the statement starts a new basic block or if we have determined
 	 in a previous pass that we need to create a new block for STMT, do
 	 so now.  */
@@ -2349,28 +2379,10 @@ is_ctrl_altering_stmt (gimple t)
   switch (gimple_code (t))
     {
     case GIMPLE_CALL:
-      {
-	int flags = gimple_call_flags (t);
-
-	/* A call alters control flow if it can make an abnormal goto.  */
-	if (call_can_make_abnormal_goto (t))
-	  return true;
-
-	/* A call also alters control flow if it does not return.  */
-	if (flags & ECF_NORETURN)
-	  return true;
-
-	/* TM ending statements have backedges out of the transaction.
-	   Return true so we split the basic block containing them.
-	   Note that the TM_BUILTIN test is merely an optimization.  */
-	if ((flags & ECF_TM_BUILTIN)
-	    && is_tm_ending_fndecl (gimple_call_fndecl (t)))
-	  return true;
-
-	/* BUILT_IN_RETURN call is same as return statement.  */
-	if (gimple_call_builtin_p (t, BUILT_IN_RETURN))
-	  return true;
-      }
+      /* Per stmt call flag indicates whether the call could alter
+	 controlflow.  */
+      if (gimple_call_ctrl_altering_p (t))
+	return true;
       break;
 
     case GIMPLE_EH_DISPATCH:
@@ -8470,6 +8482,8 @@ execute_fixup_cfg (void)
 		  && (!is_gimple_call (stmt)
 		      || (gimple_call_flags (stmt) & ECF_NORETURN) == 0)))
 	    {
+	      if (stmt && is_gimple_call (stmt))
+		gimple_call_set_ctrl_altering (stmt, false);
 	      stmt = gimple_build_call
 		  (builtin_decl_implicit (BUILT_IN_UNREACHABLE), 0);
 	      gimple_stmt_iterator gsi = gsi_last_bb (bb);
@@ -8480,10 +8494,6 @@ execute_fixup_cfg (void)
   if (count_scale != REG_BR_PROB_BASE)
     compute_function_frequency ();
 
-  /* We just processed all calls.  */
-  if (cfun->gimple_df)
-    vec_free (MODIFIED_NORETURN_CALLS (cfun));
-
   /* Dump a textual representation of the flowgraph.  */
   if (dump_file)
     gimple_dump_cfg (dump_file, dump_flags);
diff --git a/gcc/tree-cfgcleanup.c b/gcc/tree-cfgcleanup.c
index b7882cf..439f273 100644
--- a/gcc/tree-cfgcleanup.c
+++ b/gcc/tree-cfgcleanup.c
@@ -162,6 +162,23 @@ cleanup_control_expr_graph (basic_block bb, gimple_stmt_iterator gsi)
   return retval;
 }
 
+/* Cleanup the GF_CALL_CTRL_ALTERING flag according to
+   to updated gimple_call_flags.  */
+
+static void
+cleanup_call_ctrl_altering_flag (gimple bb_end)
+{
+  if (!is_gimple_call (bb_end)
+      || !gimple_call_ctrl_altering_p (bb_end))
+    return;
+
+  int flags = gimple_call_flags (bb_end);
+  if (((flags & (ECF_CONST | ECF_PURE))
+       && !(flags & ECF_LOOPING_CONST_OR_PURE))
+      || (flags & ECF_LEAF))
+    gimple_call_set_ctrl_altering (bb_end, false);
+}
+
 /* Try to remove superfluous control structures in basic block BB.  Returns
    true if anything changes.  */
 
@@ -182,6 +199,9 @@ cleanup_control_flow_bb (basic_block bb)
 
   stmt = gsi_stmt (gsi);
 
+  /* Try to cleanup ctrl altering flag for call which ends bb.  */
+  cleanup_call_ctrl_altering_flag (stmt);
+
   if (gimple_code (stmt) == GIMPLE_COND
       || gimple_code (stmt) == GIMPLE_SWITCH)
     retval |= cleanup_control_expr_graph (bb, gsi);
@@ -545,7 +565,20 @@ fixup_noreturn_call (gimple stmt)
 
   /* First split basic block if stmt is not last.  */
   if (stmt != gsi_stmt (gsi_last_bb (bb)))
-    split_block (bb, stmt);
+    {
+      if (stmt == gsi_stmt (gsi_last_nondebug_bb (bb)))
+	{
+	  /* Don't split if there are only debug stmts
+	     after stmt, that can result in -fcompare-debug
+	     failures.  Remove the debug stmts instead,
+	     they should be all unreachable anyway.  */
+	  gimple_stmt_iterator gsi = gsi_for_stmt (stmt);
+	  for (gsi_next (&gsi); !gsi_end_p (gsi); )
+	    gsi_remove (&gsi, true);
+	}
+      else
+	split_block (bb, stmt);
+    }
 
   changed |= remove_fallthru_edge (bb->succs);
 
@@ -594,30 +627,24 @@ fixup_noreturn_call (gimple stmt)
    known not to return, and remove the unreachable code.  */
 
 static bool
-split_bbs_on_noreturn_calls (void)
+split_bb_on_noreturn_calls (basic_block bb)
 {
   bool changed = false;
-  gimple stmt;
-  basic_block bb;
+  gimple_stmt_iterator gsi;
 
-  /* Detect cases where a mid-block call is now known not to return.  */
-  if (cfun->gimple_df)
-    while (vec_safe_length (MODIFIED_NORETURN_CALLS (cfun)))
-      {
-	stmt = MODIFIED_NORETURN_CALLS (cfun)->pop ();
-	bb = gimple_bb (stmt);
-	/* BB might be deleted at this point, so verify first
-	   BB is present in the cfg.  */
-	if (bb == NULL
-	    || bb->index < NUM_FIXED_BLOCKS
-	    || bb->index >= last_basic_block_for_fn (cfun)
-	    || BASIC_BLOCK_FOR_FN (cfun, bb->index) != bb
-	    || !gimple_call_noreturn_p (stmt))
-	  continue;
+  for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&gsi))
+    {
+      gimple stmt = gsi_stmt (gsi);
+
+      if (!is_gimple_call (stmt))
+	continue;
 
+      if (gimple_call_noreturn_p (stmt))
 	changed |= fixup_noreturn_call (stmt);
-      }
+    }
 
+  if (changed)
+    bitmap_set_bit (cfgcleanup_altered_bbs, bb->index);
   return changed;
 }
 
@@ -655,8 +682,6 @@ cleanup_tree_cfg_1 (void)
   basic_block bb;
   unsigned i, n;
 
-  retval |= split_bbs_on_noreturn_calls ();
-
   /* Prepare the worklists of altered blocks.  */
   cfgcleanup_altered_bbs = BITMAP_ALLOC (NULL);
 
@@ -672,7 +697,10 @@ cleanup_tree_cfg_1 (void)
     {
       bb = BASIC_BLOCK_FOR_FN (cfun, i);
       if (bb)
-	retval |= cleanup_tree_cfg_bb (bb);
+	{
+	  retval |= cleanup_tree_cfg_bb (bb);
+	  retval |= split_bb_on_noreturn_calls (bb);
+	}
     }
 
   /* Now process the altered blocks, as long as any are available.  */
@@ -689,9 +717,9 @@ cleanup_tree_cfg_1 (void)
 
       retval |= cleanup_tree_cfg_bb (bb);
 
-      /* Rerun split_bbs_on_noreturn_calls, in case we have altered any noreturn
+      /* Rerun split_bb_on_noreturn_calls, in case we have altered any noreturn
 	 calls.  */
-      retval |= split_bbs_on_noreturn_calls ();
+      retval |= split_bb_on_noreturn_calls (bb);
     }
 
   end_recording_case_labels ();
diff --git a/gcc/tree-sra.c b/gcc/tree-sra.c
index ffef13d..13f6c4a 100644
--- a/gcc/tree-sra.c
+++ b/gcc/tree-sra.c
@@ -1092,6 +1092,11 @@ build_access_from_expr_1 (tree expr, gimple stmt, bool write)
 			       "component.");
       return NULL;
     }
+  if (TREE_THIS_VOLATILE (expr))
+    {
+      disqualify_base_of_expr (expr, "part of a volatile reference.");
+      return NULL;
+    }
 
   switch (TREE_CODE (expr))
     {
diff --git a/gcc/tree-ssa-copy.c b/gcc/tree-ssa-copy.c
index 02f4743..a3d8392 100644
--- a/gcc/tree-ssa-copy.c
+++ b/gcc/tree-ssa-copy.c
@@ -235,38 +235,26 @@ copy_prop_visit_cond_stmt (gimple stmt, edge *taken_edge_p)
   enum ssa_prop_result retval = SSA_PROP_VARYING;
   location_t loc = gimple_location (stmt);
 
-  tree op0 = gimple_cond_lhs (stmt);
-  tree op1 = gimple_cond_rhs (stmt);
+  tree op0 = valueize_val (gimple_cond_lhs (stmt));
+  tree op1 = valueize_val (gimple_cond_rhs (stmt));
 
-  /* The only conditionals that we may be able to compute statically
-     are predicates involving two SSA_NAMEs.  */
-  if (TREE_CODE (op0) == SSA_NAME && TREE_CODE (op1) == SSA_NAME)
+  /* See if we can determine the predicate's value.  */
+  if (dump_file && (dump_flags & TDF_DETAILS))
     {
-      op0 = valueize_val (op0);
-      op1 = valueize_val (op1);
-
-      /* See if we can determine the predicate's value.  */
-      if (dump_file && (dump_flags & TDF_DETAILS))
-	{
-	  fprintf (dump_file, "Trying to determine truth value of ");
-	  fprintf (dump_file, "predicate ");
-	  print_gimple_stmt (dump_file, stmt, 0, 0);
-	}
+      fprintf (dump_file, "Trying to determine truth value of ");
+      fprintf (dump_file, "predicate ");
+      print_gimple_stmt (dump_file, stmt, 0, 0);
+    }
 
-      /* We can fold COND and get a useful result only when we have
-	 the same SSA_NAME on both sides of a comparison operator.  */
-      if (op0 == op1)
-	{
-	  tree folded_cond = fold_binary_loc (loc, gimple_cond_code (stmt),
-                                          boolean_type_node, op0, op1);
-	  if (folded_cond)
-	    {
-	      basic_block bb = gimple_bb (stmt);
-	      *taken_edge_p = find_taken_edge (bb, folded_cond);
-	      if (*taken_edge_p)
-		retval = SSA_PROP_INTERESTING;
-	    }
-	}
+  /* Fold COND and see whether we get a useful result.  */
+  tree folded_cond = fold_binary_loc (loc, gimple_cond_code (stmt),
+				      boolean_type_node, op0, op1);
+  if (folded_cond)
+    {
+      basic_block bb = gimple_bb (stmt);
+      *taken_edge_p = find_taken_edge (bb, folded_cond);
+      if (*taken_edge_p)
+	retval = SSA_PROP_INTERESTING;
     }
 
   if (dump_file && (dump_flags & TDF_DETAILS) && *taken_edge_p)
diff --git a/gcc/tree-ssa-loop-ivopts.c b/gcc/tree-ssa-loop-ivopts.c
index 8bc4e8f..78f036e 100644
--- a/gcc/tree-ssa-loop-ivopts.c
+++ b/gcc/tree-ssa-loop-ivopts.c
@@ -1679,6 +1679,8 @@ may_be_unaligned_p (tree ref, tree step)
     return false;
 
   unsigned int align = TYPE_ALIGN (TREE_TYPE (ref));
+  if (GET_MODE_ALIGNMENT (TYPE_MODE (TREE_TYPE (ref))) > align)
+    align = GET_MODE_ALIGNMENT (TYPE_MODE (TREE_TYPE (ref)));
 
   unsigned HOST_WIDE_INT bitpos;
   unsigned int ref_align;
diff --git a/gcc/tree-ssa-loop-niter.c b/gcc/tree-ssa-loop-niter.c
index 7628363..897b8f5 100644
--- a/gcc/tree-ssa-loop-niter.c
+++ b/gcc/tree-ssa-loop-niter.c
@@ -1636,6 +1636,9 @@ expand_simple_operations (tree expr)
 
     case PLUS_EXPR:
     case MINUS_EXPR:
+      if (TYPE_OVERFLOW_TRAPS (TREE_TYPE (expr)))
+	return expr;
+      /* Fallthru.  */
     case POINTER_PLUS_EXPR:
       /* And increments and decrements by a constant are simple.  */
       e1 = gimple_assign_rhs2 (stmt);
diff --git a/gcc/tree-ssa-math-opts.c b/gcc/tree-ssa-math-opts.c
index 292ced1..0e8d54d 100644
--- a/gcc/tree-ssa-math-opts.c
+++ b/gcc/tree-ssa-math-opts.c
@@ -1749,6 +1749,8 @@ find_bswap_1 (gimple stmt, struct symbolic_number *n, int limit)
 	  size = TYPE_PRECISION (n->type);
 	  if (size % BITS_PER_UNIT != 0)
 	    return NULL_TREE;
+	  if (size > HOST_BITS_PER_WIDEST_INT)
+	    return NULL_TREE;
 	  size /= BITS_PER_UNIT;
 	  n->n = (sizeof (HOST_WIDEST_INT) < 8 ? 0 :
 		  (unsigned HOST_WIDEST_INT)0x08070605 << 32 | 0x04030201);
@@ -1792,6 +1794,8 @@ find_bswap_1 (gimple stmt, struct symbolic_number *n, int limit)
 	    type_size = TYPE_PRECISION (type);
 	    if (type_size % BITS_PER_UNIT != 0)
 	      return NULL_TREE;
+	    if (type_size > (int) HOST_BITS_PER_WIDEST_INT)
+	      return NULL_TREE;
 
 	    /* Sign extension: result is dependent on the value.  */
 	    old_type_size = TYPE_PRECISION (n->type);
@@ -1932,7 +1936,7 @@ execute_optimize_bswap (void)
   bool changed = false;
   tree bswap16_type = NULL_TREE, bswap32_type = NULL_TREE, bswap64_type = NULL_TREE;
 
-  if (BITS_PER_UNIT != 8)
+  if (BITS_PER_UNIT != 8 || CHAR_BIT != 8)
     return 0;
 
   if (sizeof (HOST_WIDEST_INT) < 8)
diff --git a/gcc/tree-ssa-operands.c b/gcc/tree-ssa-operands.c
index c525fe5..76d04630 100644
--- a/gcc/tree-ssa-operands.c
+++ b/gcc/tree-ssa-operands.c
@@ -1091,12 +1091,6 @@ update_stmt_operands (struct function *fn, gimple stmt)
 
   timevar_push (TV_TREE_OPS);
 
-  /* If the stmt is a noreturn call queue it to be processed by
-     split_bbs_on_noreturn_calls during cfg cleanup.  */
-  if (is_gimple_call (stmt)
-      && gimple_call_noreturn_p (stmt))
-    vec_safe_push (MODIFIED_NORETURN_CALLS (fn), stmt);
-
   gcc_assert (gimple_modified_p (stmt));
   build_ssa_operands (fn, stmt);
   gimple_set_modified (stmt, false);
diff --git a/gcc/tree-ssa-tail-merge.c b/gcc/tree-ssa-tail-merge.c
index aa7f829..09e9b24 100644
--- a/gcc/tree-ssa-tail-merge.c
+++ b/gcc/tree-ssa-tail-merge.c
@@ -1159,17 +1159,9 @@ gimple_equal_p (same_succ same_succ, gimple s1, gimple s2)
       lhs2 = gimple_get_lhs (s2);
       if (TREE_CODE (lhs1) != SSA_NAME
 	  && TREE_CODE (lhs2) != SSA_NAME)
-	{
-	  /* If the vdef is the same, it's the same statement.  */
-	  if (vn_valueize (gimple_vdef (s1))
-	      == vn_valueize (gimple_vdef (s2)))
-	    return true;
-
-	  /* Test for structural equality.  */
-	  return (operand_equal_p (lhs1, lhs2, 0)
-		  && gimple_operand_equal_value_p (gimple_assign_rhs1 (s1),
-						   gimple_assign_rhs1 (s2)));
-	}
+	return (operand_equal_p (lhs1, lhs2, 0)
+		&& gimple_operand_equal_value_p (gimple_assign_rhs1 (s1),
+						 gimple_assign_rhs1 (s2)));
       else if (TREE_CODE (lhs1) == SSA_NAME
 	       && TREE_CODE (lhs2) == SSA_NAME)
 	return vn_valueize (lhs1) == vn_valueize (lhs2);
diff --git a/gcc/tree-ssanames.h b/gcc/tree-ssanames.h
index bb3b5e6..b8729ad 100644
--- a/gcc/tree-ssanames.h
+++ b/gcc/tree-ssanames.h
@@ -58,7 +58,6 @@ struct GTY (()) range_info_def {
 
 
 #define SSANAMES(fun) (fun)->gimple_df->ssa_names
-#define MODIFIED_NORETURN_CALLS(fun) (fun)->gimple_df->modified_noreturn_calls
 #define DEFAULT_DEFS(fun) (fun)->gimple_df->default_defs
 
 #define num_ssa_names (vec_safe_length (cfun->gimple_df->ssa_names))
diff --git a/gcc/tree-vect-data-refs.c b/gcc/tree-vect-data-refs.c
index 6622bd8..a1096fd 100644
--- a/gcc/tree-vect-data-refs.c
+++ b/gcc/tree-vect-data-refs.c
@@ -3841,6 +3841,9 @@ vect_get_new_vect_var (tree type, enum vect_var_kind var_kind, const char *name)
 	    is as follows:
 	    if LOOP=i_loop:	&in		(relative to i_loop)
 	    if LOOP=j_loop: 	&in+i*2B	(relative to j_loop)
+   BYTE_OFFSET: Optional, defaulted to NULL.  If supplied, it is added to the
+	    initial address.  Unlike OFFSET, which is number of elements to
+	    be added, BYTE_OFFSET is measured in bytes.
 
    Output:
    1. Return an SSA_NAME whose value is the address of the memory location of
@@ -3854,7 +3857,8 @@ tree
 vect_create_addr_base_for_vector_ref (gimple stmt,
 				      gimple_seq *new_stmt_list,
 				      tree offset,
-				      struct loop *loop)
+				      struct loop *loop,
+				      tree byte_offset)
 {
   stmt_vec_info stmt_info = vinfo_for_stmt (stmt);
   struct data_reference *dr = STMT_VINFO_DATA_REF (stmt_info);
@@ -3907,6 +3911,12 @@ vect_create_addr_base_for_vector_ref (gimple stmt,
       base_offset = fold_build2 (PLUS_EXPR, sizetype,
 				 base_offset, offset);
     }
+  if (byte_offset)
+    {
+      byte_offset = fold_convert (sizetype, byte_offset);
+      base_offset = fold_build2 (PLUS_EXPR, sizetype,
+				 base_offset, byte_offset);
+    }
 
   /* base + base_offset */
   if (loop_vinfo)
@@ -3964,6 +3974,10 @@ vect_create_addr_base_for_vector_ref (gimple stmt,
    5. BSI: location where the new stmts are to be placed if there is no loop
    6. ONLY_INIT: indicate if ap is to be updated in the loop, or remain
         pointing to the initial address.
+   7. BYTE_OFFSET (optional, defaults to NULL): a byte offset to be added
+	to the initial address accessed by the data-ref in STMT.  This is
+	similar to OFFSET, but OFFSET is counted in elements, while BYTE_OFFSET
+	in bytes.
 
    Output:
    1. Declare a new ptr to vector_type, and have it point to the base of the
@@ -3977,6 +3991,8 @@ vect_create_addr_base_for_vector_ref (gimple stmt,
          initial_address = &a[init];
       if OFFSET is supplied:
          initial_address = &a[init + OFFSET];
+      if BYTE_OFFSET is supplied:
+	 initial_address = &a[init] + BYTE_OFFSET;
 
       Return the initial_address in INITIAL_ADDRESS.
 
@@ -3994,7 +4010,7 @@ tree
 vect_create_data_ref_ptr (gimple stmt, tree aggr_type, struct loop *at_loop,
 			  tree offset, tree *initial_address,
 			  gimple_stmt_iterator *gsi, gimple *ptr_incr,
-			  bool only_init, bool *inv_p)
+			  bool only_init, bool *inv_p, tree byte_offset)
 {
   const char *base_name;
   stmt_vec_info stmt_info = vinfo_for_stmt (stmt);
@@ -4137,10 +4153,10 @@ vect_create_data_ref_ptr (gimple stmt, tree aggr_type, struct loop *at_loop,
   /* (2) Calculate the initial address of the aggregate-pointer, and set
      the aggregate-pointer to point to it before the loop.  */
 
-  /* Create: (&(base[init_val+offset]) in the loop preheader.  */
+  /* Create: (&(base[init_val+offset]+byte_offset) in the loop preheader.  */
 
   new_temp = vect_create_addr_base_for_vector_ref (stmt, &new_stmt_list,
-                                                   offset, loop);
+						   offset, loop, byte_offset);
   if (new_stmt_list)
     {
       if (pe)
diff --git a/gcc/tree-vect-loop.c b/gcc/tree-vect-loop.c
index 4204907..797f24cd 100644
--- a/gcc/tree-vect-loop.c
+++ b/gcc/tree-vect-loop.c
@@ -2321,7 +2321,8 @@ vect_is_simple_reduction_1 (loop_vec_info loop_info, gimple phi,
         }
 
       def1 = SSA_NAME_DEF_STMT (op1);
-      if (flow_bb_inside_loop_p (loop, gimple_bb (def_stmt))
+      if (gimple_bb (def1)
+	  && flow_bb_inside_loop_p (loop, gimple_bb (def_stmt))
           && loop->inner
           && flow_bb_inside_loop_p (loop->inner, gimple_bb (def1))
           && is_gimple_assign (def1))
diff --git a/gcc/tree-vect-slp.c b/gcc/tree-vect-slp.c
index 0ab267f..d48d3f5 100644
--- a/gcc/tree-vect-slp.c
+++ b/gcc/tree-vect-slp.c
@@ -1793,7 +1793,10 @@ vect_detect_hybrid_slp_stmts (slp_tree node)
 	    && (stmt_vinfo = vinfo_for_stmt (use_stmt))
 	    && !STMT_SLP_TYPE (stmt_vinfo)
             && (STMT_VINFO_RELEVANT (stmt_vinfo)
-                || VECTORIZABLE_CYCLE_DEF (STMT_VINFO_DEF_TYPE (stmt_vinfo)))
+                || VECTORIZABLE_CYCLE_DEF (STMT_VINFO_DEF_TYPE (stmt_vinfo))
+		|| (STMT_VINFO_IN_PATTERN_P (stmt_vinfo)
+		    && STMT_VINFO_RELATED_STMT (stmt_vinfo)
+		    && !STMT_SLP_TYPE (vinfo_for_stmt (STMT_VINFO_RELATED_STMT (stmt_vinfo)))))
 	    && !(gimple_code (use_stmt) == GIMPLE_PHI
                  && STMT_VINFO_DEF_TYPE (stmt_vinfo)
                   == vect_reduction_def))
diff --git a/gcc/tree-vect-stmts.c b/gcc/tree-vect-stmts.c
index 1a51d6d..eadfdfa 100644
--- a/gcc/tree-vect-stmts.c
+++ b/gcc/tree-vect-stmts.c
@@ -5600,6 +5600,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,
   int i, j, group_size, group_gap;
   tree msq = NULL_TREE, lsq;
   tree offset = NULL_TREE;
+  tree byte_offset = NULL_TREE;
   tree realignment_token = NULL_TREE;
   gimple phi = NULL;
   vec<tree> dr_chain = vNULL;
@@ -6261,7 +6262,8 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,
       if (alignment_support_scheme == dr_explicit_realign_optimized)
 	{
 	  phi = SSA_NAME_DEF_STMT (msq);
-	  offset = size_int (TYPE_VECTOR_SUBPARTS (vectype) - 1);
+	  byte_offset = size_binop (MINUS_EXPR, TYPE_SIZE_UNIT (vectype),
+				    size_one_node);
 	}
     }
   else
@@ -6302,7 +6304,8 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,
 	    dataref_ptr
 	      = vect_create_data_ref_ptr (first_stmt, aggr_type, at_loop,
 					  offset, &dummy, gsi, &ptr_incr,
-					  simd_lane_access_p, &inv_p);
+					  simd_lane_access_p, &inv_p,
+					  byte_offset);
 	}
       else if (dataref_offset)
 	dataref_offset = int_const_binop (PLUS_EXPR, dataref_offset,
diff --git a/gcc/tree-vectorizer.h b/gcc/tree-vectorizer.h
index fa2989d..b32ec46 100644
--- a/gcc/tree-vectorizer.h
+++ b/gcc/tree-vectorizer.h
@@ -414,9 +414,9 @@ typedef struct _loop_vec_info {
 #define LOOP_VINFO_SCALAR_LOOP(L)	   (L)->scalar_loop
 
 #define LOOP_REQUIRES_VERSIONING_FOR_ALIGNMENT(L) \
-  (L)->may_misalign_stmts.length () > 0
+  ((L)->may_misalign_stmts.length () > 0)
 #define LOOP_REQUIRES_VERSIONING_FOR_ALIAS(L)     \
-  (L)->may_alias_ddrs.length () > 0
+  ((L)->may_alias_ddrs.length () > 0)
 
 #define LOOP_VINFO_NITERS_KNOWN_P(L)          \
   (tree_fits_shwi_p ((L)->num_iters) && tree_to_shwi ((L)->num_iters) > 0)
@@ -1061,7 +1061,8 @@ extern bool vect_analyze_data_refs (loop_vec_info, bb_vec_info, int *,
 				    unsigned *);
 extern tree vect_create_data_ref_ptr (gimple, tree, struct loop *, tree,
 				      tree *, gimple_stmt_iterator *,
-				      gimple *, bool, bool *);
+				      gimple *, bool, bool *,
+				      tree = NULL_TREE);
 extern tree bump_vector_ptr (tree, gimple, gimple_stmt_iterator *, gimple, tree);
 extern tree vect_create_destination_var (tree, tree);
 extern bool vect_grouped_store_supported (tree, unsigned HOST_WIDE_INT);
@@ -1078,7 +1079,8 @@ extern void vect_transform_grouped_load (gimple, vec<tree> , int,
 extern void vect_record_grouped_load_vectors (gimple, vec<tree> );
 extern tree vect_get_new_vect_var (tree, enum vect_var_kind, const char *);
 extern tree vect_create_addr_base_for_vector_ref (gimple, gimple_seq *,
-                                                  tree, struct loop *);
+						  tree, struct loop *,
+						  tree = NULL_TREE);
 
 /* In tree-vect-loop.c.  */
 /* FORNOW: Used in tree-parloops.c.  */
diff --git a/gcc/ubsan.c b/gcc/ubsan.c
index ac40c85..dc70099 100644
--- a/gcc/ubsan.c
+++ b/gcc/ubsan.c
@@ -528,9 +528,9 @@ ubsan_instrument_unreachable (location_t loc)
 bool
 is_ubsan_builtin_p (tree t)
 {
-  gcc_checking_assert (TREE_CODE (t) == FUNCTION_DECL);
-  return strncmp (IDENTIFIER_POINTER (DECL_NAME (t)),
-		  "__builtin___ubsan_", 18) == 0;
+  return TREE_CODE (t) == FUNCTION_DECL
+	 && strncmp (IDENTIFIER_POINTER (DECL_NAME (t)),
+		     "__builtin___ubsan_", 18) == 0;
 }
 
 /* Expand UBSAN_NULL internal call.  */
diff --git a/libgcc/config/i386/sfp-machine.h b/libgcc/config/i386/sfp-machine.h
index 148044a..8a1923b 100644
--- a/libgcc/config/i386/sfp-machine.h
+++ b/libgcc/config/i386/sfp-machine.h
@@ -60,7 +60,7 @@ void __sfp_handle_exceptions (int);
       __sfp_handle_exceptions (_fex);		\
   } while (0);
 
-#define FP_TRAPPING_EXCEPTIONS ((_fcw >> FP_EX_SHIFT) & FP_EX_ALL)
+#define FP_TRAPPING_EXCEPTIONS ((~_fcw >> FP_EX_SHIFT) & FP_EX_ALL)
 
 #define FP_ROUNDMODE		(_fcw & FP_RND_MASK)
 #endif
diff --git a/libgomp/libgomp.h b/libgomp/libgomp.h
index bcd5b34..a1482cc 100644
--- a/libgomp/libgomp.h
+++ b/libgomp/libgomp.h
@@ -274,6 +274,7 @@ struct gomp_task_depend_entry
   struct gomp_task *task;
   bool is_in;
   bool redundant;
+  bool redundant_out;
 };
 
 struct gomp_dependers_vec
@@ -283,6 +284,17 @@ struct gomp_dependers_vec
   struct gomp_task *elem[];
 };
 
+/* Used when in GOMP_taskwait or in gomp_task_maybe_wait_for_dependencies.  */
+
+struct gomp_taskwait
+{
+  bool in_taskwait;
+  bool in_depend_wait;
+  size_t n_depend;
+  struct gomp_task *last_parent_depends_on;
+  gomp_sem_t taskwait_sem;
+};
+
 /* This structure describes a "task" to be run by a thread.  */
 
 struct gomp_task
@@ -298,17 +310,17 @@ struct gomp_task
   struct gomp_taskgroup *taskgroup;
   struct gomp_dependers_vec *dependers;
   struct htab *depend_hash;
+  struct gomp_taskwait *taskwait;
   size_t depend_count;
   size_t num_dependees;
   struct gomp_task_icv icv;
   void (*fn) (void *);
   void *fn_data;
   enum gomp_task_kind kind;
-  bool in_taskwait;
   bool in_tied_task;
   bool final_task;
   bool copy_ctors_done;
-  gomp_sem_t taskwait_sem;
+  bool parent_depends_on;
   struct gomp_task_depend_entry depend[];
 };
 
@@ -582,7 +594,6 @@ gomp_finish_task (struct gomp_task *task)
 {
   if (__builtin_expect (task->depend_hash != NULL, 0))
     free (task->depend_hash);
-  gomp_sem_destroy (&task->taskwait_sem);
 }
 
 /* team.c */
diff --git a/libgomp/task.c b/libgomp/task.c
index be2df3f..7d3233c 100644
--- a/libgomp/task.c
+++ b/libgomp/task.c
@@ -66,16 +66,16 @@ gomp_init_task (struct gomp_task *task, struct gomp_task *parent_task,
   task->parent = parent_task;
   task->icv = *prev_icv;
   task->kind = GOMP_TASK_IMPLICIT;
-  task->in_taskwait = false;
+  task->taskwait = NULL;
   task->in_tied_task = false;
   task->final_task = false;
   task->copy_ctors_done = false;
+  task->parent_depends_on = false;
   task->children = NULL;
   task->taskgroup = NULL;
   task->dependers = NULL;
   task->depend_hash = NULL;
   task->depend_count = 0;
-  gomp_sem_init (&task->taskwait_sem, 0);
 }
 
 /* Clean up a task, after completing it.  */
@@ -104,6 +104,8 @@ gomp_clear_parent (struct gomp_task *children)
     while (task != children);
 }
 
+static void gomp_task_maybe_wait_for_dependencies (void **depend);
+
 /* Called when encountering an explicit task directive.  If IF_CLAUSE is
    false, then we must not delay in executing the task.  If UNTIED is true,
    then the task may be executed by any member of the team.  */
@@ -141,35 +143,12 @@ GOMP_task (void (*fn) (void *), void *data, void (*cpyfn) (void *, void *),
 
       /* If there are depend clauses and earlier deferred sibling tasks
 	 with depend clauses, check if there isn't a dependency.  If there
-	 is, fall through to the deferred task handling, as we can't
-	 schedule such tasks right away.  There is no need to handle
+	 is, we need to wait for them.  There is no need to handle
 	 depend clauses for non-deferred tasks other than this, because
 	 the parent task is suspended until the child task finishes and thus
 	 it can't start further child tasks.  */
       if ((flags & 8) && thr->task && thr->task->depend_hash)
-	{
-	  struct gomp_task *parent = thr->task;
-	  struct gomp_task_depend_entry elem, *ent = NULL;
-	  size_t ndepend = (uintptr_t) depend[0];
-	  size_t nout = (uintptr_t) depend[1];
-	  size_t i;
-	  gomp_mutex_lock (&team->task_lock);
-	  for (i = 0; i < ndepend; i++)
-	    {
-	      elem.addr = depend[i + 2];
-	      ent = htab_find (parent->depend_hash, &elem);
-	      for (; ent; ent = ent->next)
-		if (i >= nout && ent->is_in)
-		  continue;
-		else
-		  break;
-	      if (ent)
-		break;
-	    }
-	  gomp_mutex_unlock (&team->task_lock);
-	  if (ent)
-	    goto defer;
-	}
+	gomp_task_maybe_wait_for_dependencies (depend);
 
       gomp_init_task (&task, thr->task, gomp_icv (false));
       task.kind = GOMP_TASK_IFFALSE;
@@ -209,7 +188,6 @@ GOMP_task (void (*fn) (void *), void *data, void (*cpyfn) (void *, void *),
     }
   else
     {
-     defer:;
       struct gomp_task *task;
       struct gomp_task *parent = thr->task;
       struct gomp_taskgroup *taskgroup = parent->taskgroup;
@@ -275,11 +253,12 @@ GOMP_task (void (*fn) (void *), void *data, void (*cpyfn) (void *, void *),
 	      task->depend[i].task = task;
 	      task->depend[i].is_in = i >= nout;
 	      task->depend[i].redundant = false;
+	      task->depend[i].redundant_out = false;
 
 	      hash_entry_type *slot
 		= htab_find_slot (&parent->depend_hash, &task->depend[i],
 				  INSERT);
-	      hash_entry_type out = NULL;
+	      hash_entry_type out = NULL, last = NULL;
 	      if (*slot)
 		{
 		  /* If multiple depends on the same task are the
@@ -294,6 +273,11 @@ GOMP_task (void (*fn) (void *), void *data, void (*cpyfn) (void *, void *),
 		    }
 		  for (ent = *slot; ent; ent = ent->next)
 		    {
+		      if (ent->redundant_out)
+			break;
+
+		      last = ent;
+
 		      /* depend(in:...) doesn't depend on earlier
 			 depend(in:...).  */
 		      if (i >= nout && ent->is_in)
@@ -341,21 +325,31 @@ GOMP_task (void (*fn) (void *), void *data, void (*cpyfn) (void *, void *),
 	      *slot = &task->depend[i];
 
 	      /* There is no need to store more than one depend({,in}out:)
-		 task per address in the hash table chain, because each out
+		 task per address in the hash table chain for the purpose
+		 of creation of deferred tasks, because each out
 		 depends on all earlier outs, thus it is enough to record
 		 just the last depend({,in}out:).  For depend(in:), we need
 		 to keep all of the previous ones not terminated yet, because
 		 a later depend({,in}out:) might need to depend on all of
 		 them.  So, if the new task's clause is depend({,in}out:),
 		 we know there is at most one other depend({,in}out:) clause
-		 in the list (out) and to maintain the invariant we now
-		 need to remove it from the list.  */
+		 in the list (out).  For non-deferred tasks we want to see
+		 all outs, so they are moved to the end of the chain,
+		 after first redundant_out entry all following entries
+		 should be redundant_out.  */
 	      if (!task->depend[i].is_in && out)
 		{
-		  if (out->next)
-		    out->next->prev = out->prev;
-		  out->prev->next = out->next;
-		  out->redundant = true;
+		  if (out != last)
+		    {
+		      out->next->prev = out->prev;
+		      out->prev->next = out->next;
+		      out->next = last->next;
+		      out->prev = last;
+		      last->next = out;
+		      if (out->next)
+			out->next->prev = out;
+		    }
+		  out->redundant_out = true;
 		}
 	    }
 	  if (task->num_dependees)
@@ -421,8 +415,20 @@ static inline bool
 gomp_task_run_pre (struct gomp_task *child_task, struct gomp_task *parent,
 		   struct gomp_taskgroup *taskgroup, struct gomp_team *team)
 {
-  if (parent && parent->children == child_task)
-    parent->children = child_task->next_child;
+  if (parent)
+    {
+      if (parent->children == child_task)
+	parent->children = child_task->next_child;
+      if (__builtin_expect (child_task->parent_depends_on, 0)
+	  && parent->taskwait->last_parent_depends_on == child_task)
+	{
+	  if (child_task->prev_child->kind == GOMP_TASK_WAITING
+	      && child_task->prev_child->parent_depends_on)
+	    parent->taskwait->last_parent_depends_on = child_task->prev_child;
+	  else
+	    parent->taskwait->last_parent_depends_on = NULL;
+	}
+    }
   if (taskgroup && taskgroup->children == child_task)
     taskgroup->children = child_task->next_taskgroup;
   child_task->prev_queue->next_queue = child_task->next_queue;
@@ -489,8 +495,23 @@ gomp_task_run_post_handle_dependers (struct gomp_task *child_task,
 	{
 	  if (parent->children)
 	    {
-	      task->next_child = parent->children;
-	      task->prev_child = parent->children->prev_child;
+	      /* If parent is in gomp_task_maybe_wait_for_dependencies
+		 and it doesn't need to wait for this task, put it after
+		 all ready to run tasks it needs to wait for.  */
+	      if (parent->taskwait && parent->taskwait->last_parent_depends_on
+		  && !task->parent_depends_on)
+		{
+		  struct gomp_task *last_parent_depends_on
+		    = parent->taskwait->last_parent_depends_on;
+		  task->next_child = last_parent_depends_on->next_child;
+		  task->prev_child = last_parent_depends_on;
+		}
+	      else
+		{
+		  task->next_child = parent->children;
+		  task->prev_child = parent->children->prev_child;
+		  parent->children = task;
+		}
 	      task->next_child->prev_child = task;
 	      task->prev_child->next_child = task;
 	    }
@@ -498,12 +519,23 @@ gomp_task_run_post_handle_dependers (struct gomp_task *child_task,
 	    {
 	      task->next_child = task;
 	      task->prev_child = task;
+	      parent->children = task;
 	    }
-	  parent->children = task;
-	  if (parent->in_taskwait)
+	  if (parent->taskwait)
 	    {
-	      parent->in_taskwait = false;
-	      gomp_sem_post (&parent->taskwait_sem);
+	      if (parent->taskwait->in_taskwait)
+		{
+		  parent->taskwait->in_taskwait = false;
+		  gomp_sem_post (&parent->taskwait->taskwait_sem);
+		}
+	      else if (parent->taskwait->in_depend_wait)
+		{
+		  parent->taskwait->in_depend_wait = false;
+		  gomp_sem_post (&parent->taskwait->taskwait_sem);
+		}
+	      if (parent->taskwait->last_parent_depends_on == NULL
+		  && task->parent_depends_on)
+		parent->taskwait->last_parent_depends_on = task;
 	    }
 	}
       if (taskgroup)
@@ -575,6 +607,13 @@ gomp_task_run_post_remove_parent (struct gomp_task *child_task)
   struct gomp_task *parent = child_task->parent;
   if (parent == NULL)
     return;
+  if (__builtin_expect (child_task->parent_depends_on, 0)
+      && --parent->taskwait->n_depend == 0
+      && parent->taskwait->in_depend_wait)
+    {
+      parent->taskwait->in_depend_wait = false;
+      gomp_sem_post (&parent->taskwait->taskwait_sem);
+    }
   child_task->prev_child->next_child = child_task->next_child;
   child_task->next_child->prev_child = child_task->prev_child;
   if (parent->children != child_task)
@@ -589,10 +628,10 @@ gomp_task_run_post_remove_parent (struct gomp_task *child_task)
 	 written by child_task->fn above is flushed
 	 before the NULL is written.  */
       __atomic_store_n (&parent->children, NULL, MEMMODEL_RELEASE);
-      if (parent->in_taskwait)
+      if (parent->taskwait && parent->taskwait->in_taskwait)
 	{
-	  parent->in_taskwait = false;
-	  gomp_sem_post (&parent->taskwait_sem);
+	  parent->taskwait->in_taskwait = false;
+	  gomp_sem_post (&parent->taskwait->taskwait_sem);
 	}
     }
 }
@@ -736,6 +775,7 @@ GOMP_taskwait (void)
   struct gomp_task *task = thr->task;
   struct gomp_task *child_task = NULL;
   struct gomp_task *to_free = NULL;
+  struct gomp_taskwait taskwait;
   int do_wake = 0;
 
   /* The acquire barrier on load of task->children here synchronizes
@@ -748,18 +788,194 @@ GOMP_taskwait (void)
       || __atomic_load_n (&task->children, MEMMODEL_ACQUIRE) == NULL)
     return;
 
+  memset (&taskwait, 0, sizeof (taskwait));
   gomp_mutex_lock (&team->task_lock);
   while (1)
     {
       bool cancelled = false;
       if (task->children == NULL)
 	{
+	  bool destroy_taskwait = task->taskwait != NULL;
+	  task->taskwait = NULL;
 	  gomp_mutex_unlock (&team->task_lock);
 	  if (to_free)
 	    {
 	      gomp_finish_task (to_free);
 	      free (to_free);
 	    }
+	  if (destroy_taskwait)
+	    gomp_sem_destroy (&taskwait.taskwait_sem);
+	  return;
+	}
+      if (task->children->kind == GOMP_TASK_WAITING)
+	{
+	  child_task = task->children;
+	  cancelled
+	    = gomp_task_run_pre (child_task, task, child_task->taskgroup,
+				 team);
+	  if (__builtin_expect (cancelled, 0))
+	    {
+	      if (to_free)
+		{
+		  gomp_finish_task (to_free);
+		  free (to_free);
+		  to_free = NULL;
+		}
+	      goto finish_cancelled;
+	    }
+	}
+      else
+	{
+	  /* All tasks we are waiting for are already running
+	     in other threads.  Wait for them.  */
+	  if (task->taskwait == NULL)
+	    {
+	      taskwait.in_depend_wait = false;
+	      gomp_sem_init (&taskwait.taskwait_sem, 0);
+	      task->taskwait = &taskwait;
+	    }
+	  taskwait.in_taskwait = true;
+	}
+      gomp_mutex_unlock (&team->task_lock);
+      if (do_wake)
+	{
+	  gomp_team_barrier_wake (&team->barrier, do_wake);
+	  do_wake = 0;
+	}
+      if (to_free)
+	{
+	  gomp_finish_task (to_free);
+	  free (to_free);
+	  to_free = NULL;
+	}
+      if (child_task)
+	{
+	  thr->task = child_task;
+	  child_task->fn (child_task->fn_data);
+	  thr->task = task;
+	}
+      else
+	gomp_sem_wait (&taskwait.taskwait_sem);
+      gomp_mutex_lock (&team->task_lock);
+      if (child_task)
+	{
+	 finish_cancelled:;
+	  size_t new_tasks
+	    = gomp_task_run_post_handle_depend (child_task, team);
+	  child_task->prev_child->next_child = child_task->next_child;
+	  child_task->next_child->prev_child = child_task->prev_child;
+	  if (task->children == child_task)
+	    {
+	      if (child_task->next_child != child_task)
+		task->children = child_task->next_child;
+	      else
+		task->children = NULL;
+	    }
+	  gomp_clear_parent (child_task->children);
+	  gomp_task_run_post_remove_taskgroup (child_task);
+	  to_free = child_task;
+	  child_task = NULL;
+	  team->task_count--;
+	  if (new_tasks > 1)
+	    {
+	      do_wake = team->nthreads - team->task_running_count
+			- !task->in_tied_task;
+	      if (do_wake > new_tasks)
+		do_wake = new_tasks;
+	    }
+	}
+    }
+}
+
+/* This is like GOMP_taskwait, but we only wait for tasks that the
+   upcoming task depends on.  */
+
+static void
+gomp_task_maybe_wait_for_dependencies (void **depend)
+{
+  struct gomp_thread *thr = gomp_thread ();
+  struct gomp_task *task = thr->task;
+  struct gomp_team *team = thr->ts.team;
+  struct gomp_task_depend_entry elem, *ent = NULL;
+  struct gomp_taskwait taskwait;
+  struct gomp_task *last_parent_depends_on = NULL;
+  size_t ndepend = (uintptr_t) depend[0];
+  size_t nout = (uintptr_t) depend[1];
+  size_t i;
+  size_t num_awaited = 0;
+  struct gomp_task *child_task = NULL;
+  struct gomp_task *to_free = NULL;
+  int do_wake = 0;
+
+  gomp_mutex_lock (&team->task_lock);
+  for (i = 0; i < ndepend; i++)
+    {
+      elem.addr = depend[i + 2];
+      ent = htab_find (task->depend_hash, &elem);
+      for (; ent; ent = ent->next)
+	if (i >= nout && ent->is_in)
+	  continue;
+	else
+	  {
+	    struct gomp_task *tsk = ent->task;
+	    if (!tsk->parent_depends_on)
+	      {
+		tsk->parent_depends_on = true;
+		++num_awaited;
+		if (tsk->num_dependees == 0 && tsk->kind == GOMP_TASK_WAITING)
+		  {
+		    /* If a task we need to wait for is not already
+		       running and is ready to be scheduled, move it
+		       to front, so that we run it as soon as possible.  */
+		    if (last_parent_depends_on)
+		      {
+			tsk->prev_child->next_child = tsk->next_child;
+			tsk->next_child->prev_child = tsk->prev_child;
+			tsk->prev_child = last_parent_depends_on;
+			tsk->next_child = last_parent_depends_on->next_child;
+			tsk->prev_child->next_child = tsk;
+			tsk->next_child->prev_child = tsk;
+		      }
+		    else if (tsk != task->children)
+		      {
+			tsk->prev_child->next_child = tsk->next_child;
+			tsk->next_child->prev_child = tsk->prev_child;
+			tsk->prev_child = task->children;
+			tsk->next_child = task->children->next_child;
+			task->children = tsk;
+			tsk->prev_child->next_child = tsk;
+			tsk->next_child->prev_child = tsk;
+		      }
+		    last_parent_depends_on = tsk;
+		  }
+	      }
+	  }
+    }
+  if (num_awaited == 0)
+    {
+      gomp_mutex_unlock (&team->task_lock);
+      return;
+    }
+
+  memset (&taskwait, 0, sizeof (taskwait));
+  taskwait.n_depend = num_awaited;
+  taskwait.last_parent_depends_on = last_parent_depends_on;
+  gomp_sem_init (&taskwait.taskwait_sem, 0);
+  task->taskwait = &taskwait;
+
+  while (1)
+    {
+      bool cancelled = false;
+      if (taskwait.n_depend == 0)
+	{
+	  task->taskwait = NULL;
+	  gomp_mutex_unlock (&team->task_lock);
+	  if (to_free)
+	    {
+	      gomp_finish_task (to_free);
+	      free (to_free);
+	    }
+	  gomp_sem_destroy (&taskwait.taskwait_sem);
 	  return;
 	}
       if (task->children->kind == GOMP_TASK_WAITING)
@@ -782,7 +998,7 @@ GOMP_taskwait (void)
       else
 	/* All tasks we are waiting for are already running
 	   in other threads.  Wait for them.  */
-	task->in_taskwait = true;
+	taskwait.in_depend_wait = true;
       gomp_mutex_unlock (&team->task_lock);
       if (do_wake)
 	{
@@ -802,13 +1018,15 @@ GOMP_taskwait (void)
 	  thr->task = task;
 	}
       else
-	gomp_sem_wait (&task->taskwait_sem);
+	gomp_sem_wait (&taskwait.taskwait_sem);
       gomp_mutex_lock (&team->task_lock);
       if (child_task)
 	{
 	 finish_cancelled:;
 	  size_t new_tasks
 	    = gomp_task_run_post_handle_depend (child_task, team);
+	  if (child_task->parent_depends_on)
+	    --taskwait.n_depend;
 	  child_task->prev_child->next_child = child_task->next_child;
 	  child_task->next_child->prev_child = child_task->prev_child;
 	  if (task->children == child_task)
@@ -897,18 +1115,26 @@ GOMP_taskgroup_end (void)
       if (taskgroup->children == NULL)
 	{
 	  if (taskgroup->num_children)
-	    goto do_wait;
-	  gomp_mutex_unlock (&team->task_lock);
-	  if (to_free)
 	    {
-	      gomp_finish_task (to_free);
-	      free (to_free);
+	      if (task->children == NULL)
+		goto do_wait;
+	      child_task = task->children;
+            }
+          else
+	    {
+	      gomp_mutex_unlock (&team->task_lock);
+	      if (to_free)
+		{
+		  gomp_finish_task (to_free);
+		  free (to_free);
+		}
+	      goto finish;
 	    }
-	  goto finish;
 	}
-      if (taskgroup->children->kind == GOMP_TASK_WAITING)
+      else
+	child_task = taskgroup->children;
+      if (child_task->kind == GOMP_TASK_WAITING)
 	{
-	  child_task = taskgroup->children;
 	  cancelled
 	    = gomp_task_run_pre (child_task, child_task->parent, taskgroup,
 				 team);
@@ -925,6 +1151,7 @@ GOMP_taskgroup_end (void)
 	}
       else
 	{
+	  child_task = NULL;
 	 do_wait:
 	  /* All tasks we are waiting for are already running
 	     in other threads.  Wait for them.  */
@@ -956,20 +1183,9 @@ GOMP_taskgroup_end (void)
 	 finish_cancelled:;
 	  size_t new_tasks
 	    = gomp_task_run_post_handle_depend (child_task, team);
-	  child_task->prev_taskgroup->next_taskgroup
-	    = child_task->next_taskgroup;
-	  child_task->next_taskgroup->prev_taskgroup
-	    = child_task->prev_taskgroup;
-	  --taskgroup->num_children;
-	  if (taskgroup->children == child_task)
-	    {
-	      if (child_task->next_taskgroup != child_task)
-		taskgroup->children = child_task->next_taskgroup;
-	      else
-		taskgroup->children = NULL;
-	    }
 	  gomp_task_run_post_remove_parent (child_task);
 	  gomp_clear_parent (child_task->children);
+	  gomp_task_run_post_remove_taskgroup (child_task);
 	  to_free = child_task;
 	  child_task = NULL;
 	  team->task_count--;
diff --git a/libstdc++-v3/include/bits/atomic_base.h b/libstdc++-v3/include/bits/atomic_base.h
index 242459a..1fc0ebb 100644
--- a/libstdc++-v3/include/bits/atomic_base.h
+++ b/libstdc++-v3/include/bits/atomic_base.h
@@ -675,10 +675,10 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 
       // Factored out to facilitate explicit specialization.
       constexpr ptrdiff_t
-      _M_type_size(ptrdiff_t __d) { return __d * sizeof(_PTp); }
+      _M_type_size(ptrdiff_t __d) const { return __d * sizeof(_PTp); }
 
       constexpr ptrdiff_t
-      _M_type_size(ptrdiff_t __d) volatile { return __d * sizeof(_PTp); }
+      _M_type_size(ptrdiff_t __d) const volatile { return __d * sizeof(_PTp); }
 
     public:
       __atomic_base() noexcept = default;
diff --git a/libstdc++-v3/include/bits/basic_string.h b/libstdc++-v3/include/bits/basic_string.h
index cd60376..93ceb6d 100644
--- a/libstdc++-v3/include/bits/basic_string.h
+++ b/libstdc++-v3/include/bits/basic_string.h
@@ -2811,7 +2811,23 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     inline basic_istream<_CharT, _Traits>&
     getline(basic_istream<_CharT, _Traits>& __is,
 	    basic_string<_CharT, _Traits, _Alloc>& __str)
-    { return getline(__is, __str, __is.widen('\n')); }
+    { return std::getline(__is, __str, __is.widen('\n')); }
+
+#if __cplusplus >= 201103L
+  /// Read a line from an rvalue stream into a string.
+  template<typename _CharT, typename _Traits, typename _Alloc>
+    inline basic_istream<_CharT, _Traits>&
+    getline(basic_istream<_CharT, _Traits>&& __is,
+	    basic_string<_CharT, _Traits, _Alloc>& __str, _CharT __delim)
+    { return std::getline(__is, __str, __delim); }
+
+  /// Read a line from an rvalue stream into a string.
+  template<typename _CharT, typename _Traits, typename _Alloc>
+    inline basic_istream<_CharT, _Traits>&
+    getline(basic_istream<_CharT, _Traits>&& __is,
+	    basic_string<_CharT, _Traits, _Alloc>& __str)
+    { return std::getline(__is, __str); }
+#endif
 
   template<>
     basic_istream<char>&
diff --git a/libstdc++-v3/include/bits/hashtable.h b/libstdc++-v3/include/bits/hashtable.h
index 9b6394c..588e69c 100644
--- a/libstdc++-v3/include/bits/hashtable.h
+++ b/libstdc++-v3/include/bits/hashtable.h
@@ -1281,10 +1281,10 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 	       _H1, _H2, _Hash, _RehashPolicy, _Traits>::
     __rehash_policy(const _RehashPolicy& __pol)
     {
-      size_type __n_bkt = __pol._M_bkt_for_elements(_M_element_count);
-      __n_bkt = __pol._M_next_bkt(__n_bkt);
-      if (__n_bkt != _M_bucket_count)
-	_M_rehash(__n_bkt, _M_rehash_policy._M_state());
+      auto __do_rehash =
+	__pol._M_need_rehash(_M_bucket_count, _M_element_count, 0);
+      if (__do_rehash.first)
+	_M_rehash(__do_rehash.second, _M_rehash_policy._M_state());
       _M_rehash_policy = __pol;
     }
 
diff --git a/libstdc++-v3/include/bits/random.h b/libstdc++-v3/include/bits/random.h
index edfd797..b34dbe6 100644
--- a/libstdc++-v3/include/bits/random.h
+++ b/libstdc++-v3/include/bits/random.h
@@ -164,6 +164,8 @@ _GLIBCXX_END_NAMESPACE_VERSION
     template<typename _Engine, typename _DInputType>
       struct _Adaptor
       {
+	static_assert(std::is_floating_point<_DInputType>::value,
+		      "template argument not a floating point type");
 
       public:
 	_Adaptor(_Engine& __g)
diff --git a/libstdc++-v3/include/bits/random.tcc b/libstdc++-v3/include/bits/random.tcc
index 0eda287..8849ee9 100644
--- a/libstdc++-v3/include/bits/random.tcc
+++ b/libstdc++-v3/include/bits/random.tcc
@@ -3463,6 +3463,9 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     _RealType
     generate_canonical(_UniformRandomNumberGenerator& __urng)
     {
+      static_assert(std::is_floating_point<_RealType>::value,
+		    "template argument not a floating point type");
+
       const size_t __b
 	= std::min(static_cast<size_t>(std::numeric_limits<_RealType>::digits),
                    __bits);
diff --git a/libstdc++-v3/include/bits/regex.h b/libstdc++-v3/include/bits/regex.h
index e556350..772a209 100644
--- a/libstdc++-v3/include/bits/regex.h
+++ b/libstdc++-v3/include/bits/regex.h
@@ -474,17 +474,25 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
        *
        * @param __rhs A @p regex object.
        */
-      basic_regex(const basic_regex& __rhs) = default;
+      basic_regex(const basic_regex& __rhs)
+      : _M_flags(__rhs._M_flags), _M_original_str(__rhs._M_original_str)
+      { this->imbue(__rhs.getloc()); }
 
       /**
        * @brief Move-constructs a basic regular expression.
        *
        * @param __rhs A @p regex object.
+       *
+       * The implementation is a workaround concerning ABI compatibility. See:
+       * https://gcc.gnu.org/ml/libstdc++/2014-09/msg00067.html
        */
-      basic_regex(const basic_regex&& __rhs) noexcept
-      : _M_flags(__rhs._M_flags), _M_traits(__rhs._M_traits),
-	_M_automaton(std::move(__rhs._M_automaton))
-      { }
+      basic_regex(basic_regex&& __rhs)
+      : _M_flags(__rhs._M_flags),
+      _M_original_str(std::move(__rhs._M_original_str))
+      {
+	this->imbue(__rhs.getloc());
+	__rhs._M_automaton.reset();
+      }
 
       /**
        * @brief Constructs a basic regular expression from the string
@@ -555,9 +563,12 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 
       /**
        * @brief Move-assigns one regular expression to another.
+       *
+       * The implementation is a workaround concerning ABI compatibility. See:
+       * https://gcc.gnu.org/ml/libstdc++/2014-09/msg00067.html
        */
       basic_regex&
-      operator=(basic_regex&& __rhs) noexcept
+      operator=(basic_regex&& __rhs)
       { return this->assign(std::move(__rhs)); }
 
       /**
@@ -591,8 +602,9 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       basic_regex&
       assign(const basic_regex& __rhs)
       {
-	basic_regex __tmp(__rhs);
-	this->swap(__tmp);
+	_M_flags = __rhs._M_flags;
+	_M_original_str = __rhs._M_original_str;
+	this->imbue(__rhs.getloc());
 	return *this;
       }
 
@@ -600,13 +612,17 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
        * @brief The move-assignment operator.
        *
        * @param __rhs Another regular expression object.
+       *
+       * The implementation is a workaround concerning ABI compatibility. See:
+       * https://gcc.gnu.org/ml/libstdc++/2014-09/msg00067.html
        */
       basic_regex&
-      assign(basic_regex&& __rhs) noexcept
+      assign(basic_regex&& __rhs)
       {
-	basic_regex __tmp(std::move(__rhs));
-	this->swap(__tmp);
-	return *this;
+	_M_flags = __rhs._M_flags;
+	_M_original_str = std::move(__rhs._M_original_str);
+	__rhs._M_automaton.reset();
+	this->imbue(__rhs.getloc());
       }
 
       /**
@@ -751,8 +767,8 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       swap(basic_regex& __rhs)
       {
 	std::swap(_M_flags, __rhs._M_flags);
-	std::swap(_M_traits, __rhs._M_traits);
-	std::swap(_M_automaton, __rhs._M_automaton);
+	std::swap(_M_original_str, __rhs._M_original_str);
+	this->imbue(__rhs.imbue(this->getloc()));
       }
 
 #ifdef _GLIBCXX_DEBUG
@@ -1814,7 +1830,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       /**
        * @pre   ready() == true
        */
-      template<typename _Out_iter, typename _St, typename _Sa>
+      template<typename _St, typename _Sa>
 	basic_string<char_type, _St, _Sa>
 	format(const basic_string<char_type, _St, _Sa>& __fmt,
 	       match_flag_type __flags = regex_constants::format_default) const
diff --git a/libstdc++-v3/include/bits/stl_algo.h b/libstdc++-v3/include/bits/stl_algo.h
index 4c6ca8a..cfb50a9 100644
--- a/libstdc++-v3/include/bits/stl_algo.h
+++ b/libstdc++-v3/include/bits/stl_algo.h
@@ -4430,7 +4430,12 @@ _GLIBCXX_BEGIN_NAMESPACE_ALGO
 
       if (__first != __last)
 	for (_RandomAccessIterator __i = __first + 1; __i != __last; ++__i)
-	  std::iter_swap(__i, __first + (std::rand() % ((__i - __first) + 1)));
+	  {
+	    _RandomAccessIterator __j = __first
+					+ std::rand() % ((__i - __first) + 1);
+	    if (__i != __j)
+	      std::iter_swap(__i, __j);
+	  }
     }
 
   /**
@@ -4464,7 +4469,11 @@ _GLIBCXX_BEGIN_NAMESPACE_ALGO
       if (__first == __last)
 	return;
       for (_RandomAccessIterator __i = __first + 1; __i != __last; ++__i)
-	std::iter_swap(__i, __first + __rand((__i - __first) + 1));
+	{
+	  _RandomAccessIterator __j = __first + __rand((__i - __first) + 1);
+	  if (__i != __j)
+	    std::iter_swap(__i, __j);
+	}
     }
 
 
diff --git a/libstdc++-v3/include/bits/stl_queue.h b/libstdc++-v3/include/bits/stl_queue.h
index b516664..32124e3 100644
--- a/libstdc++-v3/include/bits/stl_queue.h
+++ b/libstdc++-v3/include/bits/stl_queue.h
@@ -58,6 +58,9 @@
 
 #include <bits/concept_check.h>
 #include <debug/debug.h>
+#if __cplusplus >= 201103L
+# include <bits/uses_allocator.h>
+#endif
 
 namespace std _GLIBCXX_VISIBILITY(default)
 {
diff --git a/libstdc++-v3/include/bits/stl_stack.h b/libstdc++-v3/include/bits/stl_stack.h
index ee187da..f4bb72c 100644
--- a/libstdc++-v3/include/bits/stl_stack.h
+++ b/libstdc++-v3/include/bits/stl_stack.h
@@ -58,6 +58,9 @@
 
 #include <bits/concept_check.h>
 #include <debug/debug.h>
+#if __cplusplus >= 201103L
+# include <bits/uses_allocator.h>
+#endif
 
 namespace std _GLIBCXX_VISIBILITY(default)
 {
diff --git a/libstdc++-v3/include/bits/vector.tcc b/libstdc++-v3/include/bits/vector.tcc
index c937b38..704a644 100644
--- a/libstdc++-v3/include/bits/vector.tcc
+++ b/libstdc++-v3/include/bits/vector.tcc
@@ -228,7 +228,7 @@ _GLIBCXX_BEGIN_NAMESPACE_CONTAINER
       if (__n > capacity())
 	{
 	  vector __tmp(__n, __val, _M_get_Tp_allocator());
-	  __tmp.swap(*this);
+	  __tmp._M_impl._M_swap_data(this->_M_impl);
 	}
       else if (__n > size())
 	{
diff --git a/libstdc++-v3/include/experimental/string_view b/libstdc++-v3/include/experimental/string_view
index bebeb6b..49f46af 100644
--- a/libstdc++-v3/include/experimental/string_view
+++ b/libstdc++-v3/include/experimental/string_view
@@ -39,7 +39,6 @@
 # include <bits/c++14_warning.h>
 #else
 
-#include <debug/debug.h>
 #include <string>
 #include <limits>
 
@@ -66,18 +65,10 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
    *    _CharT*    _M_str
    *    size_t     _M_len
    *  @endcode
-   *
-   *  A basic_string_view represents an empty string with a static constexpr
-   *  length one string:
-   *
-   *  @code
-   *    static constexpr value_type _S_empty_str[1]{0};
-   *  @endcode
    */
-  template<typename _CharT, typename _Traits = char_traits<_CharT>>
+  template<typename _CharT, typename _Traits = std::char_traits<_CharT>>
     class basic_string_view
     {
-
     public:
 
       // types
@@ -99,7 +90,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 
       constexpr
       basic_string_view() noexcept
-      : _M_len{0}, _M_str{_S_empty_str}
+      : _M_len{0}, _M_str{nullptr}
       { }
 
       constexpr basic_string_view(const basic_string_view&) noexcept = default;
@@ -112,12 +103,12 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 
       constexpr basic_string_view(const _CharT* __str)
       : _M_len{__str == nullptr ? 0 : traits_type::length(__str)},
-	_M_str{__str == nullptr ? _S_empty_str : __str}
+	_M_str{__str}
       { }
 
       constexpr basic_string_view(const _CharT* __str, size_type __len)
-      : _M_len{__str == nullptr ? 0 :__len},
-        _M_str{__str == nullptr ? _S_empty_str : __str}
+      : _M_len{__len},
+        _M_str{__str}
       { }
 
       basic_string_view&
@@ -143,19 +134,19 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 
       const_reverse_iterator
       rbegin() const noexcept
-      { return std::reverse_iterator<const_iterator>(this->end()); }
+      { return const_reverse_iterator(this->end()); }
 
       const_reverse_iterator
       rend() const noexcept
-      { return std::reverse_iterator<const_iterator>(this->begin()); }
+      { return const_reverse_iterator(this->begin()); }
 
       const_reverse_iterator
       crbegin() const noexcept
-      { return std::reverse_iterator<const_iterator>(this->end()); }
+      { return const_reverse_iterator(this->end()); }
 
       const_reverse_iterator
       crend() const noexcept
-      { return std::reverse_iterator<const_iterator>(this->begin()); }
+      { return const_reverse_iterator(this->begin()); }
 
       // [string.view.capacity], capacity
 
@@ -169,8 +160,10 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 
       constexpr size_type
       max_size() const noexcept
-      { return ((npos - sizeof(size_type) - sizeof(void*))
-		/ sizeof(value_type) / 4); }
+      {
+	return (npos - sizeof(size_type) - sizeof(void*))
+		/ sizeof(value_type) / 4;
+      }
 
       constexpr bool
       empty() const noexcept
@@ -195,7 +188,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 					     "(which is %zu) >= this->size() "
 					     "(which is %zu)"),
 					 __pos, this->size()),
-		_S_empty_str[0]);
+		*this->_M_str);
       }
 
       constexpr const _CharT&
@@ -219,11 +212,12 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       { return this->_M_str; }
 
       // [string.view.modifiers], modifiers:
+
       void
       clear() noexcept
       {
 	this->_M_len = 0;
-	this->_M_str = _S_empty_str;
+	this->_M_str = nullptr;
       }
 
       void
@@ -251,8 +245,14 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       template<typename _Allocator>
         explicit operator basic_string<_CharT, _Traits, _Allocator>() const
         {
-	  return basic_string<_CharT, _Traits, _Allocator>
-					(this->_M_len, this->_M_str);
+	  return { this->_M_str, this->_M_len };
+	}
+
+      template<typename _Allocator = std::allocator<_CharT>>
+	basic_string<_CharT, _Traits, _Allocator>
+	to_string(const _Allocator& __alloc = _Allocator()) const
+	{
+	  return { this->_M_str, this->_M_len, __alloc };
 	}
 
       size_type
@@ -329,7 +329,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       find(_CharT __c, size_type __pos=0) const noexcept;
 
       size_type
-      find(const _CharT* __str, size_type __pos, size_type __n) const;
+      find(const _CharT* __str, size_type __pos, size_type __n) const noexcept;
 
       size_type
       find(const _CharT* __str, size_type __pos=0) const noexcept
@@ -343,7 +343,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       rfind(_CharT __c, size_type __pos = npos) const noexcept;
 
       size_type
-      rfind(const _CharT* __str, size_type __pos, size_type __n) const;
+      rfind(const _CharT* __str, size_type __pos, size_type __n) const noexcept;
 
       size_type
       rfind(const _CharT* __str, size_type __pos = npos) const noexcept
@@ -431,8 +431,6 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 	     : static_cast<int>(difference_type{__n1 - __n2});
       }
 
-      static constexpr value_type _S_empty_str[1]{};
-
       size_t	    _M_len;
       const _CharT* _M_str;
     };
@@ -456,131 +454,119 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
   }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator==(basic_string_view<_CharT, _Traits> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return __x.compare(__y) == 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator==(basic_string_view<_CharT, _Traits> __x,
                __detail::__idt<basic_string_view<_CharT, _Traits>> __y) noexcept
     { return __x.compare(__y) == 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator==(__detail::__idt<basic_string_view<_CharT, _Traits>> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return __x.compare(__y) == 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator!=(basic_string_view<_CharT, _Traits> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return !(__x == __y); }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator!=(basic_string_view<_CharT, _Traits> __x,
                __detail::__idt<basic_string_view<_CharT, _Traits>> __y) noexcept
     { return !(__x == __y); }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator!=(__detail::__idt<basic_string_view<_CharT, _Traits>> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return !(__x == __y); }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator< (basic_string_view<_CharT, _Traits> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return __x.compare(__y) < 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator< (basic_string_view<_CharT, _Traits> __x,
                __detail::__idt<basic_string_view<_CharT, _Traits>> __y) noexcept
     { return __x.compare(__y) < 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator< (__detail::__idt<basic_string_view<_CharT, _Traits>> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return __x.compare(__y) < 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator> (basic_string_view<_CharT, _Traits> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return __x.compare(__y) > 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator> (basic_string_view<_CharT, _Traits> __x,
                __detail::__idt<basic_string_view<_CharT, _Traits>> __y) noexcept
     { return __x.compare(__y) > 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator> (__detail::__idt<basic_string_view<_CharT, _Traits>> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return __x.compare(__y) > 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator<=(basic_string_view<_CharT, _Traits> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return __x.compare(__y) <= 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator<=(basic_string_view<_CharT, _Traits> __x,
                __detail::__idt<basic_string_view<_CharT, _Traits>> __y) noexcept
     { return __x.compare(__y) <= 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator<=(__detail::__idt<basic_string_view<_CharT, _Traits>> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return __x.compare(__y) <= 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator>=(basic_string_view<_CharT, _Traits> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return __x.compare(__y) >= 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator>=(basic_string_view<_CharT, _Traits> __x,
                __detail::__idt<basic_string_view<_CharT, _Traits>> __y) noexcept
     { return __x.compare(__y) >= 0; }
 
   template<typename _CharT, typename _Traits>
-    bool
+    inline bool
     operator>=(__detail::__idt<basic_string_view<_CharT, _Traits>> __x,
                basic_string_view<_CharT, _Traits> __y) noexcept
     { return __x.compare(__y) >= 0; }
 
-  // [string.view.comparison], sufficient additional overloads of comparison functions
-
-  // [string.view.nonmem], other non-member basic_string_view functions
-  template<typename _CharT, typename _Traits = char_traits<_CharT>,
-           typename _Allocator = allocator<_CharT>>
-    basic_string<_CharT, _Traits, _Allocator>
-    to_string(basic_string_view<_CharT, _Traits> __str,
-	      const _Allocator& __alloc = _Allocator())
-    {
-      return basic_string<_CharT, _Traits, _Allocator>
-			(__str.begin(), __str.end(), __alloc);
-    }
-
+  // [string.view.io], Inserters and extractors
   template<typename _CharT, typename _Traits>
-    basic_ostream<_CharT, _Traits>&
-      operator<<(basic_ostream<_CharT, _Traits>& __os,
-                 basic_string_view<_CharT,_Traits> __str)
-      { return __ostream_insert(__os, __str.data(), __str.size()); }
+    inline basic_ostream<_CharT, _Traits>&
+    operator<<(basic_ostream<_CharT, _Traits>& __os,
+	       basic_string_view<_CharT,_Traits> __str)
+    { return __ostream_insert(__os, __str.data(), __str.size()); }
 
 
   // basic_string_view typedef names
diff --git a/libstdc++-v3/include/experimental/string_view.tcc b/libstdc++-v3/include/experimental/string_view.tcc
index 1af3a4d..4456266 100644
--- a/libstdc++-v3/include/experimental/string_view.tcc
+++ b/libstdc++-v3/include/experimental/string_view.tcc
@@ -47,10 +47,6 @@ namespace experimental
 _GLIBCXX_BEGIN_NAMESPACE_VERSION
 
   template<typename _CharT, typename _Traits>
-    constexpr _CharT
-    basic_string_view<_CharT, _Traits>::_S_empty_str[1];
-
-  template<typename _CharT, typename _Traits>
     typename basic_string_view<_CharT, _Traits>::size_type
     basic_string_view<_CharT, _Traits>::
     find(const _CharT* __str, size_type __pos, size_type __n) const noexcept
diff --git a/libstdc++-v3/include/ext/pb_ds/detail/bin_search_tree_/traits.hpp b/libstdc++-v3/include/ext/pb_ds/detail/bin_search_tree_/traits.hpp
index d97b432..7ada365 100644
--- a/libstdc++-v3/include/ext/pb_ds/detail/bin_search_tree_/traits.hpp
+++ b/libstdc++-v3/include/ext/pb_ds/detail/bin_search_tree_/traits.hpp
@@ -55,7 +55,7 @@ namespace __gnu_pbds
 	     class Cmp_Fn,
 	     template<typename Node_CItr,
 		      class Node_Itr,
-		      class Cmp_Fn,
+		      class _Cmp_Fn,
 		      typename _Alloc>
 	     class Node_Update,
 	     class Node,
@@ -161,7 +161,7 @@ namespace __gnu_pbds
 	     class Cmp_Fn,
 	     template<typename Node_CItr,
 		      class Node_Itr,
-		      class Cmp_Fn,
+		      class _Cmp_Fn,
 		      typename _Alloc>
 	     class Node_Update,
 	     class Node,
diff --git a/libstdc++-v3/include/ext/random.tcc b/libstdc++-v3/include/ext/random.tcc
index dd7a14a..fec7f86 100644
--- a/libstdc++-v3/include/ext/random.tcc
+++ b/libstdc++-v3/include/ext/random.tcc
@@ -1314,7 +1314,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       operator()(_UniformRandomNumberGenerator& __urng,
 		 const param_type& __param)
       {
-	std::__detail::_Adaptor<_UniformRandomNumberGenerator, result_type>
+	std::__detail::_Adaptor<_UniformRandomNumberGenerator, double>
 	  __aurng(__urng);
 
 	result_type __a = __param.successful_size();
diff --git a/libstdc++-v3/include/ext/rope b/libstdc++-v3/include/ext/rope
index df3d4bb..147b335 100644
--- a/libstdc++-v3/include/ext/rope
+++ b/libstdc++-v3/include/ext/rope
@@ -1544,7 +1544,7 @@ protected:
       typedef typename _Base::allocator_type allocator_type;
       using _Base::_M_tree_ptr;
       using _Base::get_allocator;
-      using _Base::_M_get_allocator;      
+      using _Base::_M_get_allocator;
       typedef __GC_CONST _CharT* _Cstrptr;
       
       static _CharT _S_empty_c_str[1];
@@ -1876,8 +1876,9 @@ protected:
 	   const allocator_type& __a = allocator_type())
       : _Base(__a)
       {
-	this->_M_tree_ptr = (0 == __len) ?
-	  0 : _S_new_RopeFunction(__fn, __len, __delete_fn, __a);
+	this->_M_tree_ptr = (0 == __len)
+	  ? 0
+	  : _S_new_RopeFunction(__fn, __len, __delete_fn, _M_get_allocator());
       }
 
       rope(const rope& __x, const allocator_type& __a = allocator_type())
diff --git a/libstdc++-v3/include/std/condition_variable b/libstdc++-v3/include/std/condition_variable
index fc111dd..921cb83 100644
--- a/libstdc++-v3/include/std/condition_variable
+++ b/libstdc++-v3/include/std/condition_variable
@@ -189,7 +189,14 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 	~_Unlock() noexcept(false)
 	{
 	  if (uncaught_exception())
-	    __try { _M_lock.lock(); } __catch(...) { }
+	    {
+	      __try
+	      { _M_lock.lock(); }
+	      __catch(const __cxxabiv1::__forced_unwind&)
+	      { __throw_exception_again; }
+	      __catch(...)
+	      { }
+	    }
 	  else
 	    _M_lock.lock();
 	}
diff --git a/libstdc++-v3/include/std/future b/libstdc++-v3/include/std/future
index 998e90a..d446b9d 100644
--- a/libstdc++-v3/include/std/future
+++ b/libstdc++-v3/include/std/future
@@ -1240,6 +1240,10 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 	  {
 	    _M_result->_M_set(_M_fn());
 	  }
+	__catch(const __cxxabiv1::__forced_unwind&)
+	  {
+	    __throw_exception_again; // will cause broken_promise
+	  }
 	__catch(...)
 	  {
 	    _M_result->_M_error = current_exception();
@@ -1259,6 +1263,10 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
 	  {
 	    _M_fn();
 	  }
+	__catch(const __cxxabiv1::__forced_unwind&)
+	  {
+	    __throw_exception_again; // will cause broken_promise
+	  }
 	__catch(...)
 	  {
 	    _M_result->_M_error = current_exception();
@@ -1519,7 +1527,17 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
       : _M_result(new _Result<_Res>()), _M_fn(std::move(__fn))
       {
 	_M_thread = std::thread{ [this] {
-	  _M_set_result(_S_task_setter(_M_result, _M_fn));
+	    __try
+	      {
+		_M_set_result(_S_task_setter(_M_result, _M_fn));
+	      }
+	    __catch (const __cxxabiv1::__forced_unwind&)
+	      {
+		// make the shared state ready on thread cancellation
+		if (static_cast<bool>(_M_result))
+		  this->_M_break_promise(std::move(_M_result));
+		__throw_exception_again;
+	      }
         } };
       }
 
diff --git a/libstdc++-v3/include/std/mutex b/libstdc++-v3/include/std/mutex
index 0b481d6..c6b7f13 100644
--- a/libstdc++-v3/include/std/mutex
+++ b/libstdc++-v3/include/std/mutex
@@ -44,6 +44,7 @@
 #include <bits/functexcept.h>
 #include <bits/gthr.h>
 #include <bits/move.h> // for std::swap
+#include <bits/cxxabi_forced.h>
 
 #ifdef _GLIBCXX_USE_C99_STDINT_TR1
 
@@ -647,10 +648,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     {
       int __idx;
       auto __locks = std::tie(__l1, __l2, __l3...);
-      __try
-      { __try_lock_impl<0>::__do_try_lock(__locks, __idx); }
-      __catch(...)
-      { }
+      __try_lock_impl<0>::__do_try_lock(__locks, __idx);
       return __idx;
     }
 
diff --git a/libstdc++-v3/include/std/type_traits b/libstdc++-v3/include/std/type_traits
index 1ff2e62..e898c9f 100644
--- a/libstdc++-v3/include/std/type_traits
+++ b/libstdc++-v3/include/std/type_traits
@@ -634,6 +634,14 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION
     : public integral_constant<bool, __is_polymorphic(_Tp)>
     { };
 
+#if __cplusplus > 201103L
+  /// is_final
+  template<typename _Tp>
+    struct is_final
+    : public integral_constant<bool, __is_final(_Tp)>
+    { };
+#endif
+
   /// is_abstract
   template<typename _Tp>
     struct is_abstract
diff --git a/libstdc++-v3/libsupc++/atexit_thread.cc b/libstdc++-v3/libsupc++/atexit_thread.cc
index db20200..dff08e9 100644
--- a/libstdc++-v3/libsupc++/atexit_thread.cc
+++ b/libstdc++-v3/libsupc++/atexit_thread.cc
@@ -26,7 +26,7 @@
 #include <new>
 #include "bits/gthr.h"
 
-#if HAVE___CXA_THREAD_ATEXIT_IMPL
+#if _GLIBCXX_HAVE___CXA_THREAD_ATEXIT_IMPL
 
 extern "C" int __cxa_thread_atexit_impl (void (*func) (void *),
 					 void *arg, void *d);
@@ -38,7 +38,7 @@ __cxxabiv1::__cxa_thread_atexit (void (*dtor)(void *),
   return __cxa_thread_atexit_impl (dtor, obj, dso_handle);
 }
 
-#else /* HAVE___CXA_THREAD_ATEXIT_IMPL */
+#else /* _GLIBCXX_HAVE___CXA_THREAD_ATEXIT_IMPL */
 
 namespace {
   // One element in a singly-linked stack of cleanups.
@@ -142,4 +142,4 @@ __cxxabiv1::__cxa_thread_atexit (void (*dtor)(void *), void *obj, void */*dso_ha
   return 0;
 }
 
-#endif /* HAVE___CXA_THREAD_ATEXIT_IMPL */
+#endif /* _GLIBCXX_HAVE___CXA_THREAD_ATEXIT_IMPL */
